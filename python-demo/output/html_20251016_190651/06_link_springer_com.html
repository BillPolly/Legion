<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="applicable-device" content="pc,mobile">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        
        
            <meta name="robots" content="max-image-preview:large">
            <meta name="access" content="Yes">

        
        <meta name="360-site-verification" content="1268d79b5e96aecf3ff2a7dac04ad990" />

        <title>The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work | Journal of Business Ethics</title>

        
            
    
    <meta name="twitter:site" content="@SpringerLink"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work"/>
    <meta name="twitter:description" content="Journal of Business Ethics - The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the..."/>
    <meta name="twitter:image" content="https://static-content.springer.com/image/art%3A10.1007%2Fs10551-023-05339-7/MediaObjects/10551_2023_5339_Fig1_HTML.png"/>
    <meta name="journal_id" content="10551"/>
    <meta name="dc.title" content="The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work"/>
    <meta name="dc.source" content="Journal of Business Ethics 2023 185:4"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Springer"/>
    <meta name="dc.date" content="2023-02-11"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2023 The Author(s)"/>
    <meta name="dc.rights" content="2023 The Author(s)"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one&#8217;s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees&#8217; experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, &#8216;tending the machine&#8217;, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions."/>
    <meta name="prism.issn" content="1573-0697"/>
    <meta name="prism.publicationName" content="Journal of Business Ethics"/>
    <meta name="prism.publicationDate" content="2023-02-11"/>
    <meta name="prism.volume" content="185"/>
    <meta name="prism.number" content="4"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="725"/>
    <meta name="prism.endingPage" content="740"/>
    <meta name="prism.copyright" content="2023 The Author(s)"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10551-023-05339-7"/>
    <meta name="prism.doi" content="doi:10.1007/s10551-023-05339-7"/>
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10551-023-05339-7.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10551-023-05339-7"/>
    <meta name="citation_journal_title" content="Journal of Business Ethics"/>
    <meta name="citation_journal_abbrev" content="J Bus Ethics"/>
    <meta name="citation_publisher" content="Springer Netherlands"/>
    <meta name="citation_issn" content="1573-0697"/>
    <meta name="citation_title" content="The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work"/>
    <meta name="citation_volume" content="185"/>
    <meta name="citation_issue" content="4"/>
    <meta name="citation_publication_date" content="2023/07"/>
    <meta name="citation_online_date" content="2023/02/11"/>
    <meta name="citation_firstpage" content="725"/>
    <meta name="citation_lastpage" content="740"/>
    <meta name="citation_article_type" content="Original Paper"/>
    <meta name="citation_fulltext_world_readable" content=""/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1007/s10551-023-05339-7"/>
    <meta name="DOI" content="10.1007/s10551-023-05339-7"/>
    <meta name="size" content="195654"/>
    <meta name="citation_doi" content="10.1007/s10551-023-05339-7"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1007/s10551-023-05339-7&amp;api_key="/>
    <meta name="description" content="The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work re"/>
    <meta name="dc.creator" content="Bankins, Sarah"/>
    <meta name="dc.creator" content="Formosa, Paul"/>
    <meta name="dc.subject" content="Ethics"/>
    <meta name="dc.subject" content="Business and Management, general"/>
    <meta name="dc.subject" content="Management"/>
    <meta name="dc.subject" content="Business Ethics"/>
    <meta name="dc.subject" content="Quality of Life Research"/>
    <meta name="citation_reference" content="citation_journal_title=Human Studies; citation_title=Pragmatism, artificial intelligence, and posthuman bioethics: Shusterman, Rorty, Foucault; citation_author=JJ Abrams; citation_volume=27; citation_issue=3; citation_publication_date=2004; citation_pages=241-258; citation_doi=10.1023/B:HUMA.0000042130.79208.c6; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Cambridge Journal of Regions, Economy and Society.; citation_title=The wrong kind of AI? Artificial intelligence and the future of labour demand; citation_author=D Acemoglu, P Restrepo; citation_volume=13; citation_publication_date=2020; citation_pages=25-35; citation_doi=10.1093/cjres/rsz022; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Management Studies; citation_title=Outcomes of meaningful work: A meta-analysis; citation_author=BA Allan, C Batz-Barbarich, HM Sterling, L Tay; citation_volume=56; citation_issue=3; citation_publication_date=2019; citation_pages=500-528; citation_doi=10.1111/joms.12406; citation_id=CR3"/>
    <meta name="citation_reference" content="Asher-Schapiro, A. (2021). Amazon AI van cameras spark surveillance concerns. News.Trust.Org. 
                  https://news.trust.org/item/20210205132207-c0mz7/
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Human Resource Development Review; citation_title=A review of the empirical literature on meaningful work: Progress and research agenda; citation_author=C Bailey, R Yeoman, A Madden, M Thompson, G Kerridge; citation_volume=18; citation_issue=1; citation_publication_date=2019; citation_pages=83-113; citation_doi=10.1177/1534484318804653; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Ethics and Information Technology; citation_title=The ethical use of artificial intelligence in human resource management: A decision making framework; citation_author=S Bankins; citation_volume=23; citation_publication_date=2021; citation_pages=841-854; citation_doi=10.1007/s10676-021-09619-6; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=European Journal of Work and Organizational Psychology; citation_title=When AI meets PC: Exploring the implications of workplace social robots and a human-robot psychological contract; citation_author=S Bankins, P Formosa; citation_volume=29; citation_issue=2; citation_publication_date=2020; citation_pages=215-229; citation_doi=10.1080/1359432X.2019.1620328; citation_id=CR7"/>
    <meta name="citation_reference" content="Bankins, S., &amp; Formosa, P. (2021). Ethical AI at work: The social contract for artificial intelligence and its implications for the workplace psychological contract. In: M. Coetzee &amp; A. Deas (Eds.), Redefining the Psychological Contract in the Digital Era: Issues for Research and Practice (pp. 55&#8211;72). Springer: Switzerland."/>
    <meta name="citation_reference" content="citation_title=AI decision making with dignity? Contrasting workers&#39; justice perceptions of human and AI decision making in a human resource management context.; citation_publication_date=2022; citation_id=CR9; citation_author=S Bankins; citation_author=P Formosa; citation_author=Y Griep; citation_author=D Richards; citation_publisher=Information Systems Frontiers"/>
    <meta name="citation_reference" content="citation_title=Current trends in robotics; citation_inbook_title=Robot Ethics; citation_publication_date=2012; citation_pages=17-34; citation_id=CR10; citation_author=GA Bekey; citation_publisher=MIT Press"/>
    <meta name="citation_reference" content="citation_journal_title=Annual Review of Criminology; citation_title=Artificial intelligence, predictive policing, and risk assessment for law enforcement; citation_author=RA Berk; citation_volume=4; citation_issue=1; citation_publication_date=2021; citation_pages=209-237; citation_doi=10.1146/annurev-criminol-051520-012342; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_title=AI; citation_publication_date=2016; citation_id=CR12; citation_author=MA Boden; citation_publisher=Oxford University Press"/>
    <meta name="citation_reference" content="citation_journal_title=Organization Science; citation_title=Unpacking the managerial blues: How expectations formed in the past carry into new jobs; citation_author=N Bourmault, M Anteby; citation_volume=31; citation_issue=6; citation_publication_date=2020; citation_pages=1452-1474; citation_doi=10.1287/orsc.2020.1361; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Business Ethics; citation_title=A Kantian theory of meaningful work; citation_author=NE Bowie; citation_volume=17; citation_publication_date=1998; citation_pages=1083-1092; citation_doi=10.1023/A:1006023500585; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Basic Income Studies; citation_title=Artificial intelligence, jobs and the future of work; citation_author=E Bruun, A Duka; citation_volume=13; citation_issue=2; citation_publication_date=2018; citation_pages=1-15; citation_doi=10.1515/bis-2018-0018; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_title=The myth of Sisyphus and other essays; citation_publication_date=1955; citation_id=CR18; citation_author=A Camus; citation_publisher=Hamish Hamilton"/>
    <meta name="citation_reference" content="citation_journal_title=Administrative Science Quarterly; citation_title=I&#8217;m not mopping the floors, I&#8217;m putting a man on the moon: How NASA leaders enhanced the meaningfulness of work by changing the meaning of work; citation_author=AM Carton; citation_volume=63; citation_issue=2; citation_publication_date=2018; citation_pages=323-369; citation_doi=10.1177/0001839217713748; citation_id=CR19"/>
    <meta name="citation_reference" content="Cheney, G., Zorn Jr, T. E., Planalp, S., &amp; Lair, D. J. (2008). Meaningful work and personal/social well-being organizational communication engages the meanings of work. Annals of the International Communication Association, 32(1), 137&#8211;185."/>
    <meta name="citation_reference" content="Chui, M., Manyika, J., &amp; Miremadi, M. (2015). The four fundamentals of workplace automation. McKinsey. 
                  http://www.mckinsey.com/business-functions/digital-mckinsey/our-insights/four-fundamentals-of-workplace-automation
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Philosophy &amp; Technology; citation_title=Appraising black-boxed technology: The positive prospects; citation_author=ES Dahl; citation_volume=31; citation_publication_date=2018; citation_pages=571-591; citation_doi=10.1007/s13347-017-0275-1; citation_id=CR21"/>
    <meta name="citation_reference" content="Dastin, J. (2018, October 11). Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. 
                  https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G
                  
                "/>
    <meta name="citation_reference" content="citation_title=Human + Machine: Reimagining work in the age of AI; citation_publication_date=2018; citation_id=CR23; citation_author=PR Daugherty; citation_author=HJ Wilson; citation_publisher=Harvard Business Review Press"/>
    <meta name="citation_reference" content="citation_journal_title=Fast Capitalism; citation_title=Minding machines: A note on alienation; citation_author=S Engel; citation_volume=16; citation_issue=2; citation_publication_date=2019; citation_pages=129-139; citation_doi=10.32855/fcapital.201902.012; citation_id=CR24"/>
    <meta name="citation_reference" content="Ernst, E., Merola, R., &amp; Samaan, D. (2018). The economics of artificial intelligence. International Labour Organization. 
                  https://www.ilo.org/wcmsp5/groups/public/dgreports/cabinet/documents/publication/wcms_647306.pdf
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Minds and Machines; citation_title=AI4People - An ethical framework for a good AI society; citation_author=L Floridi; citation_volume=28; citation_issue=4; citation_publication_date=2018; citation_pages=689-707; citation_doi=10.1007/s11023-018-9482-5; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_title=Kantian ethics, dignity and perfection; citation_publication_date=2017; citation_id=CR27; citation_author=P Formosa; citation_publisher=Cambridge University Press"/>
    <meta name="citation_reference" content="Formosa, P. (2021). Robot autonomy vs human autonomy: Social robots, artificial intelligence (AI), and the nature of autonomy. Minds and Machines, 31, 595&#8211;616."/>
    <meta name="citation_reference" content="citation_journal_title=AI &amp; Society; citation_title=Making moral machines: Why we need artificial moral agents; citation_author=P Formosa, M Ryan; citation_volume=36; citation_publication_date=2021; citation_pages=839-851; citation_doi=10.1007/s00146-020-01089-6; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Computers &amp; Security; citation_title=A principlist framework for cybersecurity ethics; citation_author=P Formosa, M Wilson, D Richards; citation_volume=109; citation_publication_date=2021; citation_doi=10.1016/j.cose.2021.102382; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Technological Forecasting and Social Change; citation_title=The future of employment: How susceptible are jobs to computerisation?; citation_author=CB Frey, MA Osborne; citation_volume=114; citation_publication_date=2017; citation_pages=254-280; citation_doi=10.1016/j.techfore.2016.08.019; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=IZA World of Labor; citation_title=How is new technology changing job design?; citation_author=MJ Gibbs; citation_publication_date=2017; citation_doi=10.15185/izawol.344; citation_id=CR32"/>
    <meta name="citation_reference" content="Gladden, M. E. (2016). Posthuman management: Creating effective organizations in an age of social robotics, ubiquitous AI, human augmentation, and virtual worlds. Defragmenter Media: USA."/>
    <meta name="citation_reference" content="citation_journal_title=Academy of Management Review; citation_title=Relational job design and the motivation to make a prosocial difference; citation_author=AM Grant; citation_volume=32; citation_issue=2; citation_publication_date=2007; citation_pages=393-417; citation_doi=10.5465/amr.2007.24351328; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Psychology; citation_title=The significance of task significance: Job performance effects, relational mechanisms, and boundary conditions; citation_author=AM Grant; citation_volume=93; citation_issue=1; citation_publication_date=2008; citation_pages=108-124; citation_doi=10.1037/0021-9010.93.1.108; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Empirical Legal Studies; citation_title=Comparing conventional and machine-learning approaches to risk assessment in domestic abuse cases; citation_author=J Grogger, R Ivandic, T Kirchmaier; citation_volume=18; citation_issue=1; citation_publication_date=2020; citation_pages=90-130; citation_doi=10.1111/jels.12276; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Applied Psychology; citation_title=Development of the job diagnostic survey; citation_author=JR Hackman, GR Oldham; citation_volume=60; citation_issue=2; citation_publication_date=1975; citation_pages=159-170; citation_doi=10.1037/h0076546; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Organizational Behavior and Human Performance; citation_title=Motivation through the design of work: Test of a theory; citation_author=JR Hackman, GR Oldham; citation_volume=16; citation_issue=2; citation_publication_date=1976; citation_pages=250-279; citation_doi=10.1016/0030-5073(76)90016-7; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Minds and Machines; citation_title=The ethics of AI ethics: An evaluation of guidelines; citation_author=T Hagendorff; citation_volume=30; citation_publication_date=2020; citation_pages=99-120; citation_doi=10.1007/s11023-020-09517-8; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Computer; citation_title=Toward human-understandable, explainable AI; citation_author=H Hagras; citation_volume=51; citation_issue=9; citation_publication_date=2018; citation_pages=28-36; citation_doi=10.1109/MC.2018.3620965; citation_id=CR39"/>
    <meta name="citation_reference" content="Halloran, L. &amp; Andrews, J. (2018). Will you wait for the future to happen? Ernst and Young. 
                  https://www.ey.com/en_au/workforce/will-you-shape-the-future-of-work-or-will-it-shape-you
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=New Scientist; citation_title=With AI, you might unlock some of the secrets about how life works; citation_author=D Hassabis, T Revell; citation_volume=249; citation_issue=3315; citation_publication_date=2021; citation_pages=44-49; citation_doi=10.1016/S0262-4079(20)32269-7; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Ethics and Emerging Technologies; citation_title=A strategic opening for a basic income guarantee in the global crisis being created by AI, robots, desktop manufacturing and biomedicine; citation_author=J Hughes; citation_volume=24; citation_issue=1; citation_publication_date=2014; citation_pages=45-61; citation_doi=10.55613/jeet.v24i1.12; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Business Horizons; citation_title=Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making; citation_author=MH Jarrahi; citation_volume=61; citation_issue=4; citation_publication_date=2018; citation_pages=577-586; citation_doi=10.1016/j.bushor.2018.03.007; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Business Information Review; citation_title=In the age of the smart artificial intelligence: AI&#39;s dual capacities for automating and informating work; citation_author=MH Jarrahi; citation_volume=36; citation_issue=4; citation_publication_date=2019; citation_pages=178-187; citation_doi=10.1177/0266382119883999; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=Nature Machine Intelligence; citation_title=The global landscape of AI ethics guidelines; citation_author=A Jobin, M Ienca, E Vayena; citation_volume=1; citation_issue=9; citation_publication_date=2019; citation_pages=389-399; citation_doi=10.1038/s42256-019-0088-2; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=Academy of Management Annals; citation_title=Algorithms at work: The new contested terrain of control; citation_author=KC Kellogg, MA Valentine, A Christin; citation_volume=14; citation_issue=1; citation_publication_date=2020; citation_pages=366-410; citation_doi=10.5465/annals.2018.0174; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Economic Psychology; citation_title=Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon&#39;s vision of the future; citation_author=RN Langlois; citation_volume=24; citation_issue=2; citation_publication_date=2003; citation_pages=167-187; citation_doi=10.1016/S0167-4870(02)00201-5; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Business Ethics; citation_title=The challenges of algorithm-based HR decision-making for personal integrity; citation_author=U Leicht-Deobald; citation_volume=160; citation_publication_date=2019; citation_pages=377-392; citation_doi=10.1007/s10551-019-04204-w; citation_id=CR48"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Business Ethics; citation_title=Discriminating between &#8216;meaningful work&#8217; and the &#8216;management of meaning&#8217;; citation_author=M Lips-Wiersma, L Morris; citation_volume=88; citation_issue=3; citation_publication_date=2009; citation_pages=491-511; citation_doi=10.1007/s10551-009-0118-9; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Group &amp; Organization Management; citation_title=Measuring the meaning of meaningful work: Development and validation of the comprehensive meaningful work scale; citation_author=M Lips-Wiersma, S Wright; citation_volume=37; citation_issue=5; citation_publication_date=2012; citation_pages=655-685; citation_doi=10.1177/1059601112461578; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Vocational Behavior; citation_title=Fostering meaningful work in organizations: A multi-level review and integration; citation_author=EI Lysova, BA Allan, BJ Dik, RD Duffy, MF Steger; citation_volume=110; citation_publication_date=2019; citation_pages=374-389; citation_doi=10.1016/j.jvb.2018.07.004; citation_id=CR51"/>
    <meta name="citation_reference" content="Martela, F., &amp; Riekki, T. J. J. (2018). Autonomy, competence, relatedness, and beneficence: A multicultural comparison of the four pathways to meaningful work. Frontiers in Psychology, 9, 1157."/>
    <meta name="citation_reference" content="Mazmanian, M., Orlikowski, W. J., &amp; Yates, J. (2013). The autonomy paradox: The implications of mobile email devices for knowledge professionals. Organization Science, 24(5), 1337&#8211;1357."/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Business Ethics; citation_title=Meaningful work: Connecting business ethics and organization studies; citation_author=C Michaelson, MG Pratt, AM Grant, CP Dunn; citation_volume=121; citation_publication_date=2014; citation_pages=77-90; citation_doi=10.1007/s10551-013-1675-5; citation_id=CR53"/>
    <meta name="citation_reference" content="citation_title=Net privacy: How we can be free in an age of surveillance; citation_publication_date=2020; citation_id=CR54; citation_author=S Molitorisz; citation_publisher=McGill-Queen&#39;s University Press"/>
    <meta name="citation_reference" content="citation_journal_title=AI &amp; Society; citation_title=The race for an artificial general intelligence: Implications for public policy; citation_author=W Naud&#233;, N Dimitri; citation_volume=35; citation_publication_date=2020; citation_pages=367-379; citation_doi=10.1007/s00146-019-00887-x; citation_id=CR55"/>
    <meta name="citation_reference" content="citation_title=Creating capabilities: The human development approach; citation_publication_date=2011; citation_id=CR56; citation_author=MC Nussbaum; citation_publisher=Harvard University Press"/>
    <meta name="citation_reference" content="Pardes, A. (2020, November). AI can run your work meetings now. Wired. 
                  https://www.wired.com/story/ai-can-run-work-meetings-now-headroom-clockwise/
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Applied Psychology; citation_title=Automation, algorithms, and beyond: Why work design matters more than ever in a digital world; citation_author=SK Parker, G Grote; citation_volume=71; citation_issue=4; citation_publication_date=2022; citation_pages=1171-1204; citation_doi=10.1111/apps.12241; citation_id=CR58"/>
    <meta name="citation_reference" content="Pratt, M. G., &amp; Ashforth, B. E. (2003). Fostering meaningfulness in working and at work. In K. Cameron, J. E. Dutton, &amp; R. E. Quinn (Eds.), Positive organizational scholarship: Foundations of a new discipline (pp. 308&#8211;327). Berrett-Koehler: San Francisco."/>
    <meta name="citation_reference" content="Pulse+IT. (2020). The San using AI to automate multidisciplinary team meetings. Pulse+IT. 
                  https://www.pulseitmagazine.com.au:443/australian-ehealth/5558-the-san-using-ai-to-automate-multidisciplinary-team-meetings
                  
                "/>
    <meta name="citation_reference" content="Ravenscraft, E. (25 November, 2021). What is the metaverse, exactly? Wired. Retrieved from: 
                  https://www.wired.com/story/what-is-the-metaverse/
                  
                "/>
    <meta name="citation_reference" content="Roberts, P. (2020). Working smarter with data. Australian Manufacturing Forum. 
                  https://www.aumanufacturing.com.au/working-smarter-with-data-ai-gives-agriculture-the-competitive-edge
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Information, Communication and Ethics in Society.; citation_title=Artificial intelligence ethics guidelines for developers and users: Clarifying their content and normative implications; citation_author=M Ryan, BC Stahl; citation_volume=19; citation_issue=1; citation_publication_date=2020; citation_pages=61-86; citation_doi=10.1108/JICES-12-2019-0138; citation_id=CR63"/>
    <meta name="citation_reference" content="Selbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., &amp; Vertesi, J. (2019). Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 59&#8211;68)."/>
    <meta name="citation_reference" content="Selenko, E., Bankins, S., Shoss, M., Warburton, J., &amp; Restubog, S. L. D. (2022). Artificial intelligence and the future of work: A functional-identity perspective. Current Directions in Psychological Science, 31(3), 272&#8211;279."/>
    <meta name="citation_reference" content="citation_journal_title=Social Research; citation_title=Social connection and compassion: Important predictors of health and well-being; citation_author=E Seppala, T Rossomando, JR Doty; citation_volume=80; citation_issue=2; citation_publication_date=2013; citation_pages=411-430; citation_doi=10.1353/sor.2013.0027; citation_id=CR64"/>
    <meta name="citation_reference" content="citation_journal_title=Philosophy &amp; Technology; citation_title=Robots in the workplace: A threat to - or opportunity for - meaningful work?; citation_author=J Smids, S Nyholm, H Berkers; citation_volume=33; citation_publication_date=2020; citation_pages=503-522; citation_doi=10.1007/s13347-019-00377-4; citation_id=CR65"/>
    <meta name="citation_reference" content="citation_journal_title=Internet Policy Review; citation_title=Technology, autonomy, and manipulation; citation_author=D Susser, B Roessler, H Nissenbaum; citation_publication_date=2019; citation_doi=10.14763/2019.2.1410; citation_id=CR66"/>
    <meta name="citation_reference" content="Symon, G., &amp; Whiting, R. (2019). The sociomaterial negotiation of social entrepreneurs&#8217; meaningful work. Journal of Management Studies, 56(3), 655&#8211;684."/>
    <meta name="citation_reference" content="citation_title=Nudge: Improving decisions about health, wealth, and happiness; citation_publication_date=2008; citation_id=CR67; citation_author=R Thaler; citation_author=C Sunstein; citation_publisher=Yale University Press"/>
    <meta name="citation_reference" content="citation_journal_title=Bulletin of the Atomic Scientists; citation_title=The possibility and risks of artificial general intelligence; citation_author=P Torres; citation_volume=75; citation_issue=3; citation_publication_date=2019; citation_pages=105-108; citation_doi=10.1080/00963402.2019.1604873; citation_id=CR68"/>
    <meta name="citation_reference" content="citation_journal_title=Psychological Review; citation_title=Temporal construal; citation_author=Y Trope, N Liberman; citation_volume=110; citation_issue=3; citation_publication_date=2003; citation_pages=403-421; citation_doi=10.1037/0033-295X.110.3.403; citation_id=CR69"/>
    <meta name="citation_reference" content="Tubaro, P., Casilli, A. A., &amp; Coville, M. (2020). The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence. Big Data &amp; Society, 7(1). 
                  https://doi.org/10.1177/2053951720919776
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Philosophy &amp; Technology; citation_title=Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character; citation_author=S Vallor; citation_volume=28; citation_issue=1; citation_publication_date=2015; citation_pages=107-124; citation_doi=10.1007/s13347-014-0156-9; citation_id=CR71"/>
    <meta name="citation_reference" content="Walsh, T., Levy, N., Bell, G., Elliott, A., Maclaurin, J., Mareels, I., &amp; Wood, Fiona. (2019). The effective and ethical development of artificial intelligence. ACOLA. 
                  https://acola.org/wp-content/uploads/2019/07/hs4_artificial-intelligence-report.pdf
                  
                "/>
    <meta name="citation_reference" content="Wang, P. (2019). On defining artificial intelligence. Journal of Artificial General Intelligence, 10(2), 1&#8211;37."/>
    <meta name="citation_reference" content="Webster, C., &amp; Ivanov, S. (2020). Robotics, artificial intelligence, and the evolving nature of work. In: B. George &amp; J. Paul (Eds.), Digital Transformation in Business and Society. Palgrave Macmillan, Cham."/>
    <meta name="citation_reference" content="citation_journal_title=Annual Review of Organizational Psychology and Organizational Behavior; citation_title=Construal level theory in organizational research; citation_author=BM Wiesenfeld, J-N Reyt, J Brockner, Y Trope; citation_volume=4; citation_issue=1; citation_publication_date=2017; citation_pages=367-400; citation_doi=10.1146/annurev-orgpsych-032516-113115; citation_id=CR74"/>
    <meta name="citation_reference" content="citation_title=Meaning in life and why it matters; citation_publication_date=2010; citation_id=CR75; citation_author=S Wolf; citation_publisher=Princeton University Press"/>
    <meta name="citation_reference" content="World Economic Forum. (2018). The future of jobs report. Centre for the New Economy and Society: Geneva, Switzerland."/>
    <meta name="citation_reference" content="citation_journal_title=Ethics and Information Technology; citation_title=A framework for the ethical impact assessment of information technology; citation_author=D Wright; citation_volume=13; citation_publication_date=2011; citation_pages=199-226; citation_doi=10.1007/s10676-010-9242-6; citation_id=CR76"/>
    <meta name="citation_reference" content="citation_journal_title=Business Horizons; citation_title=The rising tide of artificial intelligence and business automation: Developing an ethical framework; citation_author=SA Wright, AE Schultz; citation_volume=61; citation_issue=6; citation_publication_date=2018; citation_pages=823-832; citation_doi=10.1016/j.bushor.2018.07.001; citation_id=CR77"/>
    <meta name="citation_reference" content="citation_journal_title=AIS Transactions on Human-Computer Interaction: Towards building human-machine symbiotic relationship; citation_title=Intelligence augmentation; citation_author=L Zhou, S Paul, H Demirkan, L Yuan, J Spohrer, M Zhou, J Basu; citation_volume=13; citation_issue=2; citation_publication_date=2021; citation_pages=243-264; citation_doi=10.17705/1thci.00149; citation_id=CR78"/>
    <meta name="citation_reference" content="citation_title=In the age of the smart machine: The future of work and power; citation_publication_date=1988; citation_id=CR79; citation_author=S Zuboff; citation_publisher=Basic Books"/>
    <meta name="citation_author" content="Bankins, Sarah"/>
    <meta name="citation_author_email" content="sarah.bankins@mq.edu.au"/>
    <meta name="citation_author_institution" content="Department of Management, Macquarie Business School, Macquarie University, Sydney, Australia"/>
    <meta name="citation_author" content="Formosa, Paul"/>
    <meta name="citation_author_email" content="paul.formosa@mq.edu.au"/>
    <meta name="citation_author_institution" content="Department of Philosophy, Faculty of Arts, Macquarie University, Sydney, Australia"/>
    <meta name="format-detection" content="telephone=no"/>
    <meta name="citation_cover_date" content="2023/07/01"/>
    

            
    
    <meta property="og:url" content="https://link.springer.com/article/10.1007/s10551-023-05339-7"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="SpringerLink"/>
    <meta property="og:title" content="The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work - Journal of Business Ethics"/>
    <meta property="og:description" content="The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one&#8217;s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees&#8217; experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, &#8216;tending the machine&#8217;, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions."/>
    <meta property="og:image" content="https://static-content.springer.com/image/art%3A10.1007%2Fs10551-023-05339-7/MediaObjects/10551_2023_5339_Fig1_HTML.png"/>
    

        

        <meta name="format-detection" content="telephone=no">

        
    
        
    
    
    

    


        <link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/img/favicons/darwin/apple-touch-icon-6ef0829b9c.png>
<link rel="icon" type="image/png" sizes="192x192" href=/oscar-static/img/favicons/darwin/android-chrome-192x192.png>
<link rel="icon" type="image/png" sizes="32x32" href=/oscar-static/img/favicons/darwin/favicon-32x32.png>
<link rel="icon" type="image/png" sizes="16x16" href=/oscar-static/img/favicons/darwin/favicon-16x16.png>
<link rel="shortcut icon" data-test="shortcut-icon" href=/oscar-static/img/favicons/darwin/favicon-de0c289efe.ico>

<meta name="theme-color" content="#e6e6e6">


        



<link rel="stylesheet" media="print" href=/oscar-static/app-springerlink/css/print-b8af42253b.css>



    
        
            
    <style> html{line-height:1.15;text-size-adjust:100%}body{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.8;margin:0}details,main{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;color:#025e8d}b{font-weight:bolder}sub{bottom:-.25em;font-size:75%;line-height:0;position:relative;vertical-align:baseline}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input{font-family:inherit;font-size:100%;line-height:1.15;margin:0;overflow:visible}button{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}summary{display:list-item}[hidden]{display:none}button{cursor:pointer}svg{height:1rem;width:1rem}.eds-c-header__brand img{max-width:100%}@media only screen and (min-width:768px){.eds-c-header__brand img{max-width:340px}} </style>
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  body{background:#fff;color:#222;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.8;min-height:100%}a{color:#025e8d;padding:initial;text-decoration:underline;text-decoration-skip-ink:auto}button{cursor:pointer}img{border:0;height:auto;max-width:100%;vertical-align:middle}html{box-sizing:border-box;font-size:100%;height:100%;overflow-y:scroll}h1{font-size:2.25rem}h2{font-size:1.75rem}h1,h2,h3{font-weight:700;line-height:1.2}h3{font-size:1.5rem}body{font-size:1.125rem}*{box-sizing:inherit}p{margin-bottom:2rem;margin-top:0}p:last-of-type{margin-bottom:0}.c-ad{text-align:center}@media only screen and (min-width:480px){.c-ad{padding:8px}}.c-ad--728x90{display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:876px){.js .c-ad--728x90{display:none}}.c-ad__label,.c-status-message{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-ad__label{color:#333;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-status-message{align-items:center;box-sizing:border-box;display:flex;position:relative;width:100%}.c-status-message--boxed{background-color:#fff;border:1px solid #ccc;line-height:1.4;padding:16px}.c-status-message__heading{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-status-message :last-child{margin-bottom:0}.eds-c-button{border-radius:32px;cursor:pointer;display:inline-block;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;font-weight:700;line-height:1.5;margin:0;padding:.5rem 1.5rem;position:relative;text-align:center;text-decoration:none;transition:all .2s ease 0s;width:100%}.eds-c-button span,.eds-c-button svg{vertical-align:middle}.eds-c-button svg{height:1.5rem;width:1.5rem}.eds-c-button svg:first-child{margin-right:8px}@media only screen and (min-width:480px){.eds-c-button{width:auto}}.eds-c-button--primary{background-color:#025e8d;background-image:none;border:2px solid transparent;box-shadow:none;color:#fff;text-decoration:none}.eds-c-button--primary svg{fill:currentcolor}.eds-c-header{background-color:#fff;border-bottom:2px solid #01324b;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;line-height:1.5;padding:8px 0 0}.eds-c-header__container{align-items:center;display:flex;flex-wrap:nowrap;gap:8px 16px;justify-content:space-between;margin:0 auto 8px;max-width:1280px;padding:0 8px;position:relative}.eds-c-header__nav{border-top:2px solid #c5e0f4;padding-top:4px;position:relative}.eds-c-header__nav-container{align-items:center;display:flex;flex-wrap:wrap;margin:0 auto 4px;max-width:1280px;padding:0 8px;position:relative}.eds-c-header__nav-container>:not(:last-child){margin-right:32px}.eds-c-header__link-container{align-items:center;display:flex;flex:1 0 auto;gap:8px 16px;justify-content:space-between}.eds-c-header__list{list-style:none;margin:0;padding:0}.eds-c-header__list-item{font-weight:700;margin:0 auto;max-width:1280px;padding:8px}.eds-c-header__list-item:not(:last-child){border-bottom:2px solid #c5e0f4}.eds-c-header__item{color:inherit}@media only screen and (min-width:768px){.eds-c-header__item--menu{display:none;visibility:hidden}.eds-c-header__item--menu:first-child+*{margin-block-start:0}}.eds-c-header__item--inline-links{display:none;visibility:hidden}@media only screen and (min-width:768px){.eds-c-header__item--inline-links{display:flex;gap:16px 16px;visibility:visible}}.eds-c-header__item--divider:before{border-left:2px solid #c5e0f4;content:"";height:calc(100% - 16px);margin-left:-15px;position:absolute;top:8px}.eds-c-header__brand{padding:16px 8px}.eds-c-header__brand a{display:block;line-height:1;text-decoration:none}.eds-c-header__brand img{height:1.5rem;width:auto}.eds-c-header__link{color:inherit;display:inline-block;font-weight:700;padding:16px 8px;position:relative;text-decoration-color:transparent;white-space:nowrap;word-break:normal}.eds-c-header__icon{fill:currentcolor;display:inline-block;font-size:1.5rem;height:1em;transform:translate(0);vertical-align:bottom;width:1em}.eds-c-header__icon+*{margin-left:8px}.eds-c-header__expander{background-color:#f0f7fc}.eds-c-header__search{display:block;padding:24px 0}@media only screen and (min-width:768px){.eds-c-header__search{max-width:70%}}.eds-c-header__search-container{position:relative}.eds-c-header__search-label{color:inherit;display:inline-block;font-weight:700;margin-bottom:8px}.eds-c-header__search-input{background-color:#fff;border:1px solid #000;padding:8px 48px 8px 8px;width:100%}.eds-c-header__search-button{background-color:transparent;border:0;color:inherit;height:100%;padding:0 8px;position:absolute;right:0}.has-tethered.eds-c-header__expander{border-bottom:2px solid #01324b;left:0;margin-top:-2px;top:100%;width:100%;z-index:10}@media only screen and (min-width:768px){.has-tethered.eds-c-header__expander--menu{display:none;visibility:hidden}}.has-tethered .eds-c-header__heading{display:none;visibility:hidden}.has-tethered .eds-c-header__heading:first-child+*{margin-block-start:0}.has-tethered .eds-c-header__search{margin:auto}.eds-c-header__heading{margin:0 auto;max-width:1280px;padding:16px 16px 0}.eds-c-pagination{align-items:center;display:flex;flex-wrap:wrap;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;gap:16px 0;justify-content:center;line-height:1.4;list-style:none;margin:0;padding:32px 0}@media only screen and (min-width:480px){.eds-c-pagination{padding:32px 16px}}.eds-c-pagination__item{margin-right:8px}.eds-c-pagination__item--prev{margin-right:16px}.eds-c-pagination__item--next .eds-c-pagination__link,.eds-c-pagination__item--prev .eds-c-pagination__link{padding:16px 8px}.eds-c-pagination__item--next{margin-left:8px}.eds-c-pagination__item:last-child{margin-right:0}.eds-c-pagination__link{align-items:center;color:#222;cursor:pointer;display:inline-block;font-size:1rem;margin:0;padding:16px 24px;position:relative;text-align:center;transition:all .2s ease 0s}.eds-c-pagination__link:visited{color:#222}.eds-c-pagination__link--disabled{border-color:#555;color:#555;cursor:default}.eds-c-pagination__link--active{background-color:#01324b;background-image:none;border-radius:8px;color:#fff}.eds-c-pagination__link--active:focus,.eds-c-pagination__link--active:hover,.eds-c-pagination__link--active:visited{color:#fff}.eds-c-pagination__link-container{align-items:center;display:flex}.eds-c-pagination__icon{fill:#222;height:1.5rem;width:1.5rem}.eds-c-pagination__icon--disabled{fill:#555}.eds-c-pagination__visually-hidden{border:0;clip:rect(0,0,0,0);clip-path:inset(50%);height:1px;overflow:hidden;padding:0;position:absolute!important;white-space:nowrap;width:1px}.c-breadcrumbs{color:#333;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs>li{display:inline}svg.c-breadcrumbs__chevron{margin:0 .25rem;fill:#333;height:10px;width:10px}.c-breadcrumbs--contrast,.c-breadcrumbs--contrast .c-breadcrumbs__link{color:#fff}.c-breadcrumbs--contrast svg.c-breadcrumbs__chevron{fill:#fff}@media only screen and (max-width:479px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-skip-link{background:#01324b;bottom:auto;color:#fff;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);width:100%;z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:active,.c-skip-link:hover,.c-skip-link:link,.c-skip-link:visited{color:#fff}.c-skip-link:focus{transform:translateY(0)}.l-with-sidebar{display:flex;flex-wrap:wrap}.l-with-sidebar>*{margin:0}.l-with-sidebar__sidebar{flex-basis:var(--with-sidebar--basis,400px);flex-grow:1}.l-with-sidebar>:not(.l-with-sidebar__sidebar){flex-basis:0px;flex-grow:999;min-width:var(--with-sidebar--min,53%)}.l-with-sidebar>:first-child{padding-right:4rem}@supports (gap:1em){.l-with-sidebar>:first-child{padding-right:0}.l-with-sidebar{gap:var(--with-sidebar--gap,4rem)}}.c-header__link{color:inherit;display:inline-block;font-weight:700;padding:16px 8px;position:relative;text-decoration-color:transparent;white-space:nowrap;word-break:normal}.app-masthead__colour-4{--background-color:#ff9500;--gradient-light:rgba(0,0,0,.5);--gradient-dark:rgba(0,0,0,.8)}.app-masthead{background:var(--background-color,#0070a8);position:relative}.app-masthead:after{background:radial-gradient(circle at top right,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)));bottom:0;content:"";left:0;position:absolute;right:0;top:0}@media only screen and (max-width:479px){.app-masthead:after{background:linear-gradient(225deg,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)))}}.app-masthead__container{color:var(--masthead-color,#fff);margin:0 auto;max-width:1280px;padding:0 16px;position:relative;z-index:1}.u-clear-both{clear:both}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-visually-hidden{border:0;clip:rect(0,0,0,0);clip-path:inset(50%);height:1px;overflow:hidden;padding:0;position:absolute!important;white-space:nowrap;width:1px}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-ma-16{margin:16px}.u-mt-0{margin-top:0}.u-mt-24{margin-top:24px}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-32{margin-bottom:32px}.u-sans-serif{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.u-serif{font-family:Merriweather,serif}h1,h2,h3{-webkit-font-smoothing:antialiased}p{overflow-wrap:break-word;word-break:break-word}.u-h4{font-size:1.25rem;font-weight:700;line-height:1.2}.u-mbs-0{margin-block-start:0!important}.c-article-header{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;padding:0}.c-article-identifiers__item{list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{margin-right:0;padding-right:0}@media only screen and (min-width:876px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:767px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#025e8d;border-color:transparent;color:#fff}.c-article-body .c-article-access-provider{padding:8px 16px}.c-article-body .c-article-access-provider,.c-notes{border:1px solid #d5d5d5;border-image:initial;border-left:none;border-right:none;margin:24px 0}.c-article-body .c-article-access-provider__text{color:#555}.c-article-body .c-article-access-provider__text,.c-notes__text{font-size:1rem;margin-bottom:0;padding-bottom:2px;padding-top:2px;text-align:center}.c-article-body .c-article-author-affiliation__address{color:inherit;font-weight:700;margin:0}.c-article-body .c-article-author-affiliation__authors-list{list-style:none;margin:0;padding:0}.c-article-body .c-article-author-affiliation__authors-item{display:inline;margin-left:0}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-body .c-article-subject-list--no-mb{margin-bottom:0}.c-code-block{border:1px solid #fff;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;margin-bottom:24px}.c-article-share-box__description{font-size:1rem;margin-bottom:8px}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__additional-info{color:#626262;font-size:.813rem}.c-article-share-box__button{background:#fff;box-sizing:content-box;text-align:center}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#025e8d;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{font-size:1rem}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;font-size:1.25rem;font-weight:700;line-height:1.2;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-article-section__figure-caption{display:block;margin-bottom:8px;word-break:break-word}.c-article-section__figure .video,p.app-article-masthead__access--above-download{margin:0 0 16px}.c-cod{display:block;font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#025e8d;border:1px solid #025e8d;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#025e8d}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px}.c-pdf-download__link:hover{text-decoration:none}@media only screen and (min-width:768px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.c-article-body .c-article-recommendations-list,.c-book-body .c-article-recommendations-list{display:flex;flex-direction:row;gap:16px 16px;margin:0;max-width:100%;padding:16px 0 0}.c-article-body .c-article-recommendations-list__item,.c-book-body .c-article-recommendations-list__item{flex:1 1 0%}@media only screen and (max-width:767px){.c-article-body .c-article-recommendations-list,.c-book-body .c-article-recommendations-list{flex-direction:column}}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:767px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-body .c-article-history{margin-top:24px}.app-article-metrics-bar p{margin:0}.app-article-masthead{display:flex;flex-direction:column;gap:16px 16px;padding:16px 0 24px}.app-article-masthead__info{display:flex;flex-direction:column;flex-grow:1}.app-article-masthead__brand{border-top:1px solid hsla(0,0%,100%,.8);display:flex;flex-direction:column;flex-shrink:0;gap:8px 8px;min-height:96px;padding:16px 0 0}.app-article-masthead__brand img{border:1px solid #fff;border-radius:8px;box-shadow:0 4px 15px 0 hsla(0,0%,50%,.25);height:auto;left:0;position:absolute;width:72px}.app-article-masthead__journal-link{display:block;font-size:1.125rem;font-weight:700;margin:0 0 8px;max-width:400px;padding:0 0 0 88px;position:relative}.app-article-masthead__journal-title{display:-webkit-box;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:3}.app-article-masthead__submission-link{align-items:center;display:flex;font-size:1rem;gap:4px 4px;margin:0 0 0 88px}.app-article-masthead__access{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;font-weight:300;gap:4px 4px;margin:0}.app-article-masthead__buttons{display:flex;flex-flow:column wrap;gap:16px 16px}.app-article-masthead__access svg{fill:currentcolor}.app-article-masthead a{color:#fff}.app-article-masthead a.c-pdf-download__link,.app-article-masthead__syndicated-card a,.app-article-masthead__syndicated-card a:visited,.app-masthead--pastel .app-article-masthead a,.app-masthead--pastel .app-article-masthead a:visited{color:#000}.app-masthead--pastel .c-pdf-download a.u-button--primary,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--primary{background-color:#025e8d;border:2px solid transparent;box-shadow:none;color:#fff;font-weight:700}.app-masthead--pastel .c-pdf-download a.u-button--primary:focus,.app-masthead--pastel .c-pdf-download a.u-button--primary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--primary:focus,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--primary:hover{background:0 0;border:2px solid #025e8d;box-shadow:none;color:#025e8d}.app-masthead--pastel .c-pdf-download a.u-button--secondary,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--secondary{background:0 0;border:2px solid #025e8d;color:#025e8d}.app-masthead--pastel .c-pdf-download a.u-button--secondary:focus,.app-masthead--pastel .c-pdf-download a.u-button--secondary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--secondary:focus,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--secondary:hover{background-color:#025e8d;border:2px solid transparent;color:#fff}@media only screen and (min-width:768px){.app-article-masthead{flex-direction:row;gap:64px 64px;padding:24px 0}.app-article-masthead__brand{border:0;padding:0}.app-article-masthead__brand img{height:auto;position:static;width:auto}.app-article-masthead__buttons{align-items:center;flex-direction:row;margin-top:auto}.app-article-masthead__journal-link{display:flex;flex-direction:column;gap:24px 24px;margin:0 0 8px;padding:0}.app-article-masthead__submission-link{margin:0}}@media only screen and (min-width:1024px){.app-article-masthead__brand{flex-basis:400px}}.app-article-masthead .c-article-identifiers{font-size:.875rem;font-weight:300;line-height:1;margin:0 0 8px;overflow:hidden;padding:0}.app-article-masthead .c-article-identifiers--cite-list{margin:0 0 16px}.app-article-masthead .c-article-identifiers *{color:#fff}.app-article-masthead .c-cod{display:none}.app-article-masthead .c-article-identifiers__item{border-left:1px solid #fff;border-right:0;margin:0 17px 8px -9px;padding:0 0 0 8px}.app-article-masthead .c-article-identifiers__item--cite{border-left:0}.app-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;padding:16px 0 0;row-gap:24px}.app-article-metrics-bar__item{padding:0 16px 0 0}.app-article-metrics-bar__count{font-weight:700}.app-article-metrics-bar__label{font-weight:400;padding-left:4px}.app-article-metrics-bar__icon{height:auto;margin-right:4px;margin-top:-4px;width:auto}.app-article-metrics-bar__arrow-icon{margin:4px 0 0 4px}.app-article-metrics-bar a{color:#000}.app-article-metrics-bar .app-article-metrics-bar__item--metrics{padding-right:0}.app-overview-section .c-article-author-list,.app-overview-section__authors{line-height:2}.app-article-metrics-bar{margin-top:8px}.c-book-toc-pagination+.c-book-section__back-to-top{margin-top:0}.c-article-body .c-article-access-provider__text--chapter{color:#222;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;padding:20px 0}.c-article-body .c-article-access-provider__text--chapter svg.c-status-message__icon{fill:#003f8d;vertical-align:middle}.c-article-body-section__content--separator{padding-top:40px}.c-pdf-download__link{max-height:44px}.app-article-access .u-button--primary,.app-article-access .u-button--primary:visited{color:#fff}.c-article-authors-search__list{align-items:center;display:flex;flex-wrap:wrap;gap:16px 16px;justify-content:center}@media only screen and (min-width:480px){.c-article-authors-search__list{justify-content:normal}}.c-article-authors-search__text{align-items:center;display:flex;flex-flow:column wrap;font-size:14px;justify-content:center}@media only screen and (min-width:480px){.c-article-authors-search__text{flex-direction:row;font-size:16px}}.c-article-authors-search__links-text{font-weight:700;margin-right:8px;text-align:center}@media only screen and (min-width:480px){.c-article-authors-search__links-text{text-align:left}}.c-article-authors-search__list-item--left{flex:1 1 100%}@media only screen and (min-width:480px){.c-article-authors-search__list-item--left{flex-basis:auto}}.c-article-authors-search__list-item--right{flex:1 1 auto}.c-article-identifiers{margin:0}.c-article-identifiers__item{border-right:2px solid #cedbe0;color:#222;font-size:14px}@media only screen and (min-width:480px){.c-article-identifiers__item{font-size:16px}}.c-article-identifiers__item:last-child{border-right:none}.c-article-authors-search__cta-link{font-size:14px}@media only screen and (min-width:480px){.c-article-authors-search__cta-link{font-size:16px}}.c-article-sidebar{display:none}@media only screen and (min-width:1024px){.c-article-sidebar{display:block}}.c-cod__form{border-radius:12px}.c-cod__label{font-size:.875rem}.c-cod .c-status-message{align-items:center;justify-content:center;margin-bottom:16px;padding-bottom:16px}@media only screen and (min-width:1024px){.c-cod .c-status-message{align-items:inherit}}.c-cod .c-status-message__icon{margin-top:4px}.c-cod .c-cod__prompt{font-size:1rem;margin-bottom:16px}.c-spp-access-message .c-status-message__icon{color:#00a69d;margin-top:8px}.c-article-body .app-article-access,.c-book-body .app-article-access{display:block}@media only screen and (min-width:1024px){.c-article-body .app-article-access,.c-book-body .app-article-access{display:none}}.c-article-body .app-card-service{margin-bottom:32px}@media only screen and (min-width:1024px){.c-article-body .app-card-service{display:none}}.app-article-access .buybox__buy .u-button--secondary,.app-article-access .u-button--primary,.c-cod__row .u-button--primary{background-color:#025e8d;border:2px solid #025e8d;box-shadow:none;font-size:1rem;font-weight:700;gap:8px 8px;justify-content:center;line-height:1.4;padding:8px 24px}.app-article-access .buybox__buy .u-button--secondary,.app-article-access .u-button--primary:hover,.c-cod__row .u-button--primary:hover{background-color:#fff;color:#025e8d}.app-article-access .buybox__buy .u-button--secondary:hover{background-color:#025e8d;color:#fff}.buybox__buy .c-notes__text{color:#666;font-size:.875rem;padding:0 16px 8px}.c-cod__input{flex-basis:auto;width:100%}.c-article-title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:2.25rem;font-weight:700;line-height:1.2;margin:12px 0}.c-reading-companion__figure-item figure{margin:0}@media only screen and (min-width:768px){.c-article-title{margin:16px 0}}.app-article-access{border:1px solid #cedbe0;border-radius:12px;margin:0 0 32px}.app-article-access__heading{border-bottom:1px solid #cedbe0;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1.125rem;font-weight:700;margin:0;padding:16px;text-align:center}.c-article-body .app-article-access p{margin-bottom:0}@media only screen and (min-width:1024px){.app-article-access{margin:0 0 24px}}.c-status-message{font-size:1rem}.c-article-body{font-size:1.125rem}.c-article-body dl,.c-article-body ol,.c-article-body p,.c-article-body ul{margin-bottom:32px;margin-top:0}.c-article-access-provider__text:last-of-type,.c-article-body .c-notes__text:last-of-type{margin-bottom:0}.c-article-body ol p,.c-article-body ul p{margin-bottom:16px}.c-article-section__figure-caption{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-reading-companion__figure-item{border-top-color:#cedbe0}.c-reading-companion__sticky{max-width:400px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;padding:16px 0}.c-reading-companion__reference-item:first-child{padding-top:0}.c-article-share-box__button,.js .c-article-authors-search__item .c-article-button{background:0 0;border:2px solid #025e8d;border-radius:32px;box-shadow:none;color:#025e8d;font-size:1rem;font-weight:700;line-height:1.4;margin:0;padding:8px 24px;transition:all .2s ease 0s}.c-article-authors-search__item .c-article-button{width:100%}.c-pdf-download .c-pdf-download__link{align-items:center;background-color:#fff;border:2px solid #fff;border-radius:32px;box-shadow:none;color:#01324b;cursor:pointer;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;font-weight:700;justify-content:center;line-height:1.4;padding:8px 24px;text-decoration:none}.c-context-bar__container .c-pdf-download .c-pdf-download__link{background-color:#025e8d;background-image:none;border:2px solid #025e8d;box-shadow:none;color:#fff;font-size:1rem;font-weight:700;line-height:1.4;padding:8px 24px}.c-pdf-download .c-pdf-download__link:hover{background:0 0;border:2px solid #fff;box-shadow:none;color:#fff}.c-pdf-download .c-pdf-download__link:focus{background:0 0;box-shadow:none;color:#fff}.c-context-bar__container .c-pdf-download .c-pdf-download__link:hover{border:2px solid #025e8d;box-shadow:none;color:#025e8d}.c-context-bar__container .c-pdf-download .c-pdf-download__link:focus,.c-pdf-download .c-pdf-download__link:focus{border:2px solid #025e8d}.c-article-share-box__button:focus:focus,.c-article__pill-button:focus:focus,.c-context-bar__container .c-pdf-download .c-pdf-download__link:focus:focus,.c-pdf-download .c-pdf-download__link:focus:focus{outline:3px solid #08c;will-change:transform}.c-pdf-download__link .u-icon{padding-top:0}.c-bibliographic-information__column button{margin-bottom:16px}.c-article-body .c-article-author-affiliation__list p,.c-article-body .c-article-author-information__list p,figure{margin:0}.c-article-share-box__button{margin-right:16px}.c-status-message--boxed{border-radius:12px}.c-article-associated-content__collection-title{font-size:1rem}.app-card-service__description,.c-article-body .app-card-service__description{color:#222;margin-bottom:0;margin-top:8px}.app-article-access__subscriptions a,.app-article-access__subscriptions a:visited,.app-book-series-listing__item a,.app-book-series-listing__item a:hover,.app-book-series-listing__item a:visited,.c-article-author-list a,.c-article-author-list a:visited,.c-article-buy-box a,.c-article-buy-box a:visited,.c-article-peer-review a,.c-article-peer-review a:visited,.c-article-satellite-subtitle a,.c-article-satellite-subtitle a:visited,.c-breadcrumbs__link,.c-breadcrumbs__link:hover,.c-breadcrumbs__link:visited{color:#000}.c-article-author-list svg{height:24px;margin:0 0 0 6px;width:24px}.c-article-header{margin-bottom:32px}@media only screen and (min-width:876px){.js .c-ad--conditional{display:block}}.u-lazy-ad-wrapper{background-color:#fff;display:none;min-height:149px}@media only screen and (min-width:876px){.u-lazy-ad-wrapper{display:block}}p.c-ad__label{margin-bottom:4px}.c-ad--728x90{background-color:#fff;border-bottom:2px solid #cedbe0} } </style>
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .eds-c-header__brand img{height:24px;width:203px}.app-article-masthead__journal-link img{height:93px;width:72px}@media only screen and (min-width:769px){.app-article-masthead__journal-link img{height:161px;width:122px}} } </style>

        
        <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href=/oscar-static/app-springerlink/css/core-darwin-9fe647df8f.css media="print" onload="this.media='all';this.onload=null">
        <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/enhanced-darwin-article-069c6c9d0b.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    

        
        
    <script type="text/javascript">
        config = {
            env: 'live',
            site: '10551.springer.com',
            siteWithPath: '10551.springer.com' + window.location.pathname,
            twitterHashtag: '10551',
            cmsPrefix: 'https://studio-cms.springernature.com/studio/',
            
            
            
            
            publisherBrand: 'Springer',
            mustardcut: false
        };
    </script>

        




    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/s10551-023-05339-7","Page":"article","springerJournal":true,"Publishing Model":"Hybrid Access","Country":"GB","japan":false,"doi":"10.1007-s10551-023-05339-7","Journal Id":10551,"Journal Title":"Journal of Business Ethics","imprint":"Springer","Keywords":"Meaningful work, Artificial intelligence (AI), Ethical AI, Future of work, Technology and work","kwrd":["Meaningful_work","Artificial_intelligence_(AI)","Ethical_AI","Future_of_work","Technology_and_work"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"open","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"vgzm.415900-10.1007-s10551-023-05339-7","Full HTML":"Y","Subject Codes":["SCE","SCE14000","SC500000","SC515000","SC526000","SCX23000"],"pmc":["E","E14000","500000","515000","526000","X23000"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"entitlement":{"accessDecision":"OpenAccess"},"content":{"serial":{"eissn":"1573-0697","pissn":"0167-4544"},"type":"Article","category":{"pmc":{"primarySubject":"Philosophy","primarySubjectCode":"E","secondarySubjects":{"1":"Ethics","2":"Business and Management, general","3":"Management","4":"Business Ethics","5":"Quality of Life Research"},"secondarySubjectCodes":{"1":"E14000","2":"500000","3":"515000","4":"526000","5":"X23000"}},"sucode":"SC21","articleType":"Original Paper","snt":["Philosophy of Artificial Intelligence","Computer Ethics","Ethics of Technology","Engineering Ethics","Information Ethics","Digital Ethics"]},"attributes":{"deliveryPlatform":"oscar"}},"page":{"attributes":{"environment":"live"},"category":{"pageType":"article"}},"Event Category":"Article"}];
    </script>











    <script data-test="springer-link-article-datalayer">
        window.dataLayer = window.dataLayer || [];
        window.dataLayer.push({
            ga4MeasurementId: 'G-B3E4QL2TPR',
            ga360TrackingId: 'UA-26408784-1',
            twitterId: 'o47a7',
            baiduId: 'aef3043f025ccf2305af8a194652d70b',
            ga4ServerUrl: 'https://collect.springer.com',
            imprint: 'springerlink',
                page: {
                    attributes:{
                        featureFlags: [
                            
                                { name: 'darwin-orion', active: true },
                            
                                { name: 'show-profile-page-links', active: true },
                            
                        ],
                        darwinAvailable: true
                    }
                }
            
        });
    </script>



        <script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>


        <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
                window.onArticlePage = true;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-b4356fa7f5.js', 'async': false}
            ];

            var bodyScripts = [
                
                    
                    {'src': '/oscar-static/js/global-article-es5-bundle-c7bdbee6e7.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-8cfe1d6fdf.js', 'async': false, 'module': true}
                    
                
                
                    
                
                
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>



        
            
            
                
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                    j = d.createElement(s),
                    dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://sgtm.springer.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
                performance.mark('SN GPT Ads gtm-container-fired');
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>

            
            
            
        

        <script>
(function (w, d, t) {
    function cc() {
        var h = w.location.hostname;
        var e = d.createElement(t),
        s = d.getElementsByTagName(t)[0];

        
        if (h.indexOf('springer.com') > -1 && h.indexOf('biomedcentral.com') === -1 && h.indexOf('springeropen.com') === -1) {
            e.src = 'https://cmp.springer.com/production_live/en/consent-bundle-17-70.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
        } else if (h.indexOf('biomedcentral.com') > -1) {
            e.src = 'https://cmp.biomedcentral.com/production_live/en/consent-bundle-15-45.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
        } else if (h.indexOf('springeropen.com') > -1) {
            e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-16-40.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
        } else if (h.indexOf('springernature.com') > -1) {
            e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-49-43.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-NK22KLS')");
        } else {
            e.src = '/oscar-static/js/cookie-consent-es5-bundle-8d962b73c2.js';
            e.setAttribute('data-consent', h);
        }
        s.insertAdjacentElement('afterend', e);
    }

    cc();
})(window, document, 'script');
</script>


        
        
        
    
        
    

        
    
    <link rel="canonical" href="https://link.springer.com/article/10.1007/s10551-023-05339-7"/>
    

        
        
        
        
        
    <script type="application/ld+json">{"mainEntity":{"headline":"The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work","description":"The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one’s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees’ experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, ‘tending the machine’, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions.\n","datePublished":"2023-02-11T00:00:00Z","dateModified":"2023-02-27T00:00:00Z","pageStart":"725","pageEnd":"740","license":"http://creativecommons.org/licenses/by/4.0/","sameAs":"https://doi.org/10.1007/s10551-023-05339-7","keywords":["Meaningful work","Artificial intelligence (AI)","Ethical AI","Future of work","Technology and work","Ethics","Business and Management","general","Management","Business Ethics","Quality of Life Research"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs10551-023-05339-7/MediaObjects/10551_2023_5339_Fig1_HTML.png"],"isPartOf":{"name":"Journal of Business Ethics","issn":["1573-0697","0167-4544"],"volumeNumber":"185","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Springer Netherlands","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Sarah Bankins","url":"http://orcid.org/0000-0003-2290-3086","affiliation":[{"name":"Macquarie University","address":{"name":"Department of Management, Macquarie Business School, Macquarie University, Sydney, Australia","@type":"PostalAddress"},"@type":"Organization"}],"email":"sarah.bankins@mq.edu.au","@type":"Person"},{"name":"Paul Formosa","affiliation":[{"name":"Macquarie University","address":{"name":"Department of Philosophy, Faculty of Arts, Macquarie University, Sydney, Australia","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>

        
        
    </head>

    <body class=""
    
          >
        <div class="u-visually-hidden" aria-hidden="true" data-test="darwin-icons">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><symbol id="icon-eds-i-accesses-medium" viewBox="0 0 24 24"><path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742H15a1 1 0 0 1 0-2h4.455a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM8 13c2.052 0 4.66 1.61 6.36 3.4l.124.141c.333.41.516.925.516 1.459 0 .6-.232 1.178-.64 1.599C12.666 21.388 10.054 23 8 23c-2.052 0-4.66-1.61-6.353-3.393A2.31 2.31 0 0 1 1 18c0-.6.232-1.178.64-1.6C3.34 14.61 5.948 13 8 13Zm0 2c-1.369 0-3.552 1.348-4.917 2.785A.31.31 0 0 0 3 18c0 .083.031.161.09.222C4.447 19.652 6.631 21 8 21c1.37 0 3.556-1.35 4.917-2.785A.31.31 0 0 0 13 18a.32.32 0 0 0-.048-.17l-.042-.052C11.553 16.348 9.369 15 8 15Zm0 1a2 2 0 1 1 0 4 2 2 0 0 1 0-4Z"/></symbol><symbol id="icon-eds-i-altmetric-medium" viewBox="0 0 24 24"><path d="M12 1c5.978 0 10.843 4.77 10.996 10.712l.004.306-.002.022-.002.248C22.843 18.23 17.978 23 12 23 5.925 23 1 18.075 1 12S5.925 1 12 1Zm-1.726 9.246L8.848 12.53a1 1 0 0 1-.718.461L8.003 13l-4.947.014a9.001 9.001 0 0 0 17.887-.001L16.553 13l-2.205 3.53a1 1 0 0 1-1.735-.068l-.05-.11-2.289-6.106ZM12 3a9.001 9.001 0 0 0-8.947 8.013l4.391-.012L9.652 7.47a1 1 0 0 1 1.784.179l2.288 6.104 1.428-2.283a1 1 0 0 1 .722-.462l.129-.008 4.943.012A9.001 9.001 0 0 0 12 3Z"/></symbol><symbol id="icon-eds-i-arrow-bend-down-medium" viewBox="0 0 24 24"><path d="m11.852 20.989.058.007L12 21l.075-.003.126-.017.111-.03.111-.044.098-.052.104-.074.082-.073 6-6a1 1 0 0 0-1.414-1.414L13 17.585v-12.2C13 4.075 11.964 3 10.667 3H4a1 1 0 1 0 0 2h6.667c.175 0 .333.164.333.385v12.2l-4.293-4.292a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414l6 6c.035.036.073.068.112.097l.11.071.114.054.105.035.118.025Z"/></symbol><symbol id="icon-eds-i-arrow-bend-down-small" viewBox="0 0 16 16"><path d="M1 2a1 1 0 0 0 1 1h5v8.585L3.707 8.293a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414l5 5 .063.059.093.069.081.048.105.048.104.035.105.022.096.01h.136l.122-.018.113-.03.103-.04.1-.053.102-.07.052-.043 5.04-5.037a1 1 0 1 0-1.415-1.414L9 11.583V3a2 2 0 0 0-2-2H2a1 1 0 0 0-1 1Z"/></symbol><symbol id="icon-eds-i-arrow-bend-up-medium" viewBox="0 0 24 24"><path d="m11.852 3.011.058-.007L12 3l.075.003.126.017.111.03.111.044.098.052.104.074.082.073 6 6a1 1 0 1 1-1.414 1.414L13 6.415v12.2C13 19.925 11.964 21 10.667 21H4a1 1 0 0 1 0-2h6.667c.175 0 .333-.164.333-.385v-12.2l-4.293 4.292a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l6-6c.035-.036.073-.068.112-.097l.11-.071.114-.054.105-.035.118-.025Z"/></symbol><symbol id="icon-eds-i-arrow-bend-up-small" viewBox="0 0 16 16"><path d="M1 13.998a1 1 0 0 1 1-1h5V4.413L3.707 7.705a1 1 0 0 1-1.32.084l-.094-.084a1 1 0 0 1 0-1.414l5-5 .063-.059.093-.068.081-.05.105-.047.104-.035.105-.022L7.94 1l.136.001.122.017.113.03.103.04.1.053.102.07.052.043 5.04 5.037a1 1 0 1 1-1.415 1.414L9 4.415v8.583a2 2 0 0 1-2 2H2a1 1 0 0 1-1-1Z"/></symbol><symbol id="icon-eds-i-arrow-diagonal-medium" viewBox="0 0 24 24"><path d="M14 3h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L21 4v6a1 1 0 0 1-2 0V6.414l-4.293 4.293a1 1 0 0 1-1.414-1.414L17.584 5H14a1 1 0 0 1-.993-.883L13 4a1 1 0 0 1 1-1ZM4 13a1 1 0 0 1 1 1v3.584l4.293-4.291a1 1 0 1 1 1.414 1.414L6.414 19H10a1 1 0 0 1 .993.883L11 20a1 1 0 0 1-1 1l-6.075-.003-.126-.017-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08a1.01 1.01 0 0 1-.097-.112l-.071-.11-.054-.114-.035-.105-.025-.118-.007-.058L3 20v-6a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-arrow-diagonal-small" viewBox="0 0 16 16"><path d="m2 15-.082-.004-.119-.016-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08a1.008 1.008 0 0 1-.097-.112l-.071-.11-.031-.062-.034-.081-.024-.076-.025-.118-.007-.058L1 14.02V9a1 1 0 1 1 2 0v2.584l2.793-2.791a1 1 0 1 1 1.414 1.414L4.414 13H7a1 1 0 0 1 .993.883L8 14a1 1 0 0 1-1 1H2ZM14 1l.081.003.12.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.031.062.034.081.024.076.03.148L15 2v5a1 1 0 0 1-2 0V4.414l-2.96 2.96A1 1 0 1 1 8.626 5.96L11.584 3H9a1 1 0 0 1-.993-.883L8 2a1 1 0 0 1 1-1h5Z"/></symbol><symbol id="icon-eds-i-arrow-down-medium" viewBox="0 0 24 24"><path d="m20.707 12.728-7.99 7.98a.996.996 0 0 1-.561.281l-.157.011a.998.998 0 0 1-.788-.384l-7.918-7.908a1 1 0 0 1 1.414-1.416L11 17.576V4a1 1 0 0 1 2 0v13.598l6.293-6.285a1 1 0 0 1 1.32-.082l.095.083a1 1 0 0 1-.001 1.414Z"/></symbol><symbol id="icon-eds-i-arrow-down-small" viewBox="0 0 16 16"><path d="m1.293 8.707 6 6 .063.059.093.069.081.048.105.049.104.034.056.013.118.017L8 15l.076-.003.122-.017.113-.03.085-.032.063-.03.098-.058.06-.043.05-.043 6.04-6.037a1 1 0 0 0-1.414-1.414L9 11.583V2a1 1 0 1 0-2 0v9.585L2.707 7.293a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414Z"/></symbol><symbol id="icon-eds-i-arrow-left-medium" viewBox="0 0 24 24"><path d="m11.272 3.293-7.98 7.99a.996.996 0 0 0-.281.561L3 12.001c0 .32.15.605.384.788l7.908 7.918a1 1 0 0 0 1.416-1.414L6.424 13H20a1 1 0 0 0 0-2H6.402l6.285-6.293a1 1 0 0 0 .082-1.32l-.083-.095a1 1 0 0 0-1.414.001Z"/></symbol><symbol id="icon-eds-i-arrow-left-small" viewBox="0 0 16 16"><path d="m7.293 1.293-6 6-.059.063-.069.093-.048.081-.049.105-.034.104-.013.056-.017.118L1 8l.003.076.017.122.03.113.032.085.03.063.058.098.043.06.043.05 6.037 6.04a1 1 0 0 0 1.414-1.414L4.417 9H14a1 1 0 0 0 0-2H4.415l4.292-4.293a1 1 0 0 0 .083-1.32l-.083-.094a1 1 0 0 0-1.414 0Z"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-arrow-right-small" viewBox="0 0 16 16"><path d="m8.707 1.293 6 6 .059.063.069.093.048.081.049.105.034.104.013.056.017.118L15 8l-.003.076-.017.122-.03.113-.032.085-.03.063-.058.098-.043.06-.043.05-6.037 6.04a1 1 0 0 1-1.414-1.414L11.583 9H2a1 1 0 1 1 0-2h9.585L7.293 2.707a1 1 0 0 1-.083-1.32l.083-.094a1 1 0 0 1 1.414 0Z"/></symbol><symbol id="icon-eds-i-arrow-up-medium" viewBox="0 0 24 24"><path d="m3.293 11.272 7.99-7.98a.996.996 0 0 1 .561-.281L12.001 3c.32 0 .605.15.788.384l7.918 7.908a1 1 0 0 1-1.414 1.416L13 6.424V20a1 1 0 0 1-2 0V6.402l-6.293 6.285a1 1 0 0 1-1.32.082l-.095-.083a1 1 0 0 1 .001-1.414Z"/></symbol><symbol id="icon-eds-i-arrow-up-small" viewBox="0 0 16 16"><path d="m1.293 7.293 6-6 .063-.059.093-.069.081-.048.105-.049.104-.034.056-.013.118-.017L8 1l.076.003.122.017.113.03.085.032.063.03.098.058.06.043.05.043 6.04 6.037a1 1 0 0 1-1.414 1.414L9 4.417V14a1 1 0 0 1-2 0V4.415L2.707 8.707a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414Z"/></symbol><symbol id="icon-eds-i-article-medium" viewBox="0 0 24 24"><path d="M8 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H8ZM8 11a1 1 0 1 0 0 2h8a1 1 0 1 0 0-2H8ZM7 16a1 1 0 0 1 1-1h8a1 1 0 1 1 0 2H8a1 1 0 0 1-1-1Z"/><path d="M5.545 1A2.542 2.542 0 0 0 3 3.538v16.924A2.542 2.542 0 0 0 5.545 23h12.91A2.542 2.542 0 0 0 21 20.462V3.5A2.5 2.5 0 0 0 18.5 1H5.545ZM5 3.538C5 3.245 5.24 3 5.545 3H18.5a.5.5 0 0 1 .5.5v16.962c0 .293-.24.538-.546.538H5.545A.542.542 0 0 1 5 20.462V3.538Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-book-medium" viewBox="0 0 24 24"><path d="M18.5 1A2.5 2.5 0 0 1 21 3.5v12c0 1.16-.79 2.135-1.86 2.418l-.14.031V21h1a1 1 0 0 1 .993.883L21 22a1 1 0 0 1-1 1H6.5A3.5 3.5 0 0 1 3 19.5v-15A3.5 3.5 0 0 1 6.5 1h12ZM17 18H6.5a1.5 1.5 0 0 0-1.493 1.356L5 19.5A1.5 1.5 0 0 0 6.5 21H17v-3Zm1.5-15h-12A1.5 1.5 0 0 0 5 4.5v11.837l.054-.025a3.481 3.481 0 0 1 1.254-.307L6.5 16h12a.5.5 0 0 0 .492-.41L19 15.5v-12a.5.5 0 0 0-.5-.5ZM15 6a1 1 0 0 1 0 2H9a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M1 3.786C1 2.759 1.857 2 2.82 2H6.18c.964 0 1.82.759 1.82 1.786V4h3.168c.668 0 1.298.364 1.616.938.158-.109.333-.195.523-.252l3.216-.965c.923-.277 1.962.204 2.257 1.187l4.146 13.82c.296.984-.307 1.957-1.23 2.234l-3.217.965c-.923.277-1.962-.203-2.257-1.187L13 10.005v10.21c0 1.04-.878 1.785-1.834 1.785H7.833c-.291 0-.575-.07-.83-.195A1.849 1.849 0 0 1 6.18 22H2.821C1.857 22 1 21.241 1 20.214V3.786ZM3 4v11h3V4H3Zm0 16v-3h3v3H3Zm15.075-.04-.814-2.712 2.874-.862.813 2.712-2.873.862Zm1.485-5.49-2.874.862-2.634-8.782 2.873-.862 2.635 8.782ZM8 20V6h3v14H8Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-calendar-acceptance-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-.534 7.747a1 1 0 0 1 .094 1.412l-4.846 5.538a1 1 0 0 1-1.352.141l-2.77-2.076a1 1 0 0 1 1.2-1.6l2.027 1.519 4.236-4.84a1 1 0 0 1 1.411-.094ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-date-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1ZM8 15a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm-4-4a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-decision-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-2.935 8.246 2.686 2.645c.34.335.34.883 0 1.218l-2.686 2.645a.858.858 0 0 1-1.213-.009.854.854 0 0 1 .009-1.21l1.05-1.035H7.984a.992.992 0 0 1-.984-1c0-.552.44-1 .984-1h5.928l-1.051-1.036a.854.854 0 0 1-.085-1.121l.076-.088a.858.858 0 0 1 1.213-.009ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-impact-factor-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-3.2 6.924a.48.48 0 0 1 .125.544l-1.52 3.283h2.304c.27 0 .491.215.491.483a.477.477 0 0 1-.13.327l-4.18 4.484a.498.498 0 0 1-.69.031.48.48 0 0 1-.125-.544l1.52-3.284H9.291a.487.487 0 0 1-.491-.482c0-.121.047-.238.13-.327l4.18-4.484a.498.498 0 0 1 .69-.031ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-call-papers-medium" viewBox="0 0 24 24"><g><path d="m20.707 2.883-1.414 1.414a1 1 0 0 0 1.414 1.414l1.414-1.414a1 1 0 0 0-1.414-1.414Z"/><path d="M6 16.054c0 2.026 1.052 2.943 3 2.943a1 1 0 1 1 0 2c-2.996 0-5-1.746-5-4.943v-1.227a4.068 4.068 0 0 1-1.83-1.189 4.553 4.553 0 0 1-.87-1.455 4.868 4.868 0 0 1-.3-1.686c0-1.17.417-2.298 1.17-3.14.38-.426.834-.767 1.338-1 .51-.237 1.06-.36 1.617-.36L6.632 6H7l7.932-2.895A2.363 2.363 0 0 1 18 5.36v9.28a2.36 2.36 0 0 1-3.069 2.25l.084.03L7 14.997H6v1.057Zm9.637-11.057a.415.415 0 0 0-.083.008L8 7.638v5.536l7.424 1.786.104.02c.035.01.072.02.109.02.2 0 .363-.16.363-.36V5.36c0-.2-.163-.363-.363-.363Zm-9.638 3h-.874a1.82 1.82 0 0 0-.625.111l-.15.063a2.128 2.128 0 0 0-.689.517c-.42.47-.661 1.123-.661 1.81 0 .34.06.678.176.992.114.308.28.585.485.816.4.447.925.691 1.464.691h.874v-5Z" clip-rule="evenodd"/><path d="M20 8.997h2a1 1 0 1 1 0 2h-2a1 1 0 1 1 0-2ZM20.707 14.293l1.414 1.414a1 1 0 0 1-1.414 1.414l-1.414-1.414a1 1 0 0 1 1.414-1.414Z"/></g></symbol><symbol id="icon-eds-i-card-medium" viewBox="0 0 24 24"><path d="M19.615 2c.315 0 .716.067 1.14.279.76.38 1.245 1.107 1.245 2.106v15.23c0 .315-.067.716-.279 1.14-.38.76-1.107 1.245-2.106 1.245H4.385a2.56 2.56 0 0 1-1.14-.279C2.485 21.341 2 20.614 2 19.615V4.385c0-.315.067-.716.279-1.14C2.659 2.485 3.386 2 4.385 2h15.23Zm0 2H4.385c-.213 0-.265.034-.317.14A.71.71 0 0 0 4 4.385v15.23c0 .213.034.265.14.317a.71.71 0 0 0 .245.068h15.23c.213 0 .265-.034.317-.14a.71.71 0 0 0 .068-.245V4.385c0-.213-.034-.265-.14-.317A.71.71 0 0 0 19.615 4ZM17 16a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h10Zm0-3a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h10Zm-.5-7A1.5 1.5 0 0 1 18 7.5v3a1.5 1.5 0 0 1-1.5 1.5h-9A1.5 1.5 0 0 1 6 10.5v-3A1.5 1.5 0 0 1 7.5 6h9ZM16 8H8v2h8V8Z"/></symbol><symbol id="icon-eds-i-cart-medium" viewBox="0 0 24 24"><path d="M5.76 1a1 1 0 0 1 .994.902L7.155 6h13.34c.18 0 .358.02.532.057l.174.045a2.5 2.5 0 0 1 1.693 3.103l-2.069 7.03c-.36 1.099-1.398 1.823-2.49 1.763H8.65c-1.272.015-2.352-.927-2.546-2.244L4.852 3H2a1 1 0 0 1-.993-.883L1 2a1 1 0 0 1 1-1h3.76Zm2.328 14.51a.555.555 0 0 0 .55.488l9.751.001a.533.533 0 0 0 .527-.357l2.059-7a.5.5 0 0 0-.48-.642H7.351l.737 7.51ZM18 19a2 2 0 1 1 0 4 2 2 0 0 1 0-4ZM8 19a2 2 0 1 1 0 4 2 2 0 0 1 0-4Z"/></symbol><symbol id="icon-eds-i-check-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm5.125 4.72a1 1 0 0 1 .156 1.405l-6 7.5a1 1 0 0 1-1.421.143l-3-2.5a1 1 0 0 1 1.28-1.536l2.217 1.846 5.362-6.703a1 1 0 0 1 1.406-.156Z"/></symbol><symbol id="icon-eds-i-check-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm5.125 6.72a1 1 0 0 0-1.406.155l-5.362 6.703-2.217-1.846a1 1 0 1 0-1.28 1.536l3 2.5a1 1 0 0 0 1.42-.143l6-7.5a1 1 0 0 0-.155-1.406Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 24 24"><path d="M3.305 8.28a1 1 0 0 0-.024 1.415l7.495 7.762c.314.345.757.543 1.224.543.467 0 .91-.198 1.204-.522l7.515-7.783a1 1 0 1 0-1.438-1.39L12 15.845l-7.28-7.54A1 1 0 0 0 3.4 8.2l-.096.082Z"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-left-medium" viewBox="0 0 24 24"><path d="M15.72 3.305a1 1 0 0 0-1.415-.024l-7.762 7.495A1.655 1.655 0 0 0 6 12c0 .467.198.91.522 1.204l7.783 7.515a1 1 0 1 0 1.39-1.438L8.155 12l7.54-7.28A1 1 0 0 0 15.8 3.4l-.082-.096Z"/></symbol><symbol id="icon-eds-i-chevron-left-small" viewBox="0 0 16 16"><path d="M10.722 2.308a1 1 0 0 0-1.414-.03L4.49 6.897a1.491 1.491 0 0 0-.019 2.188l4.838 4.637a1 1 0 1 0 1.384-1.444L6.229 8l4.463-4.278a1 1 0 0 0 .111-1.318l-.081-.096Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 24 24"><path d="M8.28 3.305a1 1 0 0 1 1.415-.024l7.762 7.495c.345.314.543.757.543 1.224 0 .467-.198.91-.522 1.204l-7.783 7.515a1 1 0 1 1-1.39-1.438L15.845 12l-7.54-7.28A1 1 0 0 1 8.2 3.4l.082-.096Z"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 16 16"><path d="M5.278 2.308a1 1 0 0 1 1.414-.03l4.819 4.619a1.491 1.491 0 0 1 .019 2.188l-4.838 4.637a1 1 0 1 1-1.384-1.444L9.771 8 5.308 3.722a1 1 0 0 1-.111-1.318l.081-.096Z"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 24 24"><path d="M20.695 15.72a1 1 0 0 0 .024-1.415l-7.495-7.762A1.655 1.655 0 0 0 12 6c-.467 0-.91.198-1.204.522l-7.515 7.783a1 1 0 1 0 1.438 1.39L12 8.155l7.28 7.54a1 1 0 0 0 1.319.106l.096-.082Z"/></symbol><symbol id="icon-eds-i-chevron-up-small" viewBox="0 0 16 16"><path d="M13.692 10.722a1 1 0 0 0 .03-1.414L9.103 4.49a1.491 1.491 0 0 0-2.188-.019L2.278 9.308a1 1 0 0 0 1.444 1.384L8 6.229l4.278 4.463a1 1 0 0 0 1.318.111l.096-.081Z"/></symbol><symbol id="icon-eds-i-citations-medium" viewBox="0 0 24 24"><path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM5.483 14.35c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Zm5 0c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Z"/></symbol><symbol id="icon-eds-i-clipboard-check-medium" viewBox="0 0 24 24"><path d="M14.4 1c1.238 0 2.274.865 2.536 2.024L18.5 3C19.886 3 21 4.14 21 5.535v14.93C21 21.86 19.886 23 18.5 23h-13C4.114 23 3 21.86 3 20.465V5.535C3 4.14 4.114 3 5.5 3h1.57c.27-1.147 1.3-2 2.53-2h4.8Zm4.115 4-1.59.024A2.601 2.601 0 0 1 14.4 7H9.6c-1.23 0-2.26-.853-2.53-2H5.5c-.27 0-.5.234-.5.535v14.93c0 .3.23.535.5.535h13c.27 0 .5-.234.5-.535V5.535c0-.3-.23-.535-.485-.535Zm-1.909 4.205a1 1 0 0 1 .19 1.401l-5.334 7a1 1 0 0 1-1.344.23l-2.667-1.75a1 1 0 1 1 1.098-1.672l1.887 1.238 4.769-6.258a1 1 0 0 1 1.401-.19ZM14.4 3H9.6a.6.6 0 0 0-.6.6v.8a.6.6 0 0 0 .6.6h4.8a.6.6 0 0 0 .6-.6v-.8a.6.6 0 0 0-.6-.6Z"/></symbol><symbol id="icon-eds-i-clipboard-report-medium" viewBox="0 0 24 24"><path d="M14.4 1c1.238 0 2.274.865 2.536 2.024L18.5 3C19.886 3 21 4.14 21 5.535v14.93C21 21.86 19.886 23 18.5 23h-13C4.114 23 3 21.86 3 20.465V5.535C3 4.14 4.114 3 5.5 3h1.57c.27-1.147 1.3-2 2.53-2h4.8Zm4.115 4-1.59.024A2.601 2.601 0 0 1 14.4 7H9.6c-1.23 0-2.26-.853-2.53-2H5.5c-.27 0-.5.234-.5.535v14.93c0 .3.23.535.5.535h13c.27 0 .5-.234.5-.535V5.535c0-.3-.23-.535-.485-.535Zm-2.658 10.929a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h7.857Zm0-3.929a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h7.857ZM14.4 3H9.6a.6.6 0 0 0-.6.6v.8a.6.6 0 0 0 .6.6h4.8a.6.6 0 0 0 .6-.6v-.8a.6.6 0 0 0-.6-.6Z"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18ZM8.707 7.293 12 10.585l3.293-3.292a1 1 0 0 1 1.414 1.414L13.415 12l3.292 3.293a1 1 0 0 1-1.414 1.414L12 13.415l-3.293 3.292a1 1 0 1 1-1.414-1.414L10.585 12 7.293 8.707a1 1 0 0 1 1.414-1.414Z"/></symbol><symbol id="icon-eds-i-cloud-upload-medium" viewBox="0 0 24 24"><path d="m12.852 10.011.028-.004L13 10l.075.003.126.017.086.022.136.052.098.052.104.074.082.073 3 3a1 1 0 0 1 0 1.414l-.094.083a1 1 0 0 1-1.32-.083L14 13.416V20a1 1 0 0 1-2 0v-6.586l-1.293 1.293a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l3-3 .112-.097.11-.071.114-.054.105-.035.118-.025Zm.587-7.962c3.065.362 5.497 2.662 5.992 5.562l.013.085.207.073c2.117.782 3.496 2.845 3.337 5.097l-.022.226c-.297 2.561-2.503 4.491-5.124 4.502a1 1 0 1 1-.009-2c1.619-.007 2.967-1.186 3.147-2.733.179-1.542-.86-2.979-2.487-3.353-.512-.149-.894-.579-.981-1.165-.21-2.237-2-4.035-4.308-4.308-2.31-.273-4.497 1.06-5.25 3.19l-.049.113c-.234.468-.718.756-1.176.743-1.418.057-2.689.857-3.32 2.084a3.668 3.668 0 0 0 .262 3.798c.796 1.136 2.169 1.764 3.583 1.635a1 1 0 1 1 .182 1.992c-2.125.194-4.193-.753-5.403-2.48a5.668 5.668 0 0 1-.403-5.86c.85-1.652 2.449-2.79 4.323-3.092l.287-.039.013-.028c1.207-2.741 4.125-4.404 7.186-4.042Z"/></symbol><symbol id="icon-eds-i-collection-medium" viewBox="0 0 24 24"><path d="M21 7a1 1 0 0 1 1 1v12.5a2.5 2.5 0 0 1-2.5 2.5H8a1 1 0 0 1 0-2h11.5a.5.5 0 0 0 .5-.5V8a1 1 0 0 1 1-1Zm-5.5-5A2.5 2.5 0 0 1 18 4.5v12a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 2 16.5v-12A2.5 2.5 0 0 1 4.5 2h11Zm0 2h-11a.5.5 0 0 0-.5.5v12a.5.5 0 0 0 .5.5h11a.5.5 0 0 0 .5-.5v-12a.5.5 0 0 0-.5-.5ZM13 13a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h6Zm0-3.5a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h6ZM13 6a1 1 0 0 1 0 2H7a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-conference-series-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M4.5 2A2.5 2.5 0 0 0 2 4.5v11A2.5 2.5 0 0 0 4.5 18h2.37l-2.534 2.253a1 1 0 0 0 1.328 1.494L9.88 18H11v3a1 1 0 1 0 2 0v-3h1.12l4.216 3.747a1 1 0 0 0 1.328-1.494L17.13 18h2.37a2.5 2.5 0 0 0 2.5-2.5v-11A2.5 2.5 0 0 0 19.5 2h-15ZM20 6V4.5a.5.5 0 0 0-.5-.5h-15a.5.5 0 0 0-.5.5V6h16ZM4 8v7.5a.5.5 0 0 0 .5.5h15a.5.5 0 0 0 .5-.5V8H4Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-delivery-medium" viewBox="0 0 24 24"><path d="M8.51 20.598a3.037 3.037 0 0 1-3.02 0A2.968 2.968 0 0 1 4.161 19L3.5 19A2.5 2.5 0 0 1 1 16.5v-11A2.5 2.5 0 0 1 3.5 3h10a2.5 2.5 0 0 1 2.45 2.004L16 5h2.527c.976 0 1.855.585 2.27 1.49l2.112 4.62a1 1 0 0 1 .091.416v4.856C23 17.814 21.889 19 20.484 19h-.523a1.01 1.01 0 0 1-.121-.007 2.96 2.96 0 0 1-1.33 1.605 3.037 3.037 0 0 1-3.02 0A2.968 2.968 0 0 1 14.161 19H9.838a2.968 2.968 0 0 1-1.327 1.597Zm-2.024-3.462a.955.955 0 0 0-.481.73L5.999 18l.001.022a.944.944 0 0 0 .388.777l.098.065c.316.181.712.181 1.028 0A.97.97 0 0 0 8 17.978a.95.95 0 0 0-.486-.842 1.037 1.037 0 0 0-1.028 0Zm10 0a.955.955 0 0 0-.481.73l-.005.156a.944.944 0 0 0 .388.777l.098.065c.316.181.712.181 1.028 0a.97.97 0 0 0 .486-.886.95.95 0 0 0-.486-.842 1.037 1.037 0 0 0-1.028 0ZM21 12h-5v3.17a3.038 3.038 0 0 1 2.51.232 2.993 2.993 0 0 1 1.277 1.45l.058.155.058-.005.581-.002c.27 0 .516-.263.516-.618V12Zm-7.5-7h-10a.5.5 0 0 0-.5.5v11a.5.5 0 0 0 .5.5h.662a2.964 2.964 0 0 1 1.155-1.491l.172-.107a3.037 3.037 0 0 1 3.022 0A2.987 2.987 0 0 1 9.843 17H13.5a.5.5 0 0 0 .5-.5v-11a.5.5 0 0 0-.5-.5Zm5.027 2H16v3h4.203l-1.224-2.677a.532.532 0 0 0-.375-.316L18.527 7Z"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 24 24"><path d="M22 18.5a3.5 3.5 0 0 1-3.5 3.5h-13A3.5 3.5 0 0 1 2 18.5V18a1 1 0 0 1 2 0v.5A1.5 1.5 0 0 0 5.5 20h13a1.5 1.5 0 0 0 1.5-1.5V18a1 1 0 0 1 2 0v.5Zm-3.293-7.793-6 6-.063.059-.093.069-.081.048-.105.049-.104.034-.056.013-.118.017L12 17l-.076-.003-.122-.017-.113-.03-.085-.032-.063-.03-.098-.058-.06-.043-.05-.043-6.04-6.037a1 1 0 0 1 1.414-1.414l4.294 4.29L11 3a1 1 0 0 1 2 0l.001 10.585 4.292-4.292a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414Z"/></symbol><symbol id="icon-eds-i-edit-medium" viewBox="0 0 24 24"><path d="M17.149 2a2.38 2.38 0 0 1 1.699.711l2.446 2.46a2.384 2.384 0 0 1 .005 3.38L10.01 19.906a1 1 0 0 1-.434.257l-6.3 1.8a1 1 0 0 1-1.237-1.237l1.8-6.3a1 1 0 0 1 .257-.434L15.443 2.718A2.385 2.385 0 0 1 17.15 2Zm-3.874 5.689-7.586 7.536-1.234 4.319 4.318-1.234 7.54-7.582-3.038-3.039ZM17.149 4a.395.395 0 0 0-.286.126L14.695 6.28l3.029 3.029 2.162-2.173a.384.384 0 0 0 .106-.197L20 6.864c0-.103-.04-.2-.119-.278l-2.457-2.47A.385.385 0 0 0 17.149 4Z"/></symbol><symbol id="icon-eds-i-education-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M12.41 2.088a1 1 0 0 0-.82 0l-10 4.5a1 1 0 0 0 0 1.824L3 9.047v7.124A3.001 3.001 0 0 0 4 22a3 3 0 0 0 1-5.83V9.948l1 .45V14.5a1 1 0 0 0 .087.408L7 14.5c-.913.408-.912.41-.912.41l.001.003.003.006.007.015a1.988 1.988 0 0 0 .083.16c.054.097.131.225.236.373.21.297.53.68.993 1.057C8.351 17.292 9.824 18 12 18c2.176 0 3.65-.707 4.589-1.476.463-.378.783-.76.993-1.057a4.162 4.162 0 0 0 .319-.533l.007-.015.003-.006v-.003h.002s0-.002-.913-.41l.913.408A1 1 0 0 0 18 14.5v-4.103l4.41-1.985a1 1 0 0 0 0-1.824l-10-4.5ZM16 11.297l-3.59 1.615a1 1 0 0 1-.82 0L8 11.297v2.94a3.388 3.388 0 0 0 .677.739C9.267 15.457 10.294 16 12 16s2.734-.543 3.323-1.024a3.388 3.388 0 0 0 .677-.739v-2.94ZM4.437 7.5 12 4.097 19.563 7.5 12 10.903 4.437 7.5ZM3 19a1 1 0 1 1 2 0 1 1 0 0 1-2 0Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-error-diamond-medium" viewBox="0 0 24 24"><path d="M12.002 1c.702 0 1.375.279 1.871.775l8.35 8.353a2.646 2.646 0 0 1 .001 3.744l-8.353 8.353a2.646 2.646 0 0 1-3.742 0l-8.353-8.353a2.646 2.646 0 0 1 0-3.744l8.353-8.353.156-.142c.424-.362.952-.58 1.507-.625l.21-.008Zm0 2a.646.646 0 0 0-.38.123l-.093.08-8.34 8.34a.646.646 0 0 0-.18.355L3 12c0 .171.068.336.19.457l8.353 8.354a.646.646 0 0 0 .914 0l8.354-8.354a.646.646 0 0 0-.001-.914l-8.351-8.354A.646.646 0 0 0 12.002 3ZM12 14.5a1.5 1.5 0 0 1 .144 2.993L12 17.5a1.5 1.5 0 0 1 0-3ZM12 6a1 1 0 0 1 1 1v5a1 1 0 0 1-2 0V7a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-error-filled-medium" viewBox="0 0 24 24"><path d="M12.002 1c.702 0 1.375.279 1.871.775l8.35 8.353a2.646 2.646 0 0 1 .001 3.744l-8.353 8.353a2.646 2.646 0 0 1-3.742 0l-8.353-8.353a2.646 2.646 0 0 1 0-3.744l8.353-8.353.156-.142c.424-.362.952-.58 1.507-.625l.21-.008ZM12 14.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 14.5ZM12 6a1 1 0 0 0-1 1v5a1 1 0 0 0 2 0V7a1 1 0 0 0-1-1Z"/></symbol><symbol id="icon-eds-i-external-link-medium" viewBox="0 0 24 24"><path d="M9 2a1 1 0 1 1 0 2H4.6c-.371 0-.6.209-.6.5v15c0 .291.229.5.6.5h14.8c.371 0 .6-.209.6-.5V15a1 1 0 0 1 2 0v4.5c0 1.438-1.162 2.5-2.6 2.5H4.6C3.162 22 2 20.938 2 19.5v-15C2 3.062 3.162 2 4.6 2H9Zm6 0h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L22 3v6a1 1 0 0 1-2 0V5.414l-6.693 6.693a1 1 0 0 1-1.414-1.414L18.584 4H15a1 1 0 0 1-.993-.883L14 3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-external-link-small" viewBox="0 0 16 16"><path d="M5 1a1 1 0 1 1 0 2l-2-.001V13L13 13v-2a1 1 0 0 1 2 0v2c0 1.15-.93 2-2.067 2H3.067C1.93 15 1 14.15 1 13V3c0-1.15.93-2 2.067-2H5Zm4 0h5l.075.003.126.017.111.03.111.044.098.052.096.067.09.08.044.047.073.093.051.083.054.113.035.105.03.148L15 2v5a1 1 0 0 1-2 0V4.414L9.107 8.307a1 1 0 0 1-1.414-1.414L11.584 3H9a1 1 0 0 1-.993-.883L8 2a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-file-download-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3ZM12 7a1 1 0 0 1 1 1v6.585l2.293-2.292a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414l-4 4a1.008 1.008 0 0 1-.112.097l-.11.071-.114.054-.105.035-.149.03L12 18l-.075-.003-.126-.017-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08-4-4a1 1 0 0 1 1.414-1.414L11 14.585V8a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-file-report-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742H5.545c-.674 0-1.32-.267-1.798-.742A2.535 2.535 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .142.057.278.158.379.102.102.242.159.387.159h12.91a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.915L14.085 3ZM16 17a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm0-3a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm-4.793-6.207L13 9.585l1.793-1.792a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414l-2.5 2.5a1 1 0 0 1-1.414 0L10.5 9.915l-1.793 1.792a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l2.5-2.5a1 1 0 0 1 1.414 0Z"/></symbol><symbol id="icon-eds-i-file-text-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3ZM16 15a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm0-4a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm-5-4a1 1 0 0 1 0 2H8a1 1 0 1 1 0-2h3Z"/></symbol><symbol id="icon-eds-i-file-upload-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3Zm-2.233 4.011.058-.007L12 7l.075.003.126.017.111.03.111.044.098.052.104.074.082.073 4 4a1 1 0 0 1 0 1.414l-.094.083a1 1 0 0 1-1.32-.083L13 10.415V17a1 1 0 0 1-2 0v-6.585l-2.293 2.292a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l4-4 .112-.097.11-.071.114-.054.105-.035.118-.025Z"/></symbol><symbol id="icon-eds-i-filter-medium" viewBox="0 0 24 24"><path d="M21 2a1 1 0 0 1 .82 1.573L15 13.314V18a1 1 0 0 1-.31.724l-.09.076-4 3A1 1 0 0 1 9 21v-7.684L2.18 3.573a1 1 0 0 1 .707-1.567L3 2h18Zm-1.921 2H4.92l5.9 8.427a1 1 0 0 1 .172.45L11 13v6l2-1.5V13a1 1 0 0 1 .117-.469l.064-.104L19.079 4Z"/></symbol><symbol id="icon-eds-i-funding-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M23 8A7 7 0 1 0 9 8a7 7 0 0 0 14 0ZM9.006 12.225A4.07 4.07 0 0 0 6.12 11.02H2a.979.979 0 1 0 0 1.958h4.12c.558 0 1.094.222 1.489.617l2.207 2.288c.27.27.27.687.012.944a.656.656 0 0 1-.928 0L7.744 15.67a.98.98 0 0 0-1.386 1.384l1.157 1.158c.535.536 1.244.791 1.946.765l.041.002h6.922c.874 0 1.597.748 1.597 1.688 0 .203-.146.354-.309.354H7.755c-.487 0-.96-.178-1.339-.504L2.64 17.259a.979.979 0 0 0-1.28 1.482L5.137 22c.733.631 1.66.979 2.618.979h9.957c1.26 0 2.267-1.043 2.267-2.312 0-2.006-1.584-3.646-3.555-3.646h-4.529a2.617 2.617 0 0 0-.681-2.509l-2.208-2.287ZM16 3a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm.979 3.5a.979.979 0 1 0-1.958 0v3a.979.979 0 1 0 1.958 0v-3Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-hashtag-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18ZM9.52 18.189a1 1 0 1 1-1.964-.378l.437-2.274H6a1 1 0 1 1 0-2h2.378l.592-3.076H6a1 1 0 0 1 0-2h3.354l.51-2.65a1 1 0 1 1 1.964.378l-.437 2.272h3.04l.51-2.65a1 1 0 1 1 1.964.378l-.438 2.272H18a1 1 0 0 1 0 2h-1.917l-.592 3.076H18a1 1 0 0 1 0 2h-2.893l-.51 2.652a1 1 0 1 1-1.964-.378l.437-2.274h-3.04l-.51 2.652Zm.895-4.652h3.04l.591-3.076h-3.04l-.591 3.076Z"/></symbol><symbol id="icon-eds-i-home-medium" viewBox="0 0 24 24"><path d="M5 22a1 1 0 0 1-1-1v-8.586l-1.293 1.293a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l10-10a1 1 0 0 1 1.414 0l10 10a1 1 0 0 1-1.414 1.414L20 12.415V21a1 1 0 0 1-1 1H5Zm7-17.585-6 5.999V20h5v-4a1 1 0 0 1 2 0v4h5v-9.585l-6-6Z"/></symbol><symbol id="icon-eds-i-image-medium" viewBox="0 0 24 24"><path d="M19.615 2A2.385 2.385 0 0 1 22 4.385v15.23A2.385 2.385 0 0 1 19.615 22H4.385A2.385 2.385 0 0 1 2 19.615V4.385A2.385 2.385 0 0 1 4.385 2h15.23Zm0 2H4.385A.385.385 0 0 0 4 4.385v15.23c0 .213.172.385.385.385h1.244l10.228-8.76a1 1 0 0 1 1.254-.037L20 13.392V4.385A.385.385 0 0 0 19.615 4Zm-3.07 9.283L8.703 20h10.912a.385.385 0 0 0 .385-.385v-3.713l-3.455-2.619ZM9.5 6a3.5 3.5 0 1 1 0 7 3.5 3.5 0 0 1 0-7Zm0 2a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3Z"/></symbol><symbol id="icon-eds-i-impact-factor-medium" viewBox="0 0 24 24"><path d="M16.49 2.672c.74.694.986 1.765.632 2.712l-.04.1-1.549 3.54h1.477a2.496 2.496 0 0 1 2.485 2.34l.005.163c0 .618-.23 1.21-.642 1.675l-7.147 7.961a2.48 2.48 0 0 1-3.554.165 2.512 2.512 0 0 1-.633-2.712l.042-.103L9.108 15H7.46c-1.393 0-2.379-1.11-2.455-2.369L5 12.473c0-.593.142-1.145.628-1.692l7.307-7.944a2.48 2.48 0 0 1 3.555-.165ZM14.43 4.164l-7.33 7.97c-.083.093-.101.214-.101.34 0 .277.19.526.46.526h4.163l.097-.009c.015 0 .03.003.046.009.181.078.264.32.186.5l-2.554 5.817a.512.512 0 0 0 .127.552.48.48 0 0 0 .69-.033l7.155-7.97a.513.513 0 0 0 .13-.34.497.497 0 0 0-.49-.502h-3.988a.355.355 0 0 1-.328-.497l2.555-5.844a.512.512 0 0 0-.127-.552.48.48 0 0 0-.69.033Z"/></symbol><symbol id="icon-eds-i-info-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm0 7a1 1 0 0 1 1 1v5h1.5a1 1 0 0 1 0 2h-5a1 1 0 0 1 0-2H11v-4h-.5a1 1 0 0 1-.993-.883L9.5 11a1 1 0 0 1 1-1H12Zm0-4.5a1.5 1.5 0 0 1 .144 2.993L12 8.5a1.5 1.5 0 0 1 0-3Z"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 9h-1.5a1 1 0 0 0-1 1l.007.117A1 1 0 0 0 10.5 12h.5v4H9.5a1 1 0 0 0 0 2h5a1 1 0 0 0 0-2H13v-5a1 1 0 0 0-1-1Zm0-4.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 5.5Z"/></symbol><symbol id="icon-eds-i-journal-medium" viewBox="0 0 24 24"><path d="M18.5 1A2.5 2.5 0 0 1 21 3.5v14a2.5 2.5 0 0 1-2.5 2.5h-13a.5.5 0 1 0 0 1H20a1 1 0 0 1 0 2H5.5A2.5 2.5 0 0 1 3 20.5v-17A2.5 2.5 0 0 1 5.5 1h13ZM7 3H5.5a.5.5 0 0 0-.5.5v14.549l.016-.002c.104-.02.211-.035.32-.042L5.5 18H7V3Zm11.5 0H9v15h9.5a.5.5 0 0 0 .5-.5v-14a.5.5 0 0 0-.5-.5ZM16 5a1 1 0 0 1 1 1v4a1 1 0 0 1-1 1h-5a1 1 0 0 1-1-1V6a1 1 0 0 1 1-1h5Zm-1 2h-3v2h3V7Z"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="M20.462 3C21.875 3 23 4.184 23 5.619v12.762C23 19.816 21.875 21 20.462 21H3.538C2.125 21 1 19.816 1 18.381V5.619C1 4.184 2.125 3 3.538 3h16.924ZM21 8.158l-7.378 6.258a2.549 2.549 0 0 1-3.253-.008L3 8.16v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619V8.158ZM20.462 5H3.538c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516Z"/></symbol><symbol id="icon-eds-i-mail-send-medium" viewBox="0 0 24 24"><path d="M20.444 5a2.562 2.562 0 0 1 2.548 2.37l.007.078.001.123v7.858A2.564 2.564 0 0 1 20.444 18H9.556A2.564 2.564 0 0 1 7 15.429l.001-7.977.007-.082A2.561 2.561 0 0 1 9.556 5h10.888ZM21 9.331l-5.46 3.51a1 1 0 0 1-1.08 0L9 9.332v6.097c0 .317.251.571.556.571h10.888a.564.564 0 0 0 .556-.571V9.33ZM20.444 7H9.556a.543.543 0 0 0-.32.105l5.763 3.706 5.766-3.706a.543.543 0 0 0-.32-.105ZM4.308 5a1 1 0 1 1 0 2H2a1 1 0 1 1 0-2h2.308Zm0 5.5a1 1 0 0 1 0 2H2a1 1 0 0 1 0-2h2.308Zm0 5.5a1 1 0 0 1 0 2H2a1 1 0 0 1 0-2h2.308Z"/></symbol><symbol id="icon-eds-i-mentions-medium" viewBox="0 0 24 24"><path d="m9.452 1.293 5.92 5.92 2.92-2.92a1 1 0 0 1 1.415 1.414l-2.92 2.92 5.92 5.92a1 1 0 0 1 0 1.415 10.371 10.371 0 0 1-10.378 2.584l.652 3.258A1 1 0 0 1 12 23H2a1 1 0 0 1-.874-1.486l4.789-8.62C4.194 9.074 4.9 4.43 8.038 1.292a1 1 0 0 1 1.414 0Zm-2.355 13.59L3.699 21h7.081l-.689-3.442a10.392 10.392 0 0 1-2.775-2.396l-.22-.28Zm1.69-11.427-.07.09a8.374 8.374 0 0 0 11.737 11.737l.089-.071L8.787 3.456Z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-metrics-medium" viewBox="0 0 24 24"><path d="M3 22a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v7h4V8a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v13a1 1 0 0 1-.883.993L21 22H3Zm17-2V9h-4v11h4Zm-6-8h-4v8h4v-8ZM8 4H4v16h4V4Z"/></symbol><symbol id="icon-eds-i-news-medium" viewBox="0 0 24 24"><path d="M17.384 3c.975 0 1.77.787 1.77 1.762v13.333c0 .462.354.846.815.899l.107.006.109-.006a.915.915 0 0 0 .809-.794l.006-.105V8.19a1 1 0 0 1 2 0v9.905A2.914 2.914 0 0 1 20.077 21H3.538a2.547 2.547 0 0 1-1.644-.601l-.147-.135A2.516 2.516 0 0 1 1 18.476V4.762C1 3.787 1.794 3 2.77 3h14.614Zm-.231 2H3v13.476c0 .11.035.216.1.304l.054.063c.101.1.24.157.384.157l13.761-.001-.026-.078a2.88 2.88 0 0 1-.115-.655l-.004-.17L17.153 5ZM14 15.021a.979.979 0 1 1 0 1.958H6a.979.979 0 1 1 0-1.958h8Zm0-8c.54 0 .979.438.979.979v4c0 .54-.438.979-.979.979H6A.979.979 0 0 1 5.021 12V8c0-.54.438-.979.979-.979h8Zm-.98 1.958H6.979v2.041h6.041V8.979Z"/></symbol><symbol id="icon-eds-i-newsletter-medium" viewBox="0 0 24 24"><path d="M21 10a1 1 0 0 1 1 1v9.5a2.5 2.5 0 0 1-2.5 2.5h-15A2.5 2.5 0 0 1 2 20.5V11a1 1 0 0 1 2 0v.439l8 4.888 8-4.889V11a1 1 0 0 1 1-1Zm-1 3.783-7.479 4.57a1 1 0 0 1-1.042 0l-7.48-4.57V20.5a.5.5 0 0 0 .501.5h15a.5.5 0 0 0 .5-.5v-6.717ZM15 9a1 1 0 0 1 0 2H9a1 1 0 0 1 0-2h6Zm2.5-8A2.5 2.5 0 0 1 20 3.5V9a1 1 0 0 1-2 0V3.5a.5.5 0 0 0-.5-.5h-11a.5.5 0 0 0-.5.5V9a1 1 0 1 1-2 0V3.5A2.5 2.5 0 0 1 6.5 1h11ZM15 5a1 1 0 0 1 0 2H9a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-notifcation-medium" viewBox="0 0 24 24"><path d="M14 20a1 1 0 0 1 0 2h-4a1 1 0 0 1 0-2h4ZM3 18l-.133-.007c-1.156-.124-1.156-1.862 0-1.986l.3-.012C4.32 15.923 5 15.107 5 14V9.5C5 5.368 8.014 2 12 2s7 3.368 7 7.5V14c0 1.107.68 1.923 1.832 1.995l.301.012c1.156.124 1.156 1.862 0 1.986L21 18H3Zm9-14C9.17 4 7 6.426 7 9.5V14c0 .671-.146 1.303-.416 1.858L6.51 16h10.979l-.073-.142a4.192 4.192 0 0 1-.412-1.658L17 14V9.5C17 6.426 14.83 4 12 4Z"/></symbol><symbol id="icon-eds-i-publish-medium" viewBox="0 0 24 24"><g><path d="M16.296 1.291A1 1 0 0 0 15.591 1H5.545A2.542 2.542 0 0 0 3 3.538V13a1 1 0 1 0 2 0V3.538l.007-.087A.543.543 0 0 1 5.545 3h9.633L20 7.8v12.662a.534.534 0 0 1-.158.379.548.548 0 0 1-.387.159H11a1 1 0 1 0 0 2h8.455c.674 0 1.32-.267 1.798-.742A2.534 2.534 0 0 0 22 20.462V7.385a1 1 0 0 0-.294-.709l-5.41-5.385Z"/><path d="M10.762 16.647a1 1 0 0 0-1.525-1.294l-4.472 5.271-2.153-1.665a1 1 0 1 0-1.224 1.582l2.91 2.25a1 1 0 0 0 1.374-.144l5.09-6ZM16 10a1 1 0 1 1 0 2H8a1 1 0 1 1 0-2h8ZM12 7a1 1 0 0 0-1-1H8a1 1 0 1 0 0 2h3a1 1 0 0 0 1-1Z"/></g></symbol><symbol id="icon-eds-i-refresh-medium" viewBox="0 0 24 24"><g><path d="M7.831 5.636H6.032A8.76 8.76 0 0 1 9 3.631 8.549 8.549 0 0 1 12.232 3c.603 0 1.192.063 1.76.182C17.979 4.017 21 7.632 21 12a1 1 0 1 0 2 0c0-5.296-3.674-9.746-8.591-10.776A10.61 10.61 0 0 0 5 3.851V2.805a1 1 0 0 0-.987-1H4a1 1 0 0 0-1 1v3.831a1 1 0 0 0 1 1h3.831a1 1 0 0 0 .013-2h-.013ZM17.968 18.364c-1.59 1.632-3.784 2.636-6.2 2.636C6.948 21 3 16.993 3 12a1 1 0 1 0-2 0c0 6.053 4.799 11 10.768 11 2.788 0 5.324-1.082 7.232-2.85v1.045a1 1 0 1 0 2 0v-3.831a1 1 0 0 0-1-1h-3.831a1 1 0 0 0 0 2h1.799Z"/></g></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-settings-medium" viewBox="0 0 24 24"><path d="M11.382 1h1.24a2.508 2.508 0 0 1 2.334 1.63l.523 1.378 1.59.933 1.444-.224c.954-.132 1.89.3 2.422 1.101l.095.155.598 1.066a2.56 2.56 0 0 1-.195 2.848l-.894 1.161v1.896l.92 1.163c.6.768.707 1.812.295 2.674l-.09.17-.606 1.08a2.504 2.504 0 0 1-2.531 1.25l-1.428-.223-1.589.932-.523 1.378a2.512 2.512 0 0 1-2.155 1.625L12.65 23h-1.27a2.508 2.508 0 0 1-2.334-1.63l-.524-1.379-1.59-.933-1.443.225c-.954.132-1.89-.3-2.422-1.101l-.095-.155-.598-1.066a2.56 2.56 0 0 1 .195-2.847l.891-1.161v-1.898l-.919-1.162a2.562 2.562 0 0 1-.295-2.674l.09-.17.606-1.08a2.504 2.504 0 0 1 2.531-1.25l1.43.223 1.618-.938.524-1.375.07-.167A2.507 2.507 0 0 1 11.382 1Zm.003 2a.509.509 0 0 0-.47.338l-.65 1.71a1 1 0 0 1-.434.51L7.6 6.85a1 1 0 0 1-.655.123l-1.762-.275a.497.497 0 0 0-.498.252l-.61 1.088a.562.562 0 0 0 .04.619l1.13 1.43a1 1 0 0 1 .216.62v2.585a1 1 0 0 1-.207.61L4.15 15.339a.568.568 0 0 0-.036.634l.601 1.072a.494.494 0 0 0 .484.26l1.78-.278a1 1 0 0 1 .66.126l2.2 1.292a1 1 0 0 1 .43.507l.648 1.71a.508.508 0 0 0 .467.338h1.263a.51.51 0 0 0 .47-.34l.65-1.708a1 1 0 0 1 .428-.507l2.201-1.292a1 1 0 0 1 .66-.126l1.763.275a.497.497 0 0 0 .498-.252l.61-1.088a.562.562 0 0 0-.04-.619l-1.13-1.43a1 1 0 0 1-.216-.62v-2.585a1 1 0 0 1 .207-.61l1.105-1.437a.568.568 0 0 0 .037-.634l-.601-1.072a.494.494 0 0 0-.484-.26l-1.78.278a1 1 0 0 1-.66-.126l-2.2-1.292a1 1 0 0 1-.43-.507l-.649-1.71A.508.508 0 0 0 12.62 3h-1.234ZM12 8a4 4 0 1 1 0 8 4 4 0 0 1 0-8Zm0 2a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"/></symbol><symbol id="icon-eds-i-shipping-medium" viewBox="0 0 24 24"><path d="M16.515 2c1.406 0 2.706.728 3.352 1.902l2.02 3.635.02.042.036.089.031.105.012.058.01.073.004.075v11.577c0 .64-.244 1.255-.683 1.713a2.356 2.356 0 0 1-1.701.731H4.386a2.356 2.356 0 0 1-1.702-.731 2.476 2.476 0 0 1-.683-1.713V7.948c.01-.217.083-.43.22-.6L4.2 3.905C4.833 2.755 6.089 2.032 7.486 2h9.029ZM20 9H4v10.556a.49.49 0 0 0 .075.26l.053.07a.356.356 0 0 0 .257.114h15.23c.094 0 .186-.04.258-.115a.477.477 0 0 0 .127-.33V9Zm-2 7.5a1 1 0 0 1 0 2h-4a1 1 0 0 1 0-2h4ZM16.514 4H13v3h6.3l-1.183-2.13c-.288-.522-.908-.87-1.603-.87ZM11 3.999H7.51c-.679.017-1.277.36-1.566.887L4.728 7H11V3.999Z"/></symbol><symbol id="icon-eds-i-step-guide-medium" viewBox="0 0 24 24"><path d="M11.394 9.447a1 1 0 1 0-1.788-.894l-.88 1.759-.019-.02a1 1 0 1 0-1.414 1.415l1 1a1 1 0 0 0 1.601-.26l1.5-3ZM12 11a1 1 0 0 1 1-1h3a1 1 0 1 1 0 2h-3a1 1 0 0 1-1-1ZM12 17a1 1 0 0 1 1-1h3a1 1 0 1 1 0 2h-3a1 1 0 0 1-1-1ZM10.947 14.105a1 1 0 0 1 .447 1.342l-1.5 3a1 1 0 0 1-1.601.26l-1-1a1 1 0 1 1 1.414-1.414l.02.019.879-1.76a1 1 0 0 1 1.341-.447Z"/><path d="M5.545 1A2.542 2.542 0 0 0 3 3.538v16.924A2.542 2.542 0 0 0 5.545 23h12.91A2.542 2.542 0 0 0 21 20.462V7.5a1 1 0 0 0-.293-.707l-5.5-5.5A1 1 0 0 0 14.5 1H5.545ZM5 3.538C5 3.245 5.24 3 5.545 3h8.54L19 7.914v12.547c0 .294-.24.539-.546.539H5.545A.542.542 0 0 1 5 20.462V3.538Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-submission-medium" viewBox="0 0 24 24"><g><path d="M5 3.538C5 3.245 5.24 3 5.545 3h9.633L20 7.8v12.662a.535.535 0 0 1-.158.379.549.549 0 0 1-.387.159H6a1 1 0 0 1-1-1v-2.5a1 1 0 1 0-2 0V20a3 3 0 0 0 3 3h13.455c.673 0 1.32-.266 1.798-.742A2.535 2.535 0 0 0 22 20.462V7.385a1 1 0 0 0-.294-.709l-5.41-5.385A1 1 0 0 0 15.591 1H5.545A2.542 2.542 0 0 0 3 3.538V7a1 1 0 0 0 2 0V3.538Z"/><path d="m13.707 13.707-4 4a1 1 0 0 1-1.414 0l-.083-.094a1 1 0 0 1 .083-1.32L10.585 14 2 14a1 1 0 1 1 0-2l8.583.001-2.29-2.294a1 1 0 0 1 1.414-1.414l4.037 4.04.043.05.043.06.059.098.03.063.031.085.03.113.017.122L14 13l-.004.087-.017.118-.013.056-.034.104-.049.105-.048.081-.07.093-.058.063Z"/></g></symbol><symbol id="icon-eds-i-table-1-medium" viewBox="0 0 24 24"><path d="M4.385 22a2.56 2.56 0 0 1-1.14-.279C2.485 21.341 2 20.614 2 19.615V4.385c0-.315.067-.716.279-1.14C2.659 2.485 3.386 2 4.385 2h15.23c.315 0 .716.067 1.14.279.76.38 1.245 1.107 1.245 2.106v15.23c0 .315-.067.716-.279 1.14-.38.76-1.107 1.245-2.106 1.245H4.385ZM4 19.615c0 .213.034.265.14.317a.71.71 0 0 0 .245.068H8v-4H4v3.615ZM20 16H10v4h9.615c.213 0 .265-.034.317-.14a.71.71 0 0 0 .068-.245V16Zm0-2v-4H10v4h10ZM4 14h4v-4H4v4ZM19.615 4H10v4h10V4.385c0-.213-.034-.265-.14-.317A.71.71 0 0 0 19.615 4ZM8 4H4.385l-.082.002c-.146.01-.19.047-.235.138A.71.71 0 0 0 4 4.385V8h4V4Z"/></symbol><symbol id="icon-eds-i-table-2-medium" viewBox="0 0 24 24"><path d="M4.384 22A2.384 2.384 0 0 1 2 19.616V4.384A2.384 2.384 0 0 1 4.384 2h15.232A2.384 2.384 0 0 1 22 4.384v15.232A2.384 2.384 0 0 1 19.616 22H4.384ZM10 15H4v4.616c0 .212.172.384.384.384H10v-5Zm5 0h-3v5h3v-5Zm5 0h-3v5h2.616a.384.384 0 0 0 .384-.384V15ZM10 9H4v4h6V9Zm5 0h-3v4h3V9Zm5 0h-3v4h3V9Zm-.384-5H4.384A.384.384 0 0 0 4 4.384V7h16V4.384A.384.384 0 0 0 19.616 4Z"/></symbol><symbol id="icon-eds-i-tag-medium" viewBox="0 0 24 24"><path d="m12.621 1.998.127.004L20.496 2a1.5 1.5 0 0 1 1.497 1.355L22 3.5l-.005 7.669c.038.456-.133.905-.447 1.206l-9.02 9.018a2.075 2.075 0 0 1-2.932 0l-6.99-6.99a2.075 2.075 0 0 1 .001-2.933L11.61 2.47c.246-.258.573-.418.881-.46l.131-.011Zm.286 2-8.885 8.886a.075.075 0 0 0 0 .106l6.987 6.988c.03.03.077.03.106 0l8.883-8.883L19.999 4l-7.092-.002ZM16 6.5a1.5 1.5 0 0 1 .144 2.993L16 9.5a1.5 1.5 0 0 1 0-3Z"/></symbol><symbol id="icon-eds-i-trash-medium" viewBox="0 0 24 24"><path d="M12 1c2.717 0 4.913 2.232 4.997 5H21a1 1 0 0 1 0 2h-1v12.5c0 1.389-1.152 2.5-2.556 2.5H6.556C5.152 23 4 21.889 4 20.5V8H3a1 1 0 1 1 0-2h4.003l.001-.051C7.114 3.205 9.3 1 12 1Zm6 7H6v12.5c0 .238.19.448.454.492l.102.008h10.888c.315 0 .556-.232.556-.5V8Zm-4 3a1 1 0 0 1 1 1v6.005a1 1 0 0 1-2 0V12a1 1 0 0 1 1-1Zm-4 0a1 1 0 0 1 1 1v6a1 1 0 0 1-2 0v-6a1 1 0 0 1 1-1Zm2-8c-1.595 0-2.914 1.32-2.996 3h5.991v-.02C14.903 4.31 13.589 3 12 3Z"/></symbol><symbol id="icon-eds-i-user-account-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 16c-1.806 0-3.52.994-4.664 2.698A8.947 8.947 0 0 0 12 21a8.958 8.958 0 0 0 4.664-1.301C15.52 17.994 13.806 17 12 17Zm0-14a9 9 0 0 0-6.25 15.476C7.253 16.304 9.54 15 12 15s4.747 1.304 6.25 3.475A9 9 0 0 0 12 3Zm0 3a4 4 0 1 1 0 8 4 4 0 0 1 0-8Zm0 2a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"/></symbol><symbol id="icon-eds-i-user-add-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm9 10a1 1 0 0 1 1 1v3h3a1 1 0 0 1 0 2h-3v3a1 1 0 0 1-2 0v-3h-3a1 1 0 0 1 0-2h3v-3a1 1 0 0 1 1-1Zm-5.545-.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378Z"/></symbol><symbol id="icon-eds-i-user-assign-medium" viewBox="0 0 24 24"><path d="M16.226 13.298a1 1 0 0 1 1.414-.01l.084.093a1 1 0 0 1-.073 1.32L15.39 17H22a1 1 0 0 1 0 2h-6.611l2.262 2.298a1 1 0 0 1-1.425 1.404l-3.939-4a1 1 0 0 1 0-1.404l3.94-4Zm-3.771-.449a1 1 0 1 1-.91 1.781 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 10.5 20a1 1 0 0 1 .993.883L11.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Z"/></symbol><symbol id="icon-eds-i-user-block-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm9 10a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm-5.545-.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM15 18a3 3 0 0 0 4.294 2.707l-4.001-4c-.188.391-.293.83-.293 1.293Zm3-3c-.463 0-.902.105-1.294.293l4.001 4A3 3 0 0 0 18 15Z"/></symbol><symbol id="icon-eds-i-user-check-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm13.647 12.237a1 1 0 0 1 .116 1.41l-5.091 6a1 1 0 0 1-1.375.144l-2.909-2.25a1 1 0 1 1 1.224-1.582l2.153 1.665 4.472-5.271a1 1 0 0 1 1.41-.116Zm-8.139-.977c.22.214.428.44.622.678a1 1 0 1 1-1.548 1.266 6.025 6.025 0 0 0-1.795-1.49.86.86 0 0 1-.163-.048l-.079-.036a5.721 5.721 0 0 0-2.62-.63l-.194.006c-2.76.134-5.022 2.177-5.592 4.864l-.035.175-.035.213c-.03.201-.05.405-.06.61L3.003 20 10 20a1 1 0 0 1 .993.883L11 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876l.005-.223.02-.356.02-.222.03-.248.022-.15c.02-.133.044-.265.071-.397.44-2.178 1.725-4.105 3.595-5.301a7.75 7.75 0 0 1 3.755-1.215l.12-.004a7.908 7.908 0 0 1 5.87 2.252Z"/></symbol><symbol id="icon-eds-i-user-delete-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6ZM4.763 13.227a7.713 7.713 0 0 1 7.692-.378 1 1 0 1 1-.91 1.781 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20H11.5a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897Zm11.421 1.543 2.554 2.553 2.555-2.553a1 1 0 0 1 1.414 1.414l-2.554 2.554 2.554 2.555a1 1 0 0 1-1.414 1.414l-2.555-2.554-2.554 2.554a1 1 0 0 1-1.414-1.414l2.553-2.555-2.553-2.554a1 1 0 0 1 1.414-1.414Z"/></symbol><symbol id="icon-eds-i-user-edit-medium" viewBox="0 0 24 24"><path d="m19.876 10.77 2.831 2.83a1 1 0 0 1 0 1.415l-7.246 7.246a1 1 0 0 1-.572.284l-3.277.446a1 1 0 0 1-1.125-1.13l.461-3.277a1 1 0 0 1 .283-.567l7.23-7.246a1 1 0 0 1 1.415-.001Zm-7.421 2.08a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 7.5 20a1 1 0 0 1 .993.883L8.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378Zm6.715.042-6.29 6.3-.23 1.639 1.633-.222 6.302-6.302-1.415-1.415ZM9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Z"/></symbol><symbol id="icon-eds-i-user-linked-medium" viewBox="0 0 24 24"><path d="M15.65 6c.31 0 .706.066 1.122.274C17.522 6.65 18 7.366 18 8.35v12.3c0 .31-.066.706-.274 1.122-.375.75-1.092 1.228-2.076 1.228H3.35a2.52 2.52 0 0 1-1.122-.274C1.478 22.35 1 21.634 1 20.65V8.35c0-.31.066-.706.274-1.122C1.65 6.478 2.366 6 3.35 6h12.3Zm0 2-12.376.002c-.134.007-.17.04-.21.12A.672.672 0 0 0 3 8.35v12.3c0 .198.028.24.122.287.09.044.2.063.228.063h.887c.788-2.269 2.814-3.5 5.263-3.5 2.45 0 4.475 1.231 5.263 3.5h.887c.198 0 .24-.028.287-.122.044-.09.063-.2.063-.228V8.35c0-.198-.028-.24-.122-.287A.672.672 0 0 0 15.65 8ZM9.5 19.5c-1.36 0-2.447.51-3.06 1.5h6.12c-.613-.99-1.7-1.5-3.06-1.5ZM20.65 1A2.35 2.35 0 0 1 23 3.348V15.65A2.35 2.35 0 0 1 20.65 18H20a1 1 0 0 1 0-2h.65a.35.35 0 0 0 .35-.35V3.348A.35.35 0 0 0 20.65 3H8.35a.35.35 0 0 0-.35.348V4a1 1 0 1 1-2 0v-.652A2.35 2.35 0 0 1 8.35 1h12.3ZM9.5 10a3.5 3.5 0 1 1 0 7 3.5 3.5 0 0 1 0-7Zm0 2a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3Z"/></symbol><symbol id="icon-eds-i-user-multiple-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm6 0a5 5 0 0 1 0 10 1 1 0 0 1-.117-1.993L15 9a3 3 0 0 0 0-6 1 1 0 0 1 0-2ZM9 3a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm8.857 9.545a7.99 7.99 0 0 1 2.651 1.715A8.31 8.31 0 0 1 23 20.134V21a1 1 0 0 1-1 1h-3a1 1 0 0 1 0-2h1.995l-.005-.153a6.307 6.307 0 0 0-1.673-3.945l-.204-.209a5.99 5.99 0 0 0-1.988-1.287 1 1 0 1 1 .732-1.861Zm-3.349 1.715A8.31 8.31 0 0 1 17 20.134V21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.877c.044-4.343 3.387-7.908 7.638-8.115a7.908 7.908 0 0 1 5.87 2.252ZM9.016 14l-.285.006c-3.104.15-5.58 2.718-5.725 5.9L3.004 20h11.991l-.005-.153a6.307 6.307 0 0 0-1.673-3.945l-.204-.209A5.924 5.924 0 0 0 9.3 14.008L9.016 14Z"/></symbol><symbol id="icon-eds-i-user-notify-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm10 18v1a1 1 0 0 1-2 0v-1h-3a1 1 0 0 1 0-2v-2.818C14 13.885 15.777 12 18 12s4 1.885 4 4.182V19a1 1 0 0 1 0 2h-3Zm-6.545-8.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM18 14c-1.091 0-2 .964-2 2.182V19h4v-2.818c0-1.165-.832-2.098-1.859-2.177L18 14Z"/></symbol><symbol id="icon-eds-i-user-remove-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm3.455 9.85a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM22 17a1 1 0 0 1 0 2h-8a1 1 0 0 1 0-2h8Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm0 11.5a1.5 1.5 0 0 1 .144 2.993L12 17.5a1.5 1.5 0 0 1 0-3ZM12 6a1 1 0 0 1 1 1v5a1 1 0 0 1-2 0V7a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 13.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 14.5ZM12 6a1 1 0 0 0-1 1v5a1 1 0 0 0 2 0V7a1 1 0 0 0-1-1Z"/></symbol><symbol id="icon-eds-i-work-medium" viewBox="0 0 24 24"><path d="M4 3.53808C4 3.24519 4.23975 3 4.5451 3H14.1778L19 7.80031V8C19 8.55228 19.4477 9 20 9C20.5523 9 21 8.55228 21 8V7.38477C21 7.11876 20.894 6.86372 20.7055 6.67605L15.2962 1.29129C15.1088 1.10473 14.8551 1 14.5907 1H4.5451C3.14377 1 2 2.13206 2 3.53808V20.5007C2 21.882 3.11988 23 4.5 23H8C8.55228 23 9 22.5523 9 22C9 21.4477 8.55228 21 8 21H4.5C4.22327 21 4 20.7762 4 20.5007V3.53808Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M19.8764 10.7698C19.6887 10.5822 19.4341 10.4768 19.1687 10.4769C18.9033 10.4771 18.6489 10.5827 18.4614 10.7706L11.2306 18.0167C11.0776 18.1701 10.9785 18.3691 10.9483 18.5836L10.4867 21.8605C10.443 22.1707 10.5472 22.4835 10.7682 22.7055C10.9892 22.9275 11.3015 23.0331 11.6118 22.9909L14.8888 22.5447C15.1054 22.5152 15.3064 22.4155 15.461 22.261L22.7071 15.0148C22.8947 14.8273 23 14.5729 23 14.3077C23 14.0425 22.8947 13.7881 22.7071 13.6006L19.8764 10.7698ZM12.8821 19.1931L19.17 12.8919L20.5858 14.3077L14.285 20.6085L12.6515 20.8309L12.8821 19.1931Z"/><path d="M11.0812 4.68628C11.5307 5.00729 11.6347 5.63184 11.3137 6.08125L8.81373 9.58125C8.64288 9.82045 8.37543 9.97236 8.08248 9.99661C7.78953 10.0209 7.50075 9.91498 7.29289 9.70712L5.79289 8.20712C5.40237 7.8166 5.40237 7.18343 5.79289 6.79291C6.18342 6.40239 6.81658 6.40239 7.20711 6.79291L7.8724 7.4582L9.68627 4.91878C10.0073 4.46937 10.6318 4.36527 11.0812 4.68628Z"/><path d="M11.3137 12.0813C11.6347 11.6318 11.5307 11.0073 11.0812 10.6863C10.6318 10.3653 10.0073 10.4694 9.68627 10.9188L7.8724 13.4582L7.20711 12.7929C6.81658 12.4024 6.18342 12.4024 5.79289 12.7929C5.40237 13.1834 5.40237 13.8166 5.79289 14.2071L7.29289 15.7071C7.50075 15.915 7.78953 16.0209 8.08248 15.9966C8.37543 15.9724 8.64288 15.8205 8.81373 15.5813L11.3137 12.0813Z"/></symbol><symbol id="icon-ai-stars"><path d="M22.294 13.39c.941.536.941 1.945 0 2.482l-3.613 2.061c-.228.13-.415.325-.54.563l-1.976 3.768a1.33 1.33 0 0 1-2.38 0l-1.977-3.768a1.4 1.4 0 0 0-.539-.563l-3.614-2.061c-.94-.537-.94-1.946 0-2.482l3.614-2.061c.228-.13.415-.325.54-.563l1.976-3.768a1.33 1.33 0 0 1 2.38 0l1.977 3.768c.124.238.311.433.539.563zM10.08 4.861c1.044.508 1.044 2.056 0 2.564l-1.543.751c-.29.14-.521.383-.656.684l-.72 1.61a1.334 1.334 0 0 1-2.459 0l-.72-1.61a1.4 1.4 0 0 0-.656-.684l-1.543-.751c-1.044-.508-1.044-2.056 0-2.564l1.543-.751c.29-.14.521-.383.656-.684l.72-1.61a1.334 1.334 0 0 1 2.459 0l.72 1.61c.135.301.367.543.656.684z"/></symbol><symbol id="icon-chevron-left-medium" viewBox="0 0 24 24"><path d="M15.7194 3.3054C15.3358 2.90809 14.7027 2.89699 14.3054 3.28061L6.54342 10.7757C6.19804 11.09 6 11.5335 6 12C6 12.4665 6.19804 12.91 6.5218 13.204L14.3054 20.7194C14.7027 21.103 15.3358 21.0919 15.7194 20.6946C16.103 20.2973 16.0919 19.6642 15.6946 19.2806L8.155 12L15.6946 4.71939C16.0614 4.36528 16.099 3.79863 15.8009 3.40105L15.7194 3.3054Z"/></symbol><symbol id="icon-chevron-right-medium" viewBox="0 0 24 24"><path d="M8.28061 3.3054C8.66423 2.90809 9.29729 2.89699 9.6946 3.28061L17.4566 10.7757C17.802 11.09 18 11.5335 18 12C18 12.4665 17.802 12.91 17.4782 13.204L9.6946 20.7194C9.29729 21.103 8.66423 21.0919 8.28061 20.6946C7.89699 20.2973 7.90809 19.6642 8.3054 19.2806L15.845 12L8.3054 4.71939C7.93865 4.36528 7.90098 3.79863 8.19908 3.40105L8.28061 3.3054Z"/></symbol><symbol id="icon-eds-alerts" viewBox="0 0 32 32"><path d="M28 12.667c.736 0 1.333.597 1.333 1.333v13.333A3.333 3.333 0 0 1 26 30.667H6a3.333 3.333 0 0 1-3.333-3.334V14a1.333 1.333 0 1 1 2.666 0v1.252L16 21.769l10.667-6.518V14c0-.736.597-1.333 1.333-1.333Zm-1.333 5.71-9.972 6.094c-.427.26-.963.26-1.39 0l-9.972-6.094v8.956c0 .368.299.667.667.667h20a.667.667 0 0 0 .667-.667v-8.956ZM19.333 12a1.333 1.333 0 1 1 0 2.667h-6.666a1.333 1.333 0 1 1 0-2.667h6.666Zm4-10.667a3.333 3.333 0 0 1 3.334 3.334v6.666a1.333 1.333 0 1 1-2.667 0V4.667A.667.667 0 0 0 23.333 4H8.667A.667.667 0 0 0 8 4.667v6.666a1.333 1.333 0 1 1-2.667 0V4.667a3.333 3.333 0 0 1 3.334-3.334h14.666Zm-4 5.334a1.333 1.333 0 0 1 0 2.666h-6.666a1.333 1.333 0 1 1 0-2.666h6.666Z"/></symbol><symbol id="icon-eds-arrow-up" viewBox="0 0 24 24"><path fill-rule="evenodd" d="m13.002 7.408 4.88 4.88a.99.99 0 0 0 1.32.08l.09-.08c.39-.39.39-1.03 0-1.42l-6.58-6.58a1.01 1.01 0 0 0-1.42 0l-6.58 6.58a1 1 0 0 0-.09 1.32l.08.1a1 1 0 0 0 1.42-.01l4.88-4.87v11.59a.99.99 0 0 0 .88.99l.12.01c.55 0 1-.45 1-1V7.408z" class="layer"/></symbol><symbol id="icon-eds-checklist" viewBox="0 0 32 32"><path d="M19.2 1.333a3.468 3.468 0 0 1 3.381 2.699L24.667 4C26.515 4 28 5.52 28 7.38v19.906c0 1.86-1.485 3.38-3.333 3.38H7.333c-1.848 0-3.333-1.52-3.333-3.38V7.38C4 5.52 5.485 4 7.333 4h2.093A3.468 3.468 0 0 1 12.8 1.333h6.4ZM9.426 6.667H7.333c-.36 0-.666.312-.666.713v19.906c0 .401.305.714.666.714h17.334c.36 0 .666-.313.666-.714V7.38c0-.4-.305-.713-.646-.714l-2.121.033A3.468 3.468 0 0 1 19.2 9.333h-6.4a3.468 3.468 0 0 1-3.374-2.666Zm12.715 5.606c.586.446.7 1.283.253 1.868l-7.111 9.334a1.333 1.333 0 0 1-1.792.306l-3.556-2.333a1.333 1.333 0 1 1 1.463-2.23l2.517 1.651 6.358-8.344a1.333 1.333 0 0 1 1.868-.252ZM19.2 4h-6.4a.8.8 0 0 0-.8.8v1.067a.8.8 0 0 0 .8.8h6.4a.8.8 0 0 0 .8-.8V4.8a.8.8 0 0 0-.8-.8Z"/></symbol><symbol id="icon-eds-citation" viewBox="0 0 36 36"><path d="M23.25 1.5a1.5 1.5 0 0 1 1.06.44l8.25 8.25a1.5 1.5 0 0 1 .44 1.06v19.5c0 2.105-1.645 3.75-3.75 3.75H18a1.5 1.5 0 0 1 0-3h11.25c.448 0 .75-.302.75-.75V11.873L22.628 4.5H8.31a.811.811 0 0 0-.8.68l-.011.13V16.5a1.5 1.5 0 0 1-3 0V5.31A3.81 3.81 0 0 1 8.31 1.5h14.94ZM8.223 20.358a.984.984 0 0 1-.192 1.378l-.048.034c-.54.36-.942.676-1.206.951-.59.614-.885 1.395-.885 2.343.115-.028.288-.042.518-.042.662 0 1.26.237 1.791.711.533.474.799 1.074.799 1.799 0 .753-.259 1.352-.777 1.799-.518.446-1.151.669-1.9.669-1.006 0-1.812-.293-2.417-.878C3.302 28.536 3 27.657 3 26.486c0-1.115.165-2.085.496-2.907.331-.823.734-1.513 1.209-2.071.475-.558.971-.997 1.49-1.318a6.01 6.01 0 0 1 .347-.2 1.321 1.321 0 0 1 1.681.368Zm7.5 0a.984.984 0 0 1-.192 1.378l-.048.034c-.54.36-.942.676-1.206.951-.59.614-.885 1.395-.885 2.343.115-.028.288-.042.518-.042.662 0 1.26.237 1.791.711.533.474.799 1.074.799 1.799 0 .753-.259 1.352-.777 1.799-.518.446-1.151.669-1.9.669-1.006 0-1.812-.293-2.417-.878-.604-.586-.906-1.465-.906-2.636 0-1.115.165-2.085.496-2.907.331-.823.734-1.513 1.209-2.071.475-.558.971-.997 1.49-1.318a6.01 6.01 0 0 1 .347-.2 1.321 1.321 0 0 1 1.681.368Z"/></symbol><symbol id="icon-eds-i-access-indicator" viewBox="0 0 16 16"><circle cx="4.5" cy="11.5" r="3.5" style="fill:currentColor"/><path fill-rule="evenodd" d="M4 3v3a1 1 0 0 1-2 0V2.923C2 1.875 2.84 1 3.909 1h5.909a1 1 0 0 1 .713.298l3.181 3.231a1 1 0 0 1 .288.702v7.846c0 .505-.197.993-.554 1.354a1.902 1.902 0 0 1-1.355.569H10a1 1 0 1 1 0-2h2V5.64L9.4 3H4Z" clip-rule="evenodd" style="fill:#222"/></symbol><symbol id="icon-eds-i-accessibility-medium" viewBox="0 0 24 24"><path d="M17 10.5C17.5523 10.5 18 10.9477 18 11.5C18 12.0523 17.5523 12.5 17 12.5H13V13C13 13.4952 13.2735 14.3106 13.7695 15.3027C14.1249 16.0135 14.551 16.7321 14.9483 17.3564L15.332 17.9453L15.3848 18.0332C15.6218 18.4812 15.4855 19.0448 15.0547 19.332C14.6238 19.6193 14.0508 19.5282 13.7285 19.1367L13.668 19.0547L13.2627 18.4326C12.8412 17.7703 12.3781 16.9924 11.9844 16.2061C11.4619 17.2978 10.8292 18.309 10.332 19.0547C10.0257 19.5142 9.40486 19.6384 8.94533 19.332C8.4858 19.0257 8.36163 18.4048 8.66798 17.9453C9.15666 17.2123 9.75032 16.2592 10.2197 15.2617C10.6385 14.372 10.9221 13.5218 10.9863 12.8008L11 12.5H7.00002C6.44774 12.5 6.00002 12.0523 6.00002 11.5C6.00002 10.9477 6.44774 10.5 7.00002 10.5H17Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M12 4C12.7957 4 13.5585 4.3163 14.1211 4.87891C14.6837 5.44152 15 6.20435 15 7C15 7.79565 14.6837 8.55848 14.1211 9.12109C13.5585 9.6837 12.7957 10 12 10C11.2044 10 10.4415 9.6837 9.87892 9.12109C9.31631 8.55848 9.00002 7.79565 9.00002 7C9.00002 6.20435 9.31631 5.44152 9.87892 4.87891C10.4415 4.3163 11.2044 4 12 4ZM12 6C11.7348 6 11.4805 6.10543 11.293 6.29297C11.1054 6.4805 11 6.73478 11 7C11 7.26522 11.1054 7.5195 11.293 7.70703C11.4805 7.89457 11.7348 8 12 8C12.2652 8 12.5195 7.89457 12.707 7.70703C12.8946 7.5195 13 7.26522 13 7C13 6.73478 12.8946 6.48051 12.707 6.29297C12.5195 6.10543 12.2652 6 12 6Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M12 1C18.0751 1 23 5.92487 23 12C23 18.0751 18.0751 23 12 23C5.92488 23 1.00002 18.0751 1.00002 12C1.00002 5.92487 5.92488 1 12 1ZM12 3C7.02945 3 3.00002 7.02944 3.00002 12C3.00002 16.9706 7.02945 21 12 21C16.9706 21 21 16.9706 21 12C21 7.02944 16.9706 3 12 3Z"/></symbol><symbol id="icon-eds-i-book-research-medium"><path fill-rule="evenodd" d="M9.99.952c.922 0 1.822.273 2.589.784l2.42 1.614 2.421-1.614a4.667 4.667 0 0 1 2.283-.774l.306-.01h6.324a3.333 3.333 0 0 1 3.333 3.334v8.666a1.333 1.333 0 0 1-2.666 0V4.286a.667.667 0 0 0-.667-.667h-6.324a2 2 0 0 0-1.11.336l-2.566 1.71v5.954a1.333 1.333 0 1 1-2.667 0V5.666L11.1 3.955a2 2 0 0 0-1.11-.336H3.666A.667.667 0 0 0 3 4.286v17.333c0 .368.298.667.666.667h10a1.333 1.333 0 1 1 0 2.666h-10A3.333 3.333 0 0 1 .333 21.62V4.286A3.333 3.333 0 0 1 3.666.952H9.99Zm12.343 13.334a6 6 0 0 1 5.08 9.193l1.863 1.864a1.333 1.333 0 1 1-1.886 1.886l-1.864-1.863a6 6 0 1 1-3.193-11.08Zm-3.333 6a3.333 3.333 0 1 1 6.666 0 3.333 3.333 0 0 1-6.666 0Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-copy-link" viewBox="0 0 24 24"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.4594 8.57015C19.0689 8.17963 19.0689 7.54646 19.4594 7.15594L20.2927 6.32261C20.2927 6.32261 20.2927 6.32261 20.2927 6.32261C21.0528 5.56252 21.0528 4.33019 20.2928 3.57014C19.5327 2.81007 18.3004 2.81007 17.5404 3.57014L16.7071 4.40347C16.3165 4.794 15.6834 4.794 15.2928 4.40348C14.9023 4.01296 14.9023 3.3798 15.2928 2.98927L16.1262 2.15594C17.6673 0.614803 20.1659 0.614803 21.707 2.15593C23.2481 3.69705 23.248 6.19569 21.707 7.7368L20.8737 8.57014C20.4831 8.96067 19.85 8.96067 19.4594 8.57015Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M18.0944 5.90592C18.4849 6.29643 18.4849 6.9296 18.0944 7.32013L16.4278 8.9868C16.0373 9.37733 15.4041 9.37734 15.0136 8.98682C14.6231 8.59631 14.6231 7.96314 15.0136 7.57261L16.6802 5.90594C17.0707 5.51541 17.7039 5.5154 18.0944 5.90592Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5113 6.32243C13.9018 6.71295 13.9018 7.34611 13.5113 7.73664L12.678 8.56997C12.678 8.56997 12.678 8.56997 12.678 8.56997C11.9179 9.33006 11.9179 10.5624 12.6779 11.3224C13.438 12.0825 14.6703 12.0825 15.4303 11.3224L16.2636 10.4891C16.6542 10.0986 17.2873 10.0986 17.6779 10.4891C18.0684 10.8796 18.0684 11.5128 17.6779 11.9033L16.8445 12.7366C15.3034 14.2778 12.8048 14.2778 11.2637 12.7366C9.72262 11.1955 9.72266 8.69689 11.2637 7.15578L12.097 6.32244C12.4876 5.93191 13.1207 5.93191 13.5113 6.32243Z"/><path d="M8 20V22H19.4619C20.136 22 20.7822 21.7311 21.2582 21.2529C21.7333 20.7757 22 20.1289 22 19.4549V15C22 14.4477 21.5523 14 21 14C20.4477 14 20 14.4477 20 15V19.4549C20 19.6004 19.9426 19.7397 19.8408 19.842C19.7399 19.9433 19.6037 20 19.4619 20H8Z"/><path d="M4 13H2V19.4619C2 20.136 2.26889 20.7822 2.74705 21.2582C3.22434 21.7333 3.87105 22 4.5451 22H9C9.55228 22 10 21.5523 10 21C10 20.4477 9.55228 20 9 20H4.5451C4.39957 20 4.26028 19.9426 4.15804 19.8408C4.05668 19.7399 4 19.6037 4 19.4619V13Z"/><path d="M4 13H2V4.53808C2 3.86398 2.26889 3.21777 2.74705 2.74178C3.22434 2.26666 3.87105 2 4.5451 2H9C9.55228 2 10 2.44772 10 3C10 3.55228 9.55228 4 9 4H4.5451C4.39957 4 4.26028 4.05743 4.15804 4.15921C4.05668 4.26011 4 4.39633 4 4.53808V13Z"/></symbol><symbol id="icon-eds-i-funding-dollar" viewBox="0 0 32 32"><path d="M17.333 7.79549V9.21808C18.3681 9.32469 19.2889 9.82002 19.9444 10.5523C20.2938 10.9427 20.5697 11.4022 20.7488 11.9089C20.9942 12.6031 20.6303 13.3649 19.936 13.6103C19.2418 13.8558 18.48 13.4919 18.2346 12.7976C18.1735 12.6249 18.0788 12.4665 17.9574 12.3308C17.6988 12.0419 17.3272 11.8632 16.9122 11.8632H16.042C16.028 11.8636 16.0139 11.8639 15.9997 11.8639C15.9907 11.8639 15.9817 11.8638 15.9727 11.8636C15.9676 11.8635 15.9624 11.8634 15.9573 11.8632H14.7952C14.1833 11.8632 13.6872 12.3593 13.6872 12.9713C13.6872 13.492 14.0498 13.9424 14.5584 14.0537L17.7816 14.7588C19.6498 15.1675 20.9806 16.8226 20.9806 18.734C20.9806 20.8383 19.3827 22.5712 17.333 22.7819V24.2051C17.333 24.9415 16.7361 25.5384 15.9997 25.5384C15.2633 25.5384 14.6663 24.9415 14.6663 24.2051V22.7817C13.0793 22.618 11.7653 21.5424 11.2524 20.091C11.007 19.3967 11.3709 18.635 12.0651 18.3896C12.7594 18.1442 13.5212 18.5081 13.7666 19.2024C13.9597 19.7486 14.4807 20.1367 15.0889 20.1367H15.9849C15.9898 20.1367 15.9947 20.1366 15.9997 20.1366C16.0046 20.1366 16.0095 20.1367 16.0144 20.1367H16.9122C17.6857 20.1367 18.3139 19.5088 18.3139 18.734C18.3139 18.0748 17.8548 17.5045 17.2118 17.3639L13.9886 16.6588C12.2557 16.2797 11.0205 14.7451 11.0205 12.9713C11.0205 10.9297 12.6413 9.26664 14.6663 9.19869V7.79549C14.6663 7.05911 15.2633 6.46216 15.9997 6.46216C16.7361 6.46216 17.333 7.05911 17.333 7.79549Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M15.9997 1.33325C7.8995 1.33325 1.33301 7.89974 1.33301 15.9999C1.33301 24.1002 7.89951 30.6666 15.9997 30.6666C24.1 30.6666 30.6663 24.1002 30.6663 15.9999C30.6663 7.89975 24.1 1.33325 15.9997 1.33325ZM3.99967 15.9999C3.99967 9.3725 9.37226 3.99992 15.9997 3.99992C22.6272 3.99992 27.9997 9.3725 27.9997 15.9999C27.9997 22.6274 22.6272 27.9999 15.9997 27.9999C9.37225 27.9999 3.99967 22.6274 3.99967 15.9999Z"/></symbol><symbol id="icon-eds-i-github-medium" viewBox="0 0 24 24"><path d="M 11.964844 0 C 5.347656 0 0 5.269531 0 11.792969 C 0 17.003906 3.425781 21.417969 8.179688 22.976562 C 8.773438 23.09375 8.992188 22.722656 8.992188 22.410156 C 8.992188 22.136719 8.972656 21.203125 8.972656 20.226562 C 5.644531 20.929688 4.953125 18.820312 4.953125 18.820312 C 4.417969 17.453125 3.625 17.101562 3.625 17.101562 C 2.535156 16.378906 3.703125 16.378906 3.703125 16.378906 C 4.914062 16.457031 5.546875 17.589844 5.546875 17.589844 C 6.617188 19.386719 8.339844 18.878906 9.03125 18.566406 C 9.132812 17.804688 9.449219 17.277344 9.785156 16.984375 C 7.132812 16.710938 4.339844 15.695312 4.339844 11.167969 C 4.339844 9.878906 4.8125 8.824219 5.566406 8.003906 C 5.445312 7.710938 5.03125 6.5 5.683594 4.878906 C 5.683594 4.878906 6.695312 4.566406 8.972656 6.089844 C 9.949219 5.832031 10.953125 5.703125 11.964844 5.699219 C 12.972656 5.699219 14.003906 5.835938 14.957031 6.089844 C 17.234375 4.566406 18.242188 4.878906 18.242188 4.878906 C 18.898438 6.5 18.480469 7.710938 18.363281 8.003906 C 19.136719 8.824219 19.589844 9.878906 19.589844 11.167969 C 19.589844 15.695312 16.796875 16.691406 14.125 16.984375 C 14.558594 17.355469 14.933594 18.058594 14.933594 19.171875 C 14.933594 20.753906 14.914062 22.019531 14.914062 22.410156 C 14.914062 22.722656 15.132812 23.09375 15.726562 22.976562 C 20.480469 21.414062 23.910156 17.003906 23.910156 11.792969 C 23.929688 5.269531 18.558594 0 11.964844 0 Z M 11.964844 0 "/></symbol><symbol id="icon-eds-i-institution-medium" viewBox="0 0 24 24"><g><path fill-rule="evenodd" clip-rule="evenodd" d="M11.9967 1C11.6364 1 11.279 1.0898 10.961 1.2646C10.9318 1.28061 10.9035 1.29806 10.8761 1.31689L2.79765 6.87C2.46776 7.08001 2.20618 7.38466 2.07836 7.76668C1.94823 8.15561 1.98027 8.55648 2.12665 8.90067C2.42086 9.59246 3.12798 10 3.90107 10H4.99994V16H4.49994C3.11923 16 1.99994 17.1193 1.99994 18.5V19.5C1.99994 20.8807 3.11923 22 4.49994 22H19.4999C20.8807 22 21.9999 20.8807 21.9999 19.5V18.5C21.9999 17.1193 20.8807 16 19.4999 16H18.9999V10H20.0922C20.8653 10 21.5725 9.59252 21.8667 8.90065C22.0131 8.55642 22.0451 8.15553 21.9149 7.7666C21.7871 7.38459 21.5255 7.07997 21.1956 6.86998L13.1172 1.31689C13.0898 1.29806 13.0615 1.28061 13.0324 1.2646C12.7143 1.0898 12.357 1 11.9967 1ZM4.6844 8L11.9472 3.00755C11.9616 3.00295 11.9783 3 11.9967 3C12.015 3 12.0318 3.00295 12.0461 3.00755L19.3089 8H4.6844ZM16.9999 16V10H14.9999V16H16.9999ZM12.9999 16V10H10.9999V16H12.9999ZM8.99994 16V10H6.99994V16H8.99994ZM3.99994 18.5C3.99994 18.2239 4.2238 18 4.49994 18H19.4999C19.7761 18 19.9999 18.2239 19.9999 18.5V19.5C19.9999 19.7761 19.7761 20 19.4999 20H4.49994C4.2238 20 3.99994 19.7761 3.99994 19.5V18.5Z"/></g></symbol><symbol id="icon-eds-i-limited-access" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 3v3a1 1 0 0 1-2 0V2.923C2 1.875 2.84 1 3.909 1h5.909a1 1 0 0 1 .713.298l3.181 3.231a1 1 0 0 1 .288.702V6a1 1 0 1 1-2 0v-.36L9.4 3H4ZM3 8a1 1 0 0 1 1 1v1a1 1 0 1 1-2 0V9a1 1 0 0 1 1-1Zm10 0a1 1 0 0 1 1 1v1a1 1 0 1 1-2 0V9a1 1 0 0 1 1-1Zm-3.5 6a1 1 0 0 1-1 1h-1a1 1 0 1 1 0-2h1a1 1 0 0 1 1 1Zm2.441-1a1 1 0 0 1 2 0c0 .73-.246 1.306-.706 1.664a1.61 1.61 0 0 1-.876.334l-.032.002H11.5a1 1 0 1 1 0-2h.441ZM4 13a1 1 0 0 0-2 0c0 .73.247 1.306.706 1.664a1.609 1.609 0 0 0 .876.334l.032.002H4.5a1 1 0 1 0 0-2H4Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-rss" viewBox="0 0 22 22"><path d="M1.96094 1C1.96094 0.447715 2.40865 0 2.96094 0C5.46109 0 7.93678 0.492038 10.2467 1.44806C12.5565 2.40407 14.6554 3.80534 16.4234 5.57189C18.1913 7.33843 19.5939 9.4357 20.5508 11.744C21.5077 14.0522 22.0001 16.5263 22.0001 19.0247C22.0001 19.577 21.5524 20.0247 21.0001 20.0247C20.4478 20.0247 20.0001 19.577 20.0001 19.0247C20.0001 16.7891 19.5595 14.5753 18.7033 12.5098C17.8471 10.4444 16.5919 8.56762 15.0097 6.98666C13.4275 5.40575 11.5492 4.15167 9.48182 3.29604C7.41447 2.4404 5.19868 2 2.96094 2C2.40865 2 1.96094 1.55228 1.96094 1Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M0 18.649C0 16.7974 1.50196 15.298 3.35294 15.298C5.20392 15.298 6.70588 16.7974 6.70588 18.649C6.70588 20.5003 5.20397 22 3.35294 22C1.50191 22 0 20.5003 0 18.649ZM3.35294 17.298C2.60493 17.298 2 17.9036 2 18.649C2 19.3943 2.60498 20 3.35294 20C4.1009 20 4.70588 19.3943 4.70588 18.649C4.70588 17.9036 4.10095 17.298 3.35294 17.298Z"/><path d="M3.3374 7.46115C2.78512 7.46115 2.3374 7.90887 2.3374 8.46115C2.3374 9.01344 2.78512 9.46115 3.3374 9.46115C4.54515 9.46115 5.74107 9.69885 6.85684 10.1606C7.97262 10.6224 8.98639 11.2993 9.84028 12.1525C10.6942 13.0057 11.3715 14.0185 11.8336 15.1332C12.2956 16.2478 12.5335 17.4424 12.5335 18.649C12.5335 19.2013 12.9812 19.649 13.5335 19.649C14.0858 19.649 14.5335 19.2013 14.5335 18.649C14.5335 17.1796 14.2438 15.7247 13.6811 14.3673C13.1184 13.0099 12.2936 11.7765 11.2539 10.7377C10.2142 9.69885 8.97999 8.87484 7.62168 8.31266C6.26337 7.75049 4.80757 7.46115 3.3374 7.46115Z"/></symbol><symbol id="icon-eds-i-search-category-medium" viewBox="0 0 32 32"><path fill-rule="evenodd" d="M2 5.306A3.306 3.306 0 0 1 5.306 2h5.833a3.306 3.306 0 0 1 3.306 3.306v5.833a3.306 3.306 0 0 1-3.306 3.305H5.306A3.306 3.306 0 0 1 2 11.14V5.306Zm3.306-.584a.583.583 0 0 0-.584.584v5.833c0 .322.261.583.584.583h5.833a.583.583 0 0 0 .583-.583V5.306a.583.583 0 0 0-.583-.584H5.306Zm15.555 8.945a7.194 7.194 0 1 0 4.034 13.153l2.781 2.781a1.361 1.361 0 1 0 1.925-1.925l-2.781-2.781a7.194 7.194 0 0 0-5.958-11.228Zm3.173 10.346a4.472 4.472 0 1 0-.021.021l.01-.01.011-.011Zm-5.117-19.29a.583.583 0 0 0-.584.583v5.833a1.361 1.361 0 0 1-2.722 0V5.306A3.306 3.306 0 0 1 18.917 2h5.833a3.306 3.306 0 0 1 3.306 3.306v5.833c0 .6-.161 1.166-.443 1.654a1.361 1.361 0 1 1-2.357-1.363.575.575 0 0 0 .078-.291V5.306a.583.583 0 0 0-.584-.584h-5.833ZM2 18.916a3.306 3.306 0 0 1 3.306-3.306h5.833a1.361 1.361 0 1 1 0 2.722H5.306a.583.583 0 0 0-.584.584v5.833c0 .322.261.583.584.583h5.833a.574.574 0 0 0 .29-.077 1.361 1.361 0 1 1 1.364 2.356 3.296 3.296 0 0 1-1.654.444H5.306A3.306 3.306 0 0 1 2 24.75v-5.833Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-search-magic" viewBox="0 0 20 20"><path d="M8.695 1.667a9.1 9.1 0 0 1 1.756.17A3.098 3.098 0 0 0 9.436 3.37a7.333 7.333 0 0 0-.738-.038c-3.841 0-6.956 2.986-6.956 6.668 0 3.681 3.115 6.665 6.956 6.665 3.642 0 6.627-2.681 6.928-6.096a3.19 3.19 0 0 0 1.763-.548 8.091 8.091 0 0 1-1.961 5.25l3.446 3.306a.81.81 0 0 1 0 1.178.897.897 0 0 1-1.23 0l-3.447-3.303a8.892 8.892 0 0 1-5.502 1.88C3.893 18.334 0 14.603 0 10c0-4.603 3.893-8.333 8.695-8.334Z"/><path d="M20 4.166a.663.663 0 0 1-.128.395.709.709 0 0 1-.342.251l-2.341.827-.863 2.244a.693.693 0 0 1-.263.326.74.74 0 0 1-.821 0 .693.693 0 0 1-.264-.326l-.862-2.244-2.341-.827a.715.715 0 0 1-.341-.252.669.669 0 0 1 0-.787.715.715 0 0 1 .34-.252l2.342-.827.862-2.244a.693.693 0 0 1 .264-.327.74.74 0 0 1 .821 0 .7.7 0 0 1 .263.327l.863 2.244 2.34.827a.709.709 0 0 1 .343.251.663.663 0 0 1 .128.394Z"/></symbol><symbol id="icon-eds-i-subjects-medium" viewBox="0 0 24 24"><g id="icon-subjects-copy" stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.3846154,2 C14.7015971,2 15.7692308,3.06762994 15.7692308,4.38461538 L15.7692308,7.15384615 C15.7692308,8.47082629 14.7015955,9.53846154 13.3846154,9.53846154 L13.1038388,9.53925278 C13.2061091,9.85347965 13.3815528,10.1423885 13.6195822,10.3804178 C13.9722182,10.7330539 14.436524,10.9483278 14.9293854,10.9918129 L15.1153846,11 C16.2068332,11 17.2535347,11.433562 18.0254647,12.2054189 C18.6411944,12.8212361 19.0416785,13.6120766 19.1784166,14.4609738 L19.6153846,14.4615385 C20.932386,14.4615385 22,15.5291672 22,16.8461538 L22,19.6153846 C22,20.9323924 20.9323924,22 19.6153846,22 L16.8461538,22 C15.5291672,22 14.4615385,20.932386 14.4615385,19.6153846 L14.4615385,16.8461538 C14.4615385,15.5291737 15.5291737,14.4615385 16.8461538,14.4615385 L17.126925,14.460779 C17.0246537,14.1465537 16.8492179,13.857633 16.6112344,13.6196157 C16.2144418,13.2228606 15.6764136,13 15.1153846,13 C14.0239122,13 12.9771569,12.5664197 12.2053686,11.7946314 C12.1335167,11.7227795 12.0645962,11.6485444 11.9986839,11.5721119 C11.9354038,11.6485444 11.8664833,11.7227795 11.7946314,11.7946314 C11.0228431,12.5664197 9.97608778,13 8.88461538,13 C8.323576,13 7.78552852,13.2228666 7.38881294,13.6195822 C7.15078359,13.8576115 6.97533988,14.1465203 6.8730696,14.4607472 L7.15384615,14.4615385 C8.47082629,14.4615385 9.53846154,15.5291737 9.53846154,16.8461538 L9.53846154,19.6153846 C9.53846154,20.932386 8.47083276,22 7.15384615,22 L4.38461538,22 C3.06762347,22 2,20.9323876 2,19.6153846 L2,16.8461538 C2,15.5291721 3.06762994,14.4615385 4.38461538,14.4615385 L4.8215823,14.4609378 C4.95831893,13.6120029 5.3588057,12.8211623 5.97459937,12.2053686 C6.69125996,11.488708 7.64500941,11.0636656 8.6514968,11.0066017 L8.88461538,11 C9.44565477,11 9.98370225,10.7771334 10.3804178,10.3804178 C10.6184472,10.1423885 10.7938909,9.85347965 10.8961612,9.53925278 L10.6153846,9.53846154 C9.29840448,9.53846154 8.23076923,8.47082629 8.23076923,7.15384615 L8.23076923,4.38461538 C8.23076923,3.06762994 9.29840286,2 10.6153846,2 L13.3846154,2 Z M7.15384615,16.4615385 L4.38461538,16.4615385 C4.17220099,16.4615385 4,16.63374 4,16.8461538 L4,19.6153846 C4,19.8278134 4.17218833,20 4.38461538,20 L7.15384615,20 C7.36626945,20 7.53846154,19.8278103 7.53846154,19.6153846 L7.53846154,16.8461538 C7.53846154,16.6337432 7.36625679,16.4615385 7.15384615,16.4615385 Z M19.6153846,16.4615385 L16.8461538,16.4615385 C16.6337432,16.4615385 16.4615385,16.6337432 16.4615385,16.8461538 L16.4615385,19.6153846 C16.4615385,19.8278103 16.6337306,20 16.8461538,20 L19.6153846,20 C19.8278229,20 20,19.8278229 20,19.6153846 L20,16.8461538 C20,16.6337306 19.8278103,16.4615385 19.6153846,16.4615385 Z M13.3846154,4 L10.6153846,4 C10.4029708,4 10.2307692,4.17220099 10.2307692,4.38461538 L10.2307692,7.15384615 C10.2307692,7.36625679 10.402974,7.53846154 10.6153846,7.53846154 L13.3846154,7.53846154 C13.597026,7.53846154 13.7692308,7.36625679 13.7692308,7.15384615 L13.7692308,4.38461538 C13.7692308,4.17220099 13.5970292,4 13.3846154,4 Z" id="Shape" fill-rule="nonzero"/></g></symbol><symbol id="icon-eds-small-arrow-left" viewBox="0 0 16 17"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14 8.092H2m0 0L8 2M2 8.092l6 6.035"/></symbol><symbol id="icon-eds-small-arrow-right" viewBox="0 0 16 16"><g fill-rule="evenodd" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M2 8.092h12M8 2l6 6.092M8 14.127l6-6.035"/></g></symbol><symbol id="icon-globe-with-star" viewBox="0 0 32 32"><path style="fill:none;stroke:#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M27.282 17.026c0 6.797-5.51 12.307-12.307 12.307-6.798 0-12.308-5.51-12.308-12.307 0-6.798 5.51-12.308 12.308-12.308M2.667 17.026h14.201"/><path style="fill:none;stroke:#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14.975 4.718a21.244 21.244 0 0 0-4.734 12.308c.233 4.5 1.89 8.81 4.734 12.307a21.245 21.245 0 0 0 4.394-9.467M17.045 9.72c-.709-.126-.709-1.16 0-1.286 2.568-.454 4.61-2.443 5.168-5.032l.043-.199c.153-.712 1.15-.716 1.31-.006l.052.232c.578 2.577 2.621 4.549 5.182 5.002.712.126.712 1.166 0 1.292-2.561.453-4.604 2.425-5.182 5.002l-.052.231c-.16.711-1.157.707-1.31-.005l-.043-.199c-.557-2.59-2.6-4.578-5.168-5.032Z"/></symbol><symbol id="icon-orcid-logo" viewBox="0 0 40 40"><path fill-rule="evenodd" d="M12.281 10.453c.875 0 1.578-.719 1.578-1.578 0-.86-.703-1.578-1.578-1.578-.875 0-1.578.703-1.578 1.578 0 .86.703 1.578 1.578 1.578Zm-1.203 18.641h2.406V12.359h-2.406v16.735Z"/><path fill-rule="evenodd" d="M17.016 12.36h6.5c6.187 0 8.906 4.421 8.906 8.374 0 4.297-3.36 8.375-8.875 8.375h-6.531V12.36Zm6.234 14.578h-3.828V14.53h3.703c4.688 0 6.828 2.844 6.828 6.203 0 2.063-1.25 6.203-6.703 6.203Z" clip-rule="evenodd"/></symbol><symbol id="icon-thumbs-down" viewBox="41 0 33 33"><path stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M61 17.611h-1l-2.085 4.436a1 1 0 0 1-.366.332 1.04 1.04 0 0 1-1.197-.159.95.95 0 0 1-.298-.678v-3.32h-3.93c-.61 0-.674-1.066-.599-1.55l.726-4.301a.98.98 0 0 1 .341-.622 1.06 1.06 0 0 1 .685-.249H61M63.5 11.5v6"/></symbol><symbol id="icon-thumbs-up-medium" viewBox="0 0 24 24"><path d="M6.75 9.33333H8.25L11.3778 2.67913C11.5138 2.47128 11.7025 2.29994 11.9263 2.18116C12.1502 2.06239 12.4018 2.00005 12.6576 2C13.056 1.99999 13.4384 2.15092 13.7214 2.41998C14.0044 2.68903 14.1652 3.05442 14.1688 3.43663V8.41667C16.1342 8.41667 18.1116 8.41667 20.0648 8.41667C20.9795 8.41667 21.0744 10.0164 20.9625 10.7422L19.8733 17.194C19.8269 17.5542 19.6449 17.8856 19.3616 18.1261C19.0783 18.3667 18.7132 18.4996 18.3349 18.5H6.75" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M3 18.5V9.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></symbol><symbol id="icon-thumbs-up"><path stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 15.389h1l2.085-4.436a1 1 0 0 1 .366-.332 1.04 1.04 0 0 1 1.197.159.95.95 0 0 1 .298.678v3.32h3.93c.61 0 .674 1.066.599 1.55l-.726 4.301a.98.98 0 0 1-.341.622 1.06 1.06 0 0 1-.685.249H13m-2.5 0v-6"/></symbol><symbol id="icon-tick-with-curly-circle" viewBox="0 0 40 40"><path d="M17.923.757a3.227 3.227 0 0 1 4.401.231l2.168 2.25 3.001-.866.33-.076a3.23 3.23 0 0 1 3.598 2.076l.099.325.75 3.03 3.033.753a3.229 3.229 0 0 1 2.4 3.697l-.075.33-.865 3.001 2.249 2.168.231.247a3.227 3.227 0 0 1-.231 4.401l-2.25 2.166.866 3.003.076.33a3.228 3.228 0 0 1-2.401 3.697l-3.033.75-.75 3.033a3.229 3.229 0 0 1-4.027 2.325l-3.001-.867-2.168 2.25a3.227 3.227 0 0 1-4.648 0l-2.17-2.25-2.999.867a3.229 3.229 0 0 1-4.027-2.325l-.752-3.033-3.03-.75a3.229 3.229 0 0 1-2.326-4.027l.865-3.001-2.249-2.168a3.227 3.227 0 0 1 0-4.648l2.25-2.17-.866-2.999A3.229 3.229 0 0 1 4.697 8.48l3.031-.752.752-3.03a3.229 3.229 0 0 1 4.027-2.326l3 .865L17.675.988l.247-.231Zm.027 5.156a3.23 3.23 0 0 1-3.219.864l-2.838-.82-.712 2.87a3.227 3.227 0 0 1-2.355 2.354l-2.868.712.819 2.838a3.23 3.23 0 0 1-.864 3.219L3.786 20l2.127 2.05a3.23 3.23 0 0 1 .864 3.219l-.82 2.837 2.87.713.215.062a3.228 3.228 0 0 1 2.14 2.293l.71 2.867 2.84-.818a3.229 3.229 0 0 1 3.218.864L20 36.214l2.05-2.127.16-.156a3.228 3.228 0 0 1 2.841-.76l.218.052 2.837.818.713-2.867.062-.214a3.227 3.227 0 0 1 2.293-2.141l2.867-.713-.816-2.837c-.331-1.15 0-2.389.861-3.219L36.212 20l-2.126-2.05a3.229 3.229 0 0 1-.861-3.219l.816-2.838-2.867-.712a3.228 3.228 0 0 1-2.355-2.355l-.713-2.868-2.837.819a3.23 3.23 0 0 1-3.219-.864L20 3.786l-2.05 2.127Z" stroke="transparent" stroke-width=".9"/><path d="M25.723 13.406a1.807 1.807 0 0 1 2.699 2.397l-9.658 12.074a1.808 1.808 0 0 1-2.497.316L11.44 24.57a1.806 1.806 0 1 1 2.168-2.892l3.427 2.57 8.565-10.704.124-.138Z" stroke="transparent" stroke-width=".9"/></symbol></svg>
</div>


        

        
        
    <a class="c-skip-link" href="#main">Skip to main content</a>

    
        
    <aside class="u-lazy-ad-wrapper u-mbs-0" aria-label="Advertisement">
        <div class="c-ad c-ad--728x90 c-ad--conditional" data-test="springer-doubleclick-ad">
            <div class="c-ad c-ad__inner" >
                <p class="c-ad__label">Advertisement</p>
                <div id="div-gpt-ad-LB1"
                     class="div-gpt-ad grade-c-hide"
                     data-gpt
                     data-gpt-unitpath="/270604982/springerlink/10551/article"
                     data-gpt-sizes="728x90"
                     data-gpt-targeting="pos=top;articleid=s10551-023-05339-7;"
                     data-ad-type="top"
                     style="min-width:728px;min-height:90px">
                    
                    <script>
                        window.SN = window.SN || {};
                        window.SN.libs = window.SN.libs || {};
                        window.SN.libs.ads = window.SN.libs.ads || {};
                        window.SN.libs.ads.slotConfig = window.SN.libs.ads.slotConfig || {};
                        window.SN.libs.ads.slotConfig['LB1'] = {
                            'pos': 'top',
                            'type': 'top',
                        };
                        window.SN.libs.ads.slotConfig['unitPath'] = '/270604982/springerlink/10551/article';
                    </script>
                    <noscript>
                        <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/270604982/springerlink/10551/article&amp;sz=728x90&amp;pos=top&amp;articleid=s10551-023-05339-7">
                            <img data-test="gpt-advert-fallback-img"
                                 src="//pubads.g.doubleclick.net/gampad/ad?iu=/270604982/springerlink/10551/article&amp;sz=728x90&amp;pos=top&amp;articleid=s10551-023-05339-7"
                                 alt="Advertisement"
                                 width="728"
                                 height="90">
                        </a>
                    </noscript>
                </div>
            </div>
        </div>
    </aside>

    

    <header class="eds-c-header" data-eds-c-header>
    <div class="eds-c-header__container" data-eds-c-header-expander-anchor>
        <div class="eds-c-header__brand">
            
                
                    <a href="https://link.springer.com"
                    	 data-test=springerlink-logo
                        
                            data-track="click_imprint_logo"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click logo link"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        <img src="/oscar-static/images/darwin/header/img/logo-springer-nature-link-3149409f62.svg" alt="Springer Nature Link">
                    </a>
                
            
        </div>

        
            
                
    
        <a class="c-header__link eds-c-header__link" id="identity-account-widget" data-track="click_login" data-track-context="header" href='https://idp.springer.com/auth/personal/springernature?redirect_uri=https://link.springer.com/article/10.1007/s10551-023-05339-7'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
    


            
        
    </div>

    
        <nav class="eds-c-header__nav" aria-label="header navigation">
            <div class="eds-c-header__nav-container">
                <div class="eds-c-header__item eds-c-header__item--menu">
                   <a href="#eds-c-header-nav" class="eds-c-header__link" data-eds-c-header-expander>
                        <svg class="eds-c-header__icon" width="24" height="24" aria-hidden="true" focusable="false">
                            <use xlink:href="#icon-eds-i-menu-medium"></use>
                        </svg><span>Menu</span>
                    </a>
                </div>

                <div class="eds-c-header__item eds-c-header__item--inline-links">
                    
                        <a class="eds-c-header__link" href="https://link.springer.com/journals/"
                            
                                data-track="nav_find_a_journal"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click find a journal"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Find a journal
                        </a>
                    
                        <a class="eds-c-header__link" href="https://www.springernature.com/gp/authors"
                            
                                data-track="nav_how_to_publish"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click publish with us link"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Publish with us
                        </a>
                    
                        <a class="eds-c-header__link" href="https://link.springernature.com/home/"
                            
                                data-track="nav_track_your_research"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click track your research"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Track your research
                        </a>
                    
                </div>

                <div class="eds-c-header__link-container">
                    
                        <div class="eds-c-header__item eds-c-header__item--divider">
                            <a href="#eds-c-header-popup-search" class="eds-c-header__link" data-eds-c-header-expander data-eds-c-header-test-search-btn>
                                <svg class="eds-c-header__icon" width="24" height="24" aria-hidden="true" focusable="false">
                                    <use xlink:href="#icon-eds-i-search-medium"></use>
                                </svg><span>Search</span>
                            </a>
                        </div>
                    
                    
                        <div id="ecommerce-header-cart-icon-link" class="eds-c-header__item ecommerce-cart" style="display:inline-block">
 <a class="eds-c-header__link" href="https://order.springer.com/public/cart" style="appearance:none;border:none;background:none;color:inherit;position:relative">
  <svg id="eds-i-cart" class="eds-c-header__icon" xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 24 24" aria-hidden="true" focusable="false">
   <path fill="currentColor" fill-rule="nonzero" d="M2 1a1 1 0 0 0 0 2l1.659.001 2.257 12.808a2.599 2.599 0 0 0 2.435 2.185l.167.004 9.976-.001a2.613 2.613 0 0 0 2.61-1.748l.03-.106 1.755-7.82.032-.107a2.546 2.546 0 0 0-.311-1.986l-.108-.157a2.604 2.604 0 0 0-2.197-1.076L6.042 5l-.56-3.17a1 1 0 0 0-.864-.82l-.12-.007L2.001 1ZM20.35 6.996a.63.63 0 0 1 .54.26.55.55 0 0 1 .082.505l-.028.1L19.2 15.63l-.022.05c-.094.177-.282.299-.526.317l-10.145.002a.61.61 0 0 1-.618-.515L6.394 6.999l13.955-.003ZM18 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4ZM8 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"></path>
  </svg>
  <span>Cart</span><span class="cart-info" style="display:none;position:absolute;top:10px;right:45px;background-color:#C65301;color:#fff;width:18px;height:18px;font-size:11px;border-radius:50%;line-height:17.5px;text-align:center"></span>
 </a>
 <script>(function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    document.body.addEventListener("updatedCart", function () {
        updateCartIcon();
    }, false);
    return updateCartIcon();
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function (_) { });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart.springer.com/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()</script>
</div>
                    
                </div>
            </div>
        </nav>
    
</header>



    <article lang="en" id="main" class="app-masthead__colour-21">
        <section class="app-masthead " aria-label="article masthead">
    <div class="app-masthead__container">
        
            <div class="app-article-masthead u-sans-serif js-context-bar-sticky-point-masthead" data-track-component="article" data-test="masthead-component">
                <div class="app-article-masthead__info">
                    
    
        <nav aria-label="breadcrumbs" data-test="breadcrumbs">
            <ol class="c-breadcrumbs c-breadcrumbs--contrast" itemscope itemtype="https://schema.org/BreadcrumbList">
                
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/" class="c-breadcrumbs__link" itemprop="item" data-track="click_breadcrumb" data-track-context="article page"  data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb1"><span itemprop="name">Home</span></a><meta itemprop="position" content="1">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" width="10" height="10" viewBox="0 0 10 10">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/journal/10551" class="c-breadcrumbs__link" itemprop="item" data-track="click_breadcrumb" data-track-context="article page"  data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb2"><span itemprop="name">Journal of Business Ethics</span></a><meta itemprop="position" content="2">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" width="10" height="10" viewBox="0 0 10 10">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <span itemprop="name">Article</span><meta itemprop="position" content="3">
                    </li>
                
            </ol>
        </nav>
    

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work</h1>

                    <ul class="c-article-identifiers">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Original Paper</li>
    
        <li class="c-article-identifiers__item">
            <a href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research" data-track="click" data-track-action="open access" data-track-label="link" class="u-color-open-access" data-test="open-access">Open access</a>
        </li>
    
    

                        <li class="c-article-identifiers__item">
                            Published: <time datetime="2023-02-11">11 February 2023</time>
                        </li>
                    </ul>
                    <ul class="c-article-identifiers c-article-identifiers--cite-list">
                        <li class="c-article-identifiers__item">
                            <span data-test="journal-volume">Volume 185</span>, pages 725–740, (<span data-test="article-publication-year">2023</span>)
                        </li>
                        <li class="c-article-identifiers__item c-article-identifiers__item--cite">
                            <a href="#citeas" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                        </li>
                    </ul>

                    <div class="app-article-masthead__buttons" data-test="download-article-link-wrapper" data-track-context="masthead">
                        <p class="app-article-masthead__access">
                            <svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-check-filled-medium"></use></svg>
                            You have full access to this <a href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research" data-track="click" data-track-action="open access" data-track-label="link">open access</a> article</p>
                        
                        
        <div class="c-pdf-container">
            <div class="c-pdf-download u-clear-both u-mb-16">
                <a href="/content/pdf/10.1007/s10551-023-05339-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="content_download" data-track-type="article pdf download" data-track-action="download pdf" data-track-label="button" data-track-external download>
                    
                        <span class="c-pdf-download__text">Download PDF</span>
                        <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-eds-i-download-medium"/></svg>
                    
                </a>
            </div>
        </div>
    

                        
                    </div>
                </div>
                <div class="app-article-masthead__brand">
                    
                        
                            <a href="/journal/10551"
                        
                           class="app-article-masthead__journal-link"
                           data-track="click_journal_home"
                           data-track-action="journal homepage"
                           data-track-context="article page"
                           data-track-label="link">
                            <picture>
                                <source type="image/webp" media="(min-width: 768px)" width="120" height="159"
                                        srcset="https://media.springernature.com/w120/springer-static/cover-hires/journal/10551?as=webp,
                                                    https://media.springernature.com/w316/springer-static/cover-hires/journal/10551?as=webp 2x">
                                <img width="72" height="95"
                                     src="https://media.springernature.com/w72/springer-static/cover-hires/journal/10551?as=webp"
                                     srcset="https://media.springernature.com/w144/springer-static/cover-hires/journal/10551?as=webp 2x" alt="">
                            </picture>
                            <span class="app-article-masthead__journal-title">Journal of Business Ethics</span>
                        </a>
                        
                            <a href="/journal/10551/aims-and-scope" class="app-article-masthead__submission-link"
                               data-track="click_aims_and_scope"
                               data-track-action="aims and scope"
                               data-track-context="article page"
                               data-track-label="link">
                                Aims and scope
                                <svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-arrow-right-medium"></use></svg>
                            </a>
                        
                        
                            <a href="https://www.editorialmanager.com/busi" class="app-article-masthead__submission-link"
                               data-track="click_submit_manuscript"
                               data-track-context="article masthead on springerlink article page"
                               data-track-action="submit manuscript"
                               data-track-label="link">
                                Submit manuscript
                                <svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-arrow-right-medium"></use></svg>
                            </a>
                        
                    
                </div>
            </div>
        
    </div>
</section>

        <div class="c-article-main u-container u-mt-24 u-mb-32 l-with-sidebar" id="main-content"
             data-component="article-container">
            <main class="u-serif js-main-column" data-track-component="article body">
                
                
                    <div class="c-context-bar u-hide"
                         data-test="context-bar"
                         data-context-bar
                         aria-hidden="true">
                        <div class="c-context-bar__container u-container">
                            <div class="c-context-bar__title">
                                The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work
                            </div>
                            
                                <div data-test="inCoD" data-track-context="sticky banner">
                                    
        <div class="c-pdf-container">
            <div class="c-pdf-download u-clear-both u-mb-16">
                <a href="/content/pdf/10.1007/s10551-023-05339-7.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="content_download" data-track-type="article pdf download" data-track-action="download pdf" data-track-label="button" data-track-external download>
                    
                        <span class="c-pdf-download__text">Download PDF</span>
                        <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-eds-i-download-medium"/></svg>
                    
                </a>
            </div>
        </div>
    

                                    
                                </div>
                            
                        </div>
                    </div>
                

                <div class="c-article-header">
                    <header>
                        <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="1_2" data-track-context="researcher popup with no profile" href="#auth-Sarah-Bankins-Aff1" data-author-popup="auth-Sarah-Bankins-Aff1" data-author-search="Bankins, Sarah" data-corresp-id="c1">Sarah Bankins<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="https://orcid.org/0000-0003-2290-3086"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-2290-3086</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="2_2" data-track-context="researcher popup with no profile" href="#auth-Paul-Formosa-Aff2" data-author-popup="auth-Paul-Formosa-Aff2" data-author-search="Formosa, Paul">Paul Formosa</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup> </li></ul>
                        
    


                        <div data-test="article-metrics">
                            
        <ul class="app-article-metrics-bar u-list-reset">
            
                <li class="app-article-metrics-bar__item" data-test="access-count">
                    <p class="app-article-metrics-bar__count"><svg class="u-icon app-article-metrics-bar__icon" width="24" height="24" aria-hidden="true" focusable="false">
                        <use xlink:href="#icon-eds-i-accesses-medium"></use>
                    </svg>156k <span class="app-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="app-article-metrics-bar__item" data-test=citation-count>
                    <p class="app-article-metrics-bar__count"><svg class="u-icon app-article-metrics-bar__icon" width="24" height="24" aria-hidden="true" focusable="false">
                        <use xlink:href="#icon-eds-i-citations-medium"></use>
                    </svg>222 <span class="app-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
                
                    <li class="app-article-metrics-bar__item" data-test="altmetric-score">
                        <p class="app-article-metrics-bar__count"><svg class="u-icon app-article-metrics-bar__icon" width="24" height="24" aria-hidden="true" focusable="false">
                            <use xlink:href="#icon-eds-i-altmetric-medium"></use>
                        </svg>106 <span class="app-article-metrics-bar__label">
                                Altmetric
                                </span></p>
                    </li>
                
            
            
                <li class="app-article-metrics-bar__item">
                    <p class="app-article-metrics-bar__count"><svg class="u-icon app-article-metrics-bar__icon app-article-metrics-bar__icon--mentions" width="24" height="24" aria-hidden="true" focusable="false">
                        <use xlink:href="#icon-eds-i-mentions-medium"></use>
                    </svg>13 <span class="app-article-metrics-bar__label">Mentions</span></p>
                </li>
            
            
                
                    <li class="app-article-metrics-bar__item app-article-metrics-bar__item--metrics">
                        <p class="app-article-metrics-bar__details"><a href="/article/10.1007/s10551-023-05339-7/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Explore all metrics <svg class="u-icon app-article-metrics-bar__arrow-icon" width="24" height="24" aria-hidden="true" focusable="false">
                            <use xlink:href="#icon-eds-i-arrow-right-medium"></use>
                        </svg></a></p>
                    </li>
                
            
        </ul>
    
                        </div>
                        
                        
    <div class="u-mt-32">
    

    
        <div class="u-mb-8 c-status-message c-status-message--boxed c-status-message--info">
            
                <svg class="c-status-message__icon" width="24" height="24" aria-hidden="true" focusable="false">
                    <use xlink:href="#icon-eds-i-info-filled-medium"></use>
                </svg>
            
            <p class="u-mt-0">This article has been <a href="#change-history">updated</a></p>
        </div>
    
    </div>

                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">

                    
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one’s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees’ experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, ‘tending the machine’, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions.
</p></div></div></section>

                    

                    
    


                    

                    <div data-test="cobranding-download">
                        
                    </div>

                    
                        
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-030-63864-1?as&#x3D;webp" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/978-3-030-63864-1_4?fromPaywallRec=false"
                                           data-track="select_recommendations_1"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1007/978-3-030-63864-1_4">Ethical AI at Work : The Social Contract for Artificial Intelligence and Its Implications for the Workplace Psychological Contract
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Chapter</span>
                                        
                                         <span class="c-article-meta-recommendations__date">© 2021</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3Aplaceholder%2Fimages/placeholder-figure-springernature.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/s00146-024-01960-w?fromPaywallRec=false"
                                           data-track="select_recommendations_2"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1007/s00146-024-01960-w">Artificial Intelligence and the future of work
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">18 May 2024</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-031-34107-6?as&#x3D;webp" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/978-3-031-34107-6_4?fromPaywallRec=false"
                                           data-track="select_recommendations_3"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1007/978-3-031-34107-6_4">An Innovative Method to Study the Social Impact of AI on the Work Environment Based on a Multi-dimensional Human-Centred Analysis of the Worker-AI Team
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Chapter</span>
                                        
                                         <span class="c-article-meta-recommendations__date">© 2023</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'NA',
                        timestamp: 1760635379,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                    

                    
                        
    <section class="app-explore-related-subjects" aria-labelledby="content-related-subjects" data-test="subject-content">
        <h3 id="content-related-subjects" class="app-explore-related-subjects__title">Explore related subjects</h3>
        <span class="u-sans-serif u-text-xs u-display-block u-mb-16">Discover the latest articles, books and news in related subjects, suggested using machine learning.</span>
        <ul class="app-explore-related-subjects__list app-explore-related-subjects__list--no-mb" role="list">
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/computer-ethics"  data-track="select_related_subject_1" data-track-context="related subjects from content page" data-track-label="Computer Ethics">Computer Ethics</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/digital-ethics"  data-track="select_related_subject_2" data-track-context="related subjects from content page" data-track-label="Digital Ethics">Digital Ethics</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/engineering-ethics"  data-track="select_related_subject_3" data-track-context="related subjects from content page" data-track-label="Engineering Ethics">Engineering Ethics</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/ethics-of-technology"  data-track="select_related_subject_4" data-track-context="related subjects from content page" data-track-label="Ethics of Technology">Ethics of Technology</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/information-ethics"  data-track="select_related_subject_5" data-track-context="related subjects from content page" data-track-label="Information Ethics">Information Ethics</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/philosophy-of-artificial-intelligence"  data-track="select_related_subject_6" data-track-context="related subjects from content page" data-track-label="Philosophy of Artificial Intelligence">Philosophy of Artificial Intelligence</a>
            </li>
        
        </ul>
    </section>

                    

                    
                        
    <div class="app-card-service" data-test="article-checklist-banner">
        <div>
            <a class="app-card-service__link" data-track="click_presubmission_checklist" data-track-context="article page top of reading companion" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=10551"
            data-test="article-checklist-banner-link">
            <span class="app-card-service__link-text">Use our pre-submission checklist</span>
            <svg class="app-card-service__link-icon" aria-hidden="true" focusable="false"><use xlink:href="#icon-eds-i-arrow-right-small"></use></svg>
            </a>
            <p class="app-card-service__description">Avoid common mistakes on your manuscript.</p>
        </div>
        <div class="app-card-service__icon-container">
            <svg class="app-card-service__icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-clipboard-check-medium"></use>
            </svg>
        </div>
    </div>

                    

                    
                        
                                <div class="main-content">
                                    <section data-title="Introduction"><div class="c-article-section" id="Sec100-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec100">Introduction</h2><div class="c-article-section__content" id="Sec100-content"><p>Increasing organisational use of artificially intelligent (AI) technologies will influence how people experience work (World Economic Forum [WEF], <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="World Economic Forum. (2018). The future of jobs report. Centre for the New Economy and Society: Geneva, Switzerland." href="/article/10.1007/s10551-023-05339-7#ref-CR207" id="ref-link-section-d20450213e513">2018</a>), including how and whether they experience meaningfulness in their work. AI is the ability of computers and other artificial entities to do things typically classified as requiring intelligence were a human to do them, such as reason, plan, problem solve, and learn from experience (Wang, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Wang, P. (2019). On defining artificial intelligence. Journal of Artificial General Intelligence, 10(2), 1–37." href="/article/10.1007/s10551-023-05339-7#ref-CR209" id="ref-link-section-d20450213e516">2019</a>). Meaningful work is the perception that one’s work has worth, significance, or a higher purpose (Michaelson et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Michaelson, C., Pratt, M. G., Grant, A. M., &amp; Dunn, C. P. (2014). Meaningful work: Connecting business ethics and organization studies. Journal of Business Ethics, 121, 77–90." href="/article/10.1007/s10551-023-05339-7#ref-CR53" id="ref-link-section-d20450213e519">2014</a>), and this typically requires the coordinated exercise of varied and complex skills to benefit others. Providing opportunities for meaningful work supports positive outcomes for workers (Allan et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Allan, B. A., Batz-Barbarich, C., Sterling, H. M., &amp; Tay, L. (2019). Outcomes of meaningful work: A meta-analysis. Journal of Management Studies, 56(3), 500–528." href="/article/10.1007/s10551-023-05339-7#ref-CR3" id="ref-link-section-d20450213e522">2019</a>) and is ethically important as a basis for human wellbeing and flourishing (Bailey et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Bailey, C., Yeoman, R., Madden, A., Thompson, M., &amp; Kerridge, G. (2019). A review of the empirical literature on meaningful work: Progress and research agenda. Human Resource Development Review, 18(1), 83–113." href="/article/10.1007/s10551-023-05339-7#ref-CR5" id="ref-link-section-d20450213e525">2019</a>; Lysova et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Lysova, E. I., Allan, B. A., Dik, B. J., Duffy, R. D., &amp; Steger, M. F. (2019). Fostering meaningful work in organizations: A multi-level review and integration. Journal of Vocational Behavior, 110, 374–389." href="/article/10.1007/s10551-023-05339-7#ref-CR51" id="ref-link-section-d20450213e529">2019</a>). However, despite becoming an increasingly prevalent feature of workplaces, there remains a poor understanding of how AI use will influence opportunities for meaningful work and the ethical implications of such changes.</p><p>Historically technological advancements have, since at least the first industrial revolution, significantly changed opportunities for meaningful work by altering what workers do, the nature of their skills, and their feelings of alienation from or integration with the production process (Vallor, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Vallor, S. (2015). Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character. Philosophy &amp; Technology, 28(1), 107–124." href="/article/10.1007/s10551-023-05339-7#ref-CR71" id="ref-link-section-d20450213e535">2015</a>). AI use will likely extend such changes, but its unique features and uses also generate new and conflicting implications for meaningful work. Optimistic accounts suggest that AI will expand the range of meaningful higher-order human work tasks (WEF, 2018), whereas more pessimistic accounts suggest that AI will degrade and even eliminate human work (Frey &amp; Osborne, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Frey, C. B., &amp; Osborne, M. A. (2017). The future of employment: How susceptible are jobs to computerisation? Technological Forecasting and Social Change, 114, 254–280." href="/article/10.1007/s10551-023-05339-7#ref-CR31" id="ref-link-section-d20450213e538">2017</a>). These ongoing tensions point to a lack of conceptual clarity regarding the impacts of AI on meaningful work, leading to calls for more research in this area (Parker &amp; Grote, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2022" title="Parker, S. K., &amp; Grote, G. (2022). Automation, algorithms, and beyond: Why work design matters more than ever in a digital world. Applied Psychology, 71(4), 1171–1204." href="/article/10.1007/s10551-023-05339-7#ref-CR58" id="ref-link-section-d20450213e541">2022</a>).</p><p>This conceptual paper aims to help address such gaps by examining how workplace use of AI has the potential to both enhance and diminish experiences of meaningful work, depending largely on the implementation choices of employers. This research is positioned at the intersection of the meaningful work and ethical AI literatures and makes two key contributions. First, we contextualise the meaningful work literature for the era of AI by developing conceptual resources to examine how the implementation of such technologies affects workers’ opportunities for meaningful work and connect this assessment to the ethical implications of these changes. Second, we help remedy a neglected aspect of the ethical AI literature by offering a detailed examination of AI’s implications for meaningful work.</p><p>We begin by outlining the nature of meaningful work and its ethical importance, integrating philosophical and business ethics accounts. We then examine the impacts of three paths of AI deployment—replacing some simple and complex tasks (replacement), ‘tending the machine’ (creating new forms of human work), and amplifying human skills (augmenting/assisting workers)—across five dimensions of meaningful work. These dimensions integrate both job-specific (through Hackman &amp; Oldham’s, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Hackman, J. R., &amp; Oldham, G. R. (1976). Motivation through the design of work: Test of a theory. Organizational Behavior and Human Performance, 16(2), 250–279." href="/article/10.1007/s10551-023-05339-7#ref-CR37" id="ref-link-section-d20450213e550">1976</a> job characteristics model) and more holistic (through Lips-Wiersma &amp; Morris’, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e553">2009</a> model) drivers of meaningful work. We then develop the ethical implications of our analysis by drawing on the AI4People ethical AI framework (Floridi et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e556">2018</a>) and its five principles of beneficence, non-maleficence, autonomy, justice, and explicability. We conclude with practical insights into how experiences of meaningful work will change as AI becomes more widespread and offer several directions for future research.</p></div></div></section><section data-title="AI and Work: Uses and Unique Features"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">AI and Work: Uses and Unique Features</h2><div class="c-article-section__content" id="Sec1-content"><p>Current AIs constitute artificial narrow intelligence, or AIs that can undertake actions only within restricted domains, such as classifying pictures of cats (Boden, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Boden, M. A. (2016). AI. Oxford University Press: UK." href="/article/10.1007/s10551-023-05339-7#ref-CR12" id="ref-link-section-d20450213e567">2016</a>). The “holy grail” of AI research is artificial general intelligence (Boden, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Boden, M. A. (2016). AI. Oxford University Press: UK." href="/article/10.1007/s10551-023-05339-7#ref-CR12" id="ref-link-section-d20450213e570">2016</a>), or AIs that can perform at least as well as humans across the full range of intelligent activities. We focus only on narrow AI as it is already used across many diverse sectors, including in healthcare, judicial, educational, manufacturing, and military contexts, among many others (see Bankins &amp; Formosa, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Bankins, S., &amp; Formosa, P. (2021). Ethical AI at work: The social contract for artificial intelligence and its implications for the workplace psychological contract. In: M. Coetzee &amp; A. Deas (Eds.), Redefining the Psychological Contract in the Digital Era: Issues for Research and Practice (pp. 55–72). Springer: Switzerland." href="/article/10.1007/s10551-023-05339-7#ref-CR8" id="ref-link-section-d20450213e573">2021</a>; Bekey, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Bekey, G. A. (2012). Current trends in robotics. In P. Lin, K. Abney, &amp; G. A. Bekey (Eds.), Robot ethics (pp. 17–34). MIT Press: Cambridge, Mass." href="/article/10.1007/s10551-023-05339-7#ref-CR10" id="ref-link-section-d20450213e576">2012</a>; Walsh et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Walsh, T., Levy, N., Bell, G., Elliott, A., Maclaurin, J., Mareels, I., &amp; Wood, Fiona. (2019). The effective and ethical development of artificial intelligence. ACOLA. &#xA;                  https://acola.org/wp-content/uploads/2019/07/hs4_artificial-intelligence-report.pdf&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR73" id="ref-link-section-d20450213e579">2019</a>). The established use of narrow AI also allows us to draw on practical examples to ground our assessment of its effects on meaningful work. While considering the possible implications of artificial general intelligence for meaningful work is important, and we discuss this in our future research directions, there remain persistent disagreements about when, if ever, it will be achieved (Boden, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Boden, M. A. (2016). AI. Oxford University Press: UK." href="/article/10.1007/s10551-023-05339-7#ref-CR12" id="ref-link-section-d20450213e583">2016</a>). This makes it critical to examine the impacts of current AI capabilities on opportunities for meaningful work that are occurring now and in the near-term (Webster &amp; Ivanov, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Webster, C., &amp; Ivanov, S. (2020). Robotics, artificial intelligence, and the evolving nature of work. In: B. George &amp; J. Paul (Eds.), Digital Transformation in Business and Society. Palgrave Macmillan, Cham." href="/article/10.1007/s10551-023-05339-7#ref-CR206" id="ref-link-section-d20450213e586">2020</a>).</p><p>Past research demonstrates the dual positive and negative effects of technology upon aspects of meaningful work. For example, technology use can upskill workers and enhance their autonomy, but it can also deskill and serve to control them (Vallor, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Vallor, S. (2015). Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character. Philosophy &amp; Technology, 28(1), 107–124." href="/article/10.1007/s10551-023-05339-7#ref-CR71" id="ref-link-section-d20450213e592">2015</a>; Mazmanian et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Mazmanian, M., Orlikowski, W. J., &amp; Yates, J. (2013). The autonomy paradox: The implications of mobile email devices for knowledge professionals. Organization Science, 24(5), 1337–1357." href="/article/10.1007/s10551-023-05339-7#ref-CR202" id="ref-link-section-d20450213e595">2013</a>), with meaningfulness generally elevated in the former case (Cheney et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Cheney, G., Zorn Jr, T. E., Planalp, S., &amp; Lair, D. J. (2008). Meaningful work and personal/social well-being organizational communication engages the meanings of work. Annals of the International Communication Association, 32(1), 137–185." href="/article/10.1007/s10551-023-05339-7#ref-CR200" id="ref-link-section-d20450213e598">2008</a>). Technology’s positive effects can also help individuals confirm pre-existing notions of meaningful work, but its negative outcomes can require them to re-interpret and adjust those meanings as the technology’s dual effects are realised, for example by providing on-demand connection to work but heightening distraction from other responsibilities (Symon &amp; Whiting, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Symon, G., &amp; Whiting, R. (2019). The sociomaterial negotiation of social entrepreneurs’ meaningful work. Journal of Management Studies, 56(3), 655–684." href="/article/10.1007/s10551-023-05339-7#ref-CR205" id="ref-link-section-d20450213e601">2019</a>). Such dual effects remain evident in advancing forms of technology, such as workplace robotics that offer both benefits and threats to meaningful human work (see Smids et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Smids, J., Nyholm, S., &amp; Berkers, H. (2020). Robots in the workplace: A threat to - or opportunity for - meaningful work? Philosophy &amp; Technology, 33, 503–522." href="/article/10.1007/s10551-023-05339-7#ref-CR65" id="ref-link-section-d20450213e604">2020</a>).</p><p>These findings are critical, but their focus is on broader types of information and communication technologies, whereas we focus specifically upon AI and its implications for meaningful work. While AI use should also generate these types of dual effects, its unique features warrant specific attention. For example, compared to past technologies AI can undertake more cognitive tasks, expanding beyond ‘blue collar’ work in manufacturing where technology’s role in replacing human labour has a long history, and into more ‘white collar’ forms of work (Bankins &amp; Formosa, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bankins, S., &amp; Formosa, P. (2020). When AI meets PC: Exploring the implications of workplace social robots and a human-robot psychological contract. European Journal of Work and Organizational Psychology, 29(2), 215–229." href="/article/10.1007/s10551-023-05339-7#ref-CR7" id="ref-link-section-d20450213e610">2020</a>). Further, machine learning in AIs is often driven by large amounts of data, the acquisition of which raises serious concerns about privacy, consent, and surveillance, with implications for worker autonomy (Bailey et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Bailey, C., Yeoman, R., Madden, A., Thompson, M., &amp; Kerridge, G. (2019). A review of the empirical literature on meaningful work: Progress and research agenda. Human Resource Development Review, 18(1), 83–113." href="/article/10.1007/s10551-023-05339-7#ref-CR5" id="ref-link-section-d20450213e613">2019</a>). Potential biases in data collection, the use of AI models built from biased data, and the resultant replication of systemic injustices (Walsh et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Walsh, T., Levy, N., Bell, G., Elliott, A., Maclaurin, J., Mareels, I., &amp; Wood, Fiona. (2019). The effective and ethical development of artificial intelligence. ACOLA. &#xA;                  https://acola.org/wp-content/uploads/2019/07/hs4_artificial-intelligence-report.pdf&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR73" id="ref-link-section-d20450213e616">2019</a>), as already evidenced in some AI-driven recruitment practices (Dastin, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Dastin, J. (2018, October 11). Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. &#xA;                  https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR22" id="ref-link-section-d20450213e619">2018</a>), raises further concerns about the potential for one’s AI-informed work to harm others. The potential for such harms is then exacerbated given the scale at which AI can be deployed. The way AIs expand opportunities to manipulate and control humans also raises important issues (Susser et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Susser, D., Roessler, B., &amp; Nissenbaum, H. (2019). Technology, autonomy, and manipulation. Internet Policy Review. &#xA;                  https://doi.org/10.14763/2019.2.1410&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR66" id="ref-link-section-d20450213e622">2019</a>), particularly through the way it can act as an information gatekeeper for human workers (Kellogg et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Kellogg, K. C., Valentine, M. A., &amp; Christin, A. (2020). Algorithms at work: The new contested terrain of control. Academy of Management Annals, 14(1), 366–410." href="/article/10.1007/s10551-023-05339-7#ref-CR46" id="ref-link-section-d20450213e626">2020</a>). Finally, the ‘blackbox’ nature of the neural networks many AIs use means end-users and even AI developers cannot understand how an AI generates its outputs (Jarrahi, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Jarrahi, M. H. (2019). In the age of the smart artificial intelligence: AI's dual capacities for automating and informating work. Business Information Review, 36(4), 178–187." href="/article/10.1007/s10551-023-05339-7#ref-CR44" id="ref-link-section-d20450213e629">2019</a>). This can make it difficult to trust AIs, to feel competent in working alongside them, and to build responsible systems for which human workers can be held meaningfully accountable (Dahl, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Dahl, E. S. (2018). Appraising black-boxed technology: The positive prospects. Philosophy &amp; Technology, 31, 571–591." href="/article/10.1007/s10551-023-05339-7#ref-CR21" id="ref-link-section-d20450213e632">2018</a>). These features of AI have attendant consequences for meaningful work that we will explore. We first turn to explaining the components of meaningful work and its ethical importance.</p></div></div></section><section data-title="What Constitutes Meaningful Work?"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">What Constitutes Meaningful Work?</h2><div class="c-article-section__content" id="Sec2-content"><p>Several approaches outline what constitutes meaningful work. One dominant task-based framework is Hackman and Oldham’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Hackman, J. R., &amp; Oldham, G. R. (1976). Motivation through the design of work: Test of a theory. Organizational Behavior and Human Performance, 16(2), 250–279." href="/article/10.1007/s10551-023-05339-7#ref-CR37" id="ref-link-section-d20450213e643">1976</a>) job characteristics model (JCM), which examines how job and task design influences experiences of meaningfulness in work (Pratt &amp; Ashforth, 2003).<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> Other frameworks extend beyond a task focus to adopt a more “humanistic” approach (Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e661">2009</a>, p. 493). For example, Lips-Wiersma and Morris (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e664">2009</a>) suggest that meaningful work derives from finding balance between “being (true to self)-doing (making a difference)” and a focus on “self (self-actualisation)-others (serving others)”. This creates the meaningful work dimensions of “developing and becoming self”, “serving others”, “unity with others”, and “expressing one’s full potential” (Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e667">2009</a>, p. 501).</p><p>To adopt a holistic approach for exploring the impacts of AI on meaningful work we integrate aspects of meaningful job design from the JCM (Hackman &amp; Oldham, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Hackman, J. R., &amp; Oldham, G. R. (1976). Motivation through the design of work: Test of a theory. Organizational Behavior and Human Performance, 16(2), 250–279." href="/article/10.1007/s10551-023-05339-7#ref-CR37" id="ref-link-section-d20450213e673">1976</a>) with dimensions of work that facilitate the more wide-ranging enhancement of oneself through development, contribution, and connection to others from Lips-Wiersma and Morris’ (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e676">2009</a>) framework. This harmonisation generates five meaningful work dimensions that we focus our analysis upon.<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> The first dimension we label <i>task integrity</i>. This encompasses task identity from the JCM, or the range of tasks an individual does and the opportunity to complete a whole piece of work. This ability to undertake integrated rather than fragmented tasks then influences the extent to which workers can fully develop themselves, their capacities, and express their full potential as an integrated whole person (“developing and becoming self” and “expressing full potential” from Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e691">2009</a>). The second dimension we label <i>skill cultivation and use</i>. This encompasses skill variety and use from the JCM, or the ability to use and develop a range of skills at work. Like the types of tasks to which they are applied, prospects for skill utilisation then influence opportunities for growth through learning and the broader cultivation of the self and one’s potential via developing, testing, and exercising a varied range of competencies (“developing and becoming self” and “expressing full potential” from Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e698">2009</a>).</p><p>The third dimension is <i>task significance</i> (per the JCM) which connects one’s work to the wider world. This dimension reflects the extent to which individuals can see how their work benefits, and contributes to the betterment of, others (“serving others” from Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e707">2009</a>). The fourth dimension is <i>autonomy</i> (per the JCM), which reflects how freely individuals can determine their work approaches and the extent of their freedom from intrusive surveillance and monitoring. The more autonomy workers experience the greater their capacity to engage in activities like job crafting to enhance fit between individual needs and job requirements, and to undertake work that fosters self-development, moral cultivation, and that affords alignment with one’s values (“developing and becoming self” and “expressing full potential” from Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e713">2009</a>). The final dimension is <i>belongingness</i>, reflecting the ways that work can help us feel connected to a wider group to generate meaningfulness through a sense of unity with others (Bailey et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Bailey, C., Yeoman, R., Madden, A., Thompson, M., &amp; Kerridge, G. (2019). A review of the empirical literature on meaningful work: Progress and research agenda. Human Resource Development Review, 18(1), 83–113." href="/article/10.1007/s10551-023-05339-7#ref-CR5" id="ref-link-section-d20450213e720">2019</a>; Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e723">2009</a>; Martela &amp; Riekki, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Martela, F., &amp; Riekki, T. J. J. (2018). Autonomy, competence, relatedness, and beneficence: A multicultural comparison of the four pathways to meaningful work. Frontiers in Psychology, 9, 1157." href="/article/10.1007/s10551-023-05339-7#ref-CR52" id="ref-link-section-d20450213e726">2018</a>). Now that we know what underpins experiences of meaning in work, we can turn to explaining the ethical dimensions of both meaningful work and AI.</p></div></div></section><section data-title="The Ethics of Meaningful Work and Ethical AI"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">The Ethics of Meaningful Work and Ethical AI</h2><div class="c-article-section__content" id="Sec3-content"><p>Recent philosophical discussions of meaningfulness tend to focus on what makes life itself, or the activities and relationships that compose a well-lived life, meaningful (Wolf, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wolf, S. (2010). Meaning in life and why it matters. Princeton University Press: New Jersey." href="/article/10.1007/s10551-023-05339-7#ref-CR75" id="ref-link-section-d20450213e737">2010</a>). The paradigm of meaningless work is Sisyphus, who is condemned as punishment to repeatedly roll a rock to the top of a mountain (Camus, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1955" title="Camus, A. (1955). The myth of Sisyphus and other essays. Hamish Hamilton." href="/article/10.1007/s10551-023-05339-7#ref-CR18" id="ref-link-section-d20450213e740">1955</a>). Sisyphus’ work is boring, repetitive, simple, does not benefit others, and is not freely chosen.<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> By implication, meaningful work should be engaging, varied, require the use of complex skills, benefit others, and be freely chosen. This emphasises two aspects of meaningfulness that Wolf (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wolf, S. (2010). Meaning in life and why it matters. Princeton University Press: New Jersey." href="/article/10.1007/s10551-023-05339-7#ref-CR75" id="ref-link-section-d20450213e752">2010</a>) calls subjective (do you <i>experience</i> work as meaningful?) and objective (is the work <i>actually</i> meaningful?) elements. As we take meaningful work to be “personally significant and worthwhile” (Lysova et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Lysova, E. I., Allan, B. A., Dik, B. J., Duffy, R. D., &amp; Steger, M. F. (2019). Fostering meaningful work in organizations: A multi-level review and integration. Journal of Vocational Behavior, 110, 374–389." href="/article/10.1007/s10551-023-05339-7#ref-CR51" id="ref-link-section-d20450213e762">2019</a>, p. 375), our definition is inclusive of these subjective (it is <i>personally</i> significant) and objective (it <i>is</i> worthwhile) aspects.</p><h3 class="c-article__sub-heading" id="Sec4">The Ethical Implications of Meaningful Work: Why is it Ethically Important?</h3><p>Literature in business ethics and political philosophy explore the ethical significance of meaningful work (Michaelson et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Michaelson, C., Pratt, M. G., Grant, A. M., &amp; Dunn, C. P. (2014). Meaningful work: Connecting business ethics and organization studies. Journal of Business Ethics, 121, 77–90." href="/article/10.1007/s10551-023-05339-7#ref-CR53" id="ref-link-section-d20450213e778">2014</a>). Meaningful work can be viewed as ethically significant either because it is intrinsically valuable (first basis), or because it is a constitutive element of a broader good (second basis), or because it is an instrumental good that leads to other valuable goods (third basis) (Michaelson et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Michaelson, C., Pratt, M. G., Grant, A. M., &amp; Dunn, C. P. (2014). Meaningful work: Connecting business ethics and organization studies. Journal of Business Ethics, 121, 77–90." href="/article/10.1007/s10551-023-05339-7#ref-CR53" id="ref-link-section-d20450213e781">2014</a>). From these three bases we can see that there are good grounds for holding meaningful work to be ethically important across each of our three most used ethical theories: Kantian ethics, Virtue Theory, and Utilitarianism.</p><p>Regarding the first basis, Kantian ethical theories focus on treating people with dignity and respect as rational agents who have normative authority over their lives, and this includes imperfect duties to promote and develop the rational capacities and self-chosen ends of moral agents (Formosa, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Formosa, P. (2017). Kantian ethics, dignity and perfection. Cambridge University Press: Cambridge." href="/article/10.1007/s10551-023-05339-7#ref-CR27" id="ref-link-section-d20450213e787">2017</a>). Meaningful work is ethically significant as it provides an important way to develop and exercise one’s rational capacities and use them in ways that help others to meet their ends. Bowie (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1998" title="Bowie, N. E. (1998). A Kantian theory of meaningful work. Journal of Business Ethics, 17, 1083–1092." href="/article/10.1007/s10551-023-05339-7#ref-CR15" id="ref-link-section-d20450213e790">1998</a>, p. 1083) identifies six features of meaningful work that explain why Kantians should care about it, including that the work is “freely entered into”, “not paternalistic”, ‘‘provides a wage sufficient for physical welfare”, allows workers to exercise their “autonomy and independence”, “develop” their “rational capacities”, and promotes their “moral development”. In terms of the second basis, many virtue ethicists argue that meaningful work is an integral part of flourishing as a human being. For example, Nussbaum (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Nussbaum, M. C. (2011). Creating capabilities: The human development approach. Harvard University Press: USA." href="/article/10.1007/s10551-023-05339-7#ref-CR56" id="ref-link-section-d20450213e793">2011</a>) argues that “being able to work as a human being” is a central human capability. This means being able to exercise our practical reason, use our senses, imagination and thought, have some control over our work environment, and being able to have “meaningful relations of mutual recognition with other workers” (Nussbaum, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Nussbaum, M. C. (2011). Creating capabilities: The human development approach. Harvard University Press: USA." href="/article/10.1007/s10551-023-05339-7#ref-CR56" id="ref-link-section-d20450213e796">2011</a>, p. 34). The capability to pursue meaningful work is thus an important right and component of human flourishing. In terms of the third basis, evidence shows the positive instrumental impacts that meaningful work has on wellbeing and a range of other goods (Allan et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Allan, B. A., Batz-Barbarich, C., Sterling, H. M., &amp; Tay, L. (2019). Outcomes of meaningful work: A meta-analysis. Journal of Management Studies, 56(3), 500–528." href="/article/10.1007/s10551-023-05339-7#ref-CR3" id="ref-link-section-d20450213e799">2019</a>). This gives us good reasons to care about meaningful work for the sake of other important goods it contributes to and promotes, such as human wellbeing, that are valued on a range of ethical theories, including Utilitarianism.</p><p>Overall, according to all three of our most used moral theories there are good reasons to care about meaningful work given that it respects workers’ autonomy and their ability to exercise complex skills in helping others, contributes to their wellbeing, and allows them to flourish as complex human beings. Given its ethically valuable nature, it follows that organisations have strong <i>pro tanto</i> reasons to promote, support, and offer meaningful work (Michaelson et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Michaelson, C., Pratt, M. G., Grant, A. M., &amp; Dunn, C. P. (2014). Meaningful work: Connecting business ethics and organization studies. Journal of Business Ethics, 121, 77–90." href="/article/10.1007/s10551-023-05339-7#ref-CR53" id="ref-link-section-d20450213e808">2014</a>). Of course, <i>pro tanto</i> reasons are not indefeasible reasons, and so other considerations may outweigh them, such as improved efficiency, which means changes that lead to less meaningful work are not necessarily unethical. Further, some workers may be willing to trade off less meaningful work for other gains, such as more income or leisure time. Even so, meaningful work remains ethically important and changes that impact the amount of meaningful work for humans must be taken into ethical account, even if such considerations are not always overriding.</p><h3 class="c-article__sub-heading" id="Sec5">The Ethical Implications of AI Use</h3><p>Given the ethical importance of meaningful work, more scholarship is needed to explore the potential impacts of AI upon it. The ethical significance of AI use is widely recognised and discussed (see Floridi et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e822">2018</a>; Hagendorff, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Hagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. Minds and Machines, 30, 99–120." href="/article/10.1007/s10551-023-05339-7#ref-CR38" id="ref-link-section-d20450213e825">2020</a>; Jobin et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Jobin, A., Ienca, M., &amp; Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature Machine Intelligence, 1(9), 389–399." href="/article/10.1007/s10551-023-05339-7#ref-CR45" id="ref-link-section-d20450213e828">2019</a>), leading to various organisational, national, and international documents outlining ethical principles for AI deployment. However, AI’s effects on meaningful work are not a focus of any of these principles. For example, Jobin et al.’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Jobin, A., Ienca, M., &amp; Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature Machine Intelligence, 1(9), 389–399." href="/article/10.1007/s10551-023-05339-7#ref-CR45" id="ref-link-section-d20450213e831">2019</a>) meta-analysis of ethical AI guidelines identifies 11 principles, but none mention meaningful work directly. Hagendorff’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Hagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. Minds and Machines, 30, 99–120." href="/article/10.1007/s10551-023-05339-7#ref-CR38" id="ref-link-section-d20450213e834">2020</a>) analysis also does not identify it, although related issues around the “future of employment” are discussed. An analysis by Ryan and Stahl (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Ryan, M., &amp; Stahl, B. C. (2020). Artificial intelligence ethics guidelines for developers and users: Clarifying their content and normative implications. Journal of Information, Communication and Ethics in Society, 19(1), 61–86." href="/article/10.1007/s10551-023-05339-7#ref-CR63" id="ref-link-section-d20450213e838">2020</a>, p. 67) mentions the need to “retrain and retool” human workers who are fully replaced by AI, but this sidelines human-AI collaborations in workplaces and AI’s broader impacts on meaningful work. The AI4People framework also makes no direct mention of meaningful work, but it does note the possibility of AI liberating people from the “drudgery” of some work (Floridi et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e841">2018</a>, p. 691).</p><p>While these frameworks do not mention meaningful work explicitly, we can nonetheless draw on them to identify ethical concerns that AI’s impacts on meaningful work raise. To do this we draw on the AI4People ethical AI framework (Floridi et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e847">2018</a>) and its five principles of beneficence, non-maleficence, autonomy, justice, and explicability. We utilise this widely discussed framework as it emerged from a robust consensus-building program to formulate ethical AI principles. The framework’s focus on the impacts of AI on “human dignity and flourishing” across its elements of “autonomous self-realisation… human agency… individual and societal capabilities... [and] societal cohesion” (Floridi et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e850">2018</a>, p. 690) also fits our focus, given that the impacts of AI on dignity, autonomous agency, social cohesion, skills and capabilities, and human flourishing all relate to our dimensions of meaningful work. The foundational principles of this framework (minus explicability) have also been utilised in related work on the ethical design and deployment of broader information technologies (see Wright, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wright, D. (2011). A framework for the ethical impact assessment of information technology. Ethics and Information Technology, 13, 199–226." href="/article/10.1007/s10551-023-05339-7#ref-CR76" id="ref-link-section-d20450213e853">2011</a>), which again emphasises the framework’s usefulness in our context.</p><p>The five principles of the AI4People framework allow us to explore the wide-ranging impacts of AI on meaningful work. The first principle is <i>beneficence</i>, or the benefits AI can bring toward promoting human wellbeing and preserving human dignity in an environmentally sustainable way. <i>Non-maleficence</i> is about ensuring that AI does not harm humanity, and this includes not violating individuals’ privacy and maintaining the safety and security of AI systems. <i>Autonomy</i> is about giving humans the power to decide what AI does. A linking concern between the first two principles is the use of AI, intentionally or not, to cause harm by interfering with and disrespecting human autonomy by “nudging… human behaviour in undesirable ways” (Floridi et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e868">2018</a>, p. 697). Nudging involves setting up the “choice architecture”, or decision context, to intentionally attempt to push (or “nudge”) people to make certain choices (Thaler &amp; Sunstein, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Thaler, R., &amp; Sunstein, C. (2008). Nudge:  Improving decisions about health, wealth, and happiness. Yale University Press: New Haven, CT." href="/article/10.1007/s10551-023-05339-7#ref-CR67" id="ref-link-section-d20450213e871">2008</a>). <i>Justice</i> is about fairly distributing the benefits and burdens from AI use and not undermining solidarity and social cohesion. Finally, <i>explicability</i> is about ensuring that AI operates in ways that are intelligible and accountable, so that we can understand how it works and we can require someone to be responsible for its actions. In the context of meaningful work, these principles lead us to focus on the benefits and harms that AI can bring to workers, including on their tasks, skills and social relations, the way AI might control, nudge, and manipulate workers’ autonomy, the distribution of the benefits and harms AI brings, and the extent of intelligibility and accountability in AI workplace deployments.</p><p>Our overall conceptual framework is presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10551-023-05339-7#Fig1">1</a> and our analysis is structured as follows. We first outline the impacts of AI on the five dimensions of meaningful work by analysing its effects through three pathways (outlined below) for AI deployment: replacement; ‘tending the machine’; and amplifying. We then turn to the AI4People ethical framework to draw out the ethical implications of these impacts on meaningful work. This structure allows us to focus in a systematic way on each important set of analyses, first related to AI’s effects on meaningful work and then the ethical implications of this, while highlighting how these effects are often contingent on the ways in which AI is deployed.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10551-023-05339-7/figures/1" rel="nofollow"><picture><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10551-023-05339-7/MediaObjects/10551_2023_5339_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="237"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Overview of conceptual framework</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10551-023-05339-7/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="The Effects of Artificial Intelligence on Meaningful Work"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">The Effects of Artificial Intelligence on Meaningful Work</h2><div class="c-article-section__content" id="Sec6-content"><p>AI represents a range of technologies that can be used in many ways alongside human workers doing many different tasks. This makes it important to examine not only what tasks the AI does, but also how human workers’ tasks change following AI deployment and the comparative meaningfulness of their new work. While we briefly discuss the impacts of full human replacement by AI upon meaningful work, we focus our analysis on meaningful work outcomes when humans work alongside AI.<sup><a href="#Fn4"><span class="u-visually-hidden">Footnote </span>4</a></sup> This is because such work configurations already, and will increasingly, characterise many workplaces (Jarrahi, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Jarrahi, M. H. (2018). Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making. Business Horizons, 61(4), 577–586." href="/article/10.1007/s10551-023-05339-7#ref-CR43" id="ref-link-section-d20450213e928">2018</a>) and reflects our focus on clear current and near-term impacts of narrow AI.</p><h3 class="c-article__sub-heading" id="Sec7">Technology’s Effects on Work: Three Paths</h3><p>Our analytical framework adapts and expands Langlois' (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. Journal of Economic Psychology, 24(2), 167–187." href="/article/10.1007/s10551-023-05339-7#ref-CR47" id="ref-link-section-d20450213e938">2003</a>) characterisation of how technology integrates into a work process. This structures our analysis around three key paths through which AI will shape humans’ experiences of meaningful work.</p><p>In the first path, <i>AI assumes some tasks (either simple or complex) while workers remain engaged elsewhere in the (roughly similar) work process</i>. This is akin to AI replacing humans in some tasks. For example, if a personalised maths learning app is introduced in a classroom, the teacher may re-focus upon other existing tasks (e.g., more time for lesson planning) or undertake new work (e.g., individualised maths coaching), but the overall work process of ‘teaching’ remains similar (see such examples in Acemoglu &amp; Restrepo, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Acemoglu, D., &amp; Restrepo, P. (2020). The wrong kind of AI? Artificial intelligence and the future of labour demand. Cambridge Journal of Regions, Economy and Society, 13, 25–35." href="/article/10.1007/s10551-023-05339-7#ref-CR2" id="ref-link-section-d20450213e947">2020</a>). We also focus on the two ends of the skills spectrum for illustrative purposes (i.e., simple and complex tasks), and acknowledge that tasks will likely involve various skills. The key difference between this path and the next is that here the replacement work undertaken by humans is not focused on managing the AI, but in the next path it is.</p><p>In the second path, <i>AI assumes a set of tasks resulting in new human work focused on</i> “<i>tending the machine”</i> (Langlois, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. Journal of Economic Psychology, 24(2), 167–187." href="/article/10.1007/s10551-023-05339-7#ref-CR47" id="ref-link-section-d20450213e959">2003</a>, p. 175). This is akin to creating new types of tasks for workers.<sup><a href="#Fn5"><span class="u-visually-hidden">Footnote </span>5</a></sup> We further divide ‘tending the machine’ into two emerging forms of work associated with managing AI: (1) what we term ‘<i>managing</i> the machine’, which generates new, complex, and interesting forms of work for humans; and (2) what Langlois (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. Journal of Economic Psychology, 24(2), 167–187." href="/article/10.1007/s10551-023-05339-7#ref-CR47" id="ref-link-section-d20450213e975">2003</a>, p. 175) terms “<i>minding</i> the machine”, which generates more mundane, rote, and lower-skilled work for humans. Again, we focus on two ends of a spectrum for illustrative purposes, while acknowledging that human work may exist across both categories. <i>‘Managing the machine’</i> reflects integrated and complex work, such as “coordination and buffering” roles (Langlois, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. Journal of Economic Psychology, 24(2), 167–187." href="/article/10.1007/s10551-023-05339-7#ref-CR47" id="ref-link-section-d20450213e984">2003</a>, p. 175), as well as trainer, explainer, and sustainer roles (Daugherty &amp; Wilson, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Daugherty, P. R., &amp; Wilson, H. J. (2018). Human + Machine: Reimagining work in the age of AI. Harvard Business Review Press." href="/article/10.1007/s10551-023-05339-7#ref-CR23" id="ref-link-section-d20450213e987">2018</a>). Examples include: managing the interactions between data, the wider organisation, and other stakeholders (coordination and buffering); training the AI to complete tasks and training others in AI use (training); explaining and interpreting the AI’s operation and outputs to stakeholders (explaining); and ensuring the system’s continued explainability, accountability, and fairness (sustaining) (Daugherty &amp; Wilson, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Daugherty, P. R., &amp; Wilson, H. J. (2018). Human + Machine: Reimagining work in the age of AI. Harvard Business Review Press." href="/article/10.1007/s10551-023-05339-7#ref-CR23" id="ref-link-section-d20450213e990">2018</a>). In contrast, <i>‘minding the machine’</i> work involves tasks such as “AI preparation” (sourcing, annotating, and labelling data) and “AI verification” through validating AI output (such as checking image recognition accuracy) (Tubaro et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Tubaro, P., Casilli, A. A., &amp; Coville, M. (2020). The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence. Big Data &amp; Society, 7(1). &#xA;                  https://doi.org/10.1177/2053951720919776&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR70" id="ref-link-section-d20450213e997">2020</a>, p. 1). This type of work tends to reflect fragmented and disconnected micro-work tasks that are often outsourced to low wage and low skill workers (Tubaro et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Tubaro, P., Casilli, A. A., &amp; Coville, M. (2020). The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence. Big Data &amp; Society, 7(1). &#xA;                  https://doi.org/10.1177/2053951720919776&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR70" id="ref-link-section-d20450213e1000">2020</a>), leading to characterisations of “janitor work” and new digitalised forms of Taylorism (Jarrahi, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Jarrahi, M. H. (2019). In the age of the smart artificial intelligence: AI's dual capacities for automating and informating work. Business Information Review, 36(4), 178–187." href="/article/10.1007/s10551-023-05339-7#ref-CR44" id="ref-link-section-d20450213e1003">2019</a>, p. 183).</p><p>In the third path, <i>AI ‘amplifies’ or ‘assists’ workers by improving how human workers do their existing work</i> (Daugherty &amp; Wilson, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Daugherty, P. R., &amp; Wilson, H. J. (2018). Human + Machine: Reimagining work in the age of AI. Harvard Business Review Press." href="/article/10.1007/s10551-023-05339-7#ref-CR23" id="ref-link-section-d20450213e1012">2018</a>). This is akin to AI assisting workers with their tasks and/or augmenting and enhancing workers’ abilities. Here AI is neither assuming specific tasks that a human previously did (as in the first path) nor does managing the AI constitute a worker’s primary role (as in the second path), but rather the technology assists the worker to do her existing work better. For example, the AI Corti provides real-time assistance to emergency operators by analysing callers’ responses to questions, assessing the severity of their condition, and recommending actions to the operator based on modelling of thousands of previous calls (Formosa &amp; Ryan, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Formosa, P., &amp; Ryan, M. (2021). Making moral machines: Why we need artificial moral agents. AI &amp; Society, 36, 839–851." href="/article/10.1007/s10551-023-05339-7#ref-CR29" id="ref-link-section-d20450213e1015">2021</a>). This amplifies, in a significant new way, the abilities of emergency operators to determine optimal responses. The use of AI to amplify a human worker accords with Zuboff’s (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Zuboff, S. (1988). In the age of the smart machine: The future of work and power. Basic Books: New York." href="/article/10.1007/s10551-023-05339-7#ref-CR79" id="ref-link-section-d20450213e1018">1988</a>) “informating” powers of technology, whereby it improves humans’ access to integrated and more meaningful forms of data, often cross-functionally, to generate new insights (see Jarrahi, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Jarrahi, M. H. (2019). In the age of the smart artificial intelligence: AI's dual capacities for automating and informating work. Business Information Review, 36(4), 178–187." href="/article/10.1007/s10551-023-05339-7#ref-CR44" id="ref-link-section-d20450213e1021">2019</a>).</p><p>We now analyse how, through each of these three deployment pathways, AI use will impact the five dimensions of meaningful work. While individual jobs could experience elements of all three paths (e.g., some replacing, some ‘tending the machine’ work, and some amplifying) and some overlap may occur (e.g., AI replacing a rote human task also assists the worker), we discuss each path as distinct for analytical purposes. The ethical implications of these impacts are then assessed in the subsequent section.</p><h3 class="c-article__sub-heading" id="Sec8">Task Integrity and Skill Cultivation and Use</h3><p>Workers’ tasks can range from being highly fragmented to being highly integrated, and the diversity of skills they can activate will also vary as a result. Both of these aspects generate opportunities to achieve and develop one’s abilities and potential through work (Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e1036">2009</a>). As the nature of what a worker does (i.e., tasks) strongly impacts what they need to do that work (i.e., skills), we discuss these two dimensions together.</p><p>First, we consider the path of AI taking over some tasks while leaving workers engaged in other work. The tasks the AI assumes could be <i>simple</i> or <i>complex</i> (or anything in between), but the predominance of narrow AI means it is mainly deployed to replace humans in specific narrow tasks. An espoused benefit of AI is its ability to undertake simple tasks that are often boring and unchallenging for humans, such as collating information for meetings (Pulse + IT, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Pulse+IT. (2020). The San using AI to automate multidisciplinary team meetings. Pulse+IT. &#xA;                  https://www.pulseitmagazine.com.au:443/australian-ehealth/5558-the-san-using-ai-to-automate-multidisciplinary-team-meetings&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR60" id="ref-link-section-d20450213e1048">2020</a>) or assessing fruit quality (Roberts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Roberts, P. (2020). Working smarter with data. Australian Manufacturing Forum. &#xA;                  https://www.aumanufacturing.com.au/working-smarter-with-data-ai-gives-agriculture-the-competitive-edge&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR62" id="ref-link-section-d20450213e1051">2020</a>). Deploying AI in this way is unlikely to generate significant feelings of marginalisation from a wider work process due to the simple nature of the tasks it is assuming, particularly when the human takes on other comparable or more interesting work. This should result in neutral or improved perceptions of task integrity and may free workers’ time to engage in more learning and development.</p><p>However, when AI assumes more complex and significant tasks then its implications, both positive and negative, may be more profound. For example, in human resource management an AI can shortlist candidates to progress to interviews based on natural language processing of applications (Bankins, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Bankins, S. (2021). The ethical use of artificial intelligence in human resource management: A decision-making framework. Ethics and Information Technology, 23, 841–854." href="/article/10.1007/s10551-023-05339-7#ref-CR6" id="ref-link-section-d20450213e1057">2021</a>; Leicht-Deobald et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Leicht-Deobald, U., et al. (2019). The challenges of algorithm-based HR decision-making for personal integrity. Journal of Business Ethics, 160, 377–392." href="/article/10.1007/s10551-023-05339-7#ref-CR48" id="ref-link-section-d20450213e1060">2019</a>). Shortlisting applicants can be a complex and significant component of the recruitment and selection process. Using AI for this task could then degrade workers’ experiences of task integrity as they no longer undertake a significant part of a work process, assuming this work is not comparably replaced. Shifting workers to other more rote tasks, despite adding work that maintains their level of involvement in the work process, is also likely to compound feelings of reduced task integrity, as the worker moves from undertaking more significant to less significant work. This can also limit the scope for workers to develop and express their full capabilities at work and reduce their opportunities for growth.</p><p>In contrast, if workers shift to new but similarly complex or even more significant tasks elsewhere in the work process, then this should support task integrity as the worker continues to contribute meaningfully to work outcomes. For example, the AI ‘AlphaFold’ developed by DeepMind is designed to automate and accelerate the process of determining protein structures, an important step in developing new treatments for human diseases (Hassabis &amp; Revell, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Hassabis, D., &amp; Revell, T. (2021). With AI, you might unlock some of the secrets about how life works. New Scientist, 249(3315), 44–49." href="/article/10.1007/s10551-023-05339-7#ref-CR41" id="ref-link-section-d20450213e1066">2021</a>). While AlphaFold can assume significant tasks previously done by human scientists (i.e., determining protein structures) this should positively impact, or at least have a neutral effect, on task integrity if it allows scientists to re-focus their work efforts on other important aspects of their broader goal of curing diseases. However, there remain risks to AI being used in this way. Continuing with this example, if scientists have trained for many years to do the experimental work that AlphaFold can now do more quickly and accurately, this generates significant risks for their ability to exercise their full capacities, demonstrate their mastery, and utilise the skills they have invested years in developing to reach their full potential.</p><p>Changes in skill cultivation and use due to technology replacing either simple or complex tasks also raises deskilling concerns, whereby skilled human work is offloaded to machines resulting in skill loss (Vallor, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Vallor, S. (2015). Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character. Philosophy &amp; Technology, 28(1), 107–124." href="/article/10.1007/s10551-023-05339-7#ref-CR71" id="ref-link-section-d20450213e1073">2015</a>). Ethically, it is critical to establish whether the human skills lost (i.e., offloaded to machines) are important and whether they can be exercised and maintained through other forms of work or in other life domains (Michaelson et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Michaelson, C., Pratt, M. G., Grant, A. M., &amp; Dunn, C. P. (2014). Meaningful work: Connecting business ethics and organization studies. Journal of Business Ethics, 121, 77–90." href="/article/10.1007/s10551-023-05339-7#ref-CR53" id="ref-link-section-d20450213e1076">2014</a>; Wolf, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wolf, S. (2010). Meaning in life and why it matters. Princeton University Press: New Jersey." href="/article/10.1007/s10551-023-05339-7#ref-CR75" id="ref-link-section-d20450213e1079">2010</a>). As simple and rote work generally requires basic skills that can be cultivated elsewhere or are not significant, there is limited scope for significant deskilling in this case. However, complex tasks generally require complex skills, such as judgement, intuition, context awareness, and ethical thinking. From a deskilling perspective, these types of skills are particularly ethically problematic for workers to risk losing. This means when workers are left with fewer overall complex and significant tasks following AI deployment, then their ability to cultivate and use important skills will likely decrease, negatively impacting this dimension of meaningful work.</p><p>It is worth noting that where replacement involves AI assuming a worker’s whole job, for example where the job is constituted entirely of simple and rote tasks that are most susceptible to full automation (Gibbs, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Gibbs, M. J. (2017). How is new technology changing job design? IZA World of Labor. &#xA;                  https://doi.org/10.15185/izawol.344&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR32" id="ref-link-section-d20450213e1085">2017</a>), this will likely lead to unemployment (if redeployment is not possible). This effectively removes, at least temporarily, paid meaningful work from that worker’s life and poses the greatest risk to the ability to experience meaningful work. This also provides the conditions for a wide range of skills to be lost or degraded, as well as having significant negative impacts on important self-attitudes, such as feelings of self-respect and self-worth (see Selenko et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2022" title="Selenko, E., Bankins, S., Shoss, M., Warburton, J., &amp; Restubog, S. L. D. (2022). Artificial intelligence and the future of work: A functional-identity perspective. Current Directions in Psychological Science, 31(3), 272–279." href="/article/10.1007/s10551-023-05339-7#ref-CR204" id="ref-link-section-d20450213e1088">2022</a> for work on AI use and employees’ sense of identity). This case also raises broader political questions about how society should deal with such a scenario should it become more widespread (Hughes, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Hughes, J. (2014). A strategic opening for a basic income guarantee in the global crisis being created by AI, robots, desktop manufacturing and biomedicine. Journal of Ethics and Emerging Technologies, 24(1), 45–61." href="/article/10.1007/s10551-023-05339-7#ref-CR42" id="ref-link-section-d20450213e1091">2014</a>). While these questions are beyond our focus here, we do highlight them in our discussion of future research directions.</p><p>Second, we consider the path of workers <i>‘tending the machine’</i>, whether in ‘managing’ or ‘minding’ forms. <i>‘Managing the machine’</i> work should enhance what Bourmault and Anteby (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bourmault, N., &amp; Anteby, M. (2020). Unpacking the managerial blues: How expectations formed in the past carry into new jobs. Organization Science, 31(6), 1452–1474." href="/article/10.1007/s10551-023-05339-7#ref-CR14" id="ref-link-section-d20450213e1103">2020</a>, p. 1453) term “administrative responsibility”, through offering a wider scope and variety of duties. This should enhance task integrity where the shift to coordination and buffering work provides opportunities for integrated and challenging activities across training, explaining, and sustaining roles through supervisory work, technology oversight, exceptions management, and cross-functional coordination of entire work processes. Such coordination and buffering work will also require the development of flexible and wide-ranging skill sets (Langlois, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. Journal of Economic Psychology, 24(2), 167–187." href="/article/10.1007/s10551-023-05339-7#ref-CR47" id="ref-link-section-d20450213e1106">2003</a>), supporting skill cultivation and use and more broadly widening and deepening one’s ability to learn, achieve, and develop at work.</p><p>In contrast, rather than generating more complex and interesting human work, <i>‘minding the machine’</i> produces a “more benignant role for humans” through more mundane and rote tasks (Langlois, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. Journal of Economic Psychology, 24(2), 167–187." href="/article/10.1007/s10551-023-05339-7#ref-CR47" id="ref-link-section-d20450213e1115">2003</a>, p. 174). This would reduce task integrity as workers become more distanced from their work outcomes. The generally repetitive and fragmented nature of ‘minding the machine’ work also suggests its associated skills are low and narrow, offering little opportunity for varied skill cultivation. Such AI “janitor work” (Jarrahi, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Jarrahi, M. H. (2019). In the age of the smart artificial intelligence: AI's dual capacities for automating and informating work. Business Information Review, 36(4), 178–187." href="/article/10.1007/s10551-023-05339-7#ref-CR44" id="ref-link-section-d20450213e1118">2019</a>, p. 183) risks degrading workers’ abilities to meaningfully develop their capabilities and reach and express their full potential at work, leading to lower levels of meaningfulness on this dimension.</p><p>Third, when AI <i>amplifies</i> workers’ abilities to do their current tasks, positive impacts on task integrity and skill cultivation and use should ensue. For example, in the policing domain, machine learning technologies can collate previously disparate data sources to analyse characteristics and histories of domestic violence victims and perpetrators to better predict, compared to current human-driven systems, repeat attacks and better prioritise preventative actions (Grogger et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Grogger, J., Ivandic, R., &amp; Kirchmaier, T. (2020). Comparing conventional and machine-learning approaches to risk assessment in domestic abuse cases. Journal of Empirical Legal Studies, 18(1), 90–130." href="/article/10.1007/s10551-023-05339-7#ref-CR35" id="ref-link-section-d20450213e1127">2020</a>).<sup><a href="#Fn6"><span class="u-visually-hidden">Footnote </span>6</a></sup> In such cases, experiences of task integrity are likely to remain consistent or improve as AI supports workers to better complete their tasks and achieve work goals. Skill cultivation and use should remain neutral or improve as it is likely that workers, while maintaining their current skills, will need to develop new ones to interpret and integrate AI output into their decision making.</p><p>However, a feature of AI that may constrain skill use across all three paths is its ‘blackbox’ nature (Boden, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Boden, M. A. (2016). AI. Oxford University Press: UK." href="/article/10.1007/s10551-023-05339-7#ref-CR12" id="ref-link-section-d20450213e1142">2016</a>). While AI designers are developing ways to improve lay person interfaces, the use of ‘blackbox’ (or unexplainable) AI in workplaces may degrade workers’ skill cultivation, use, and feelings of competence. For example, where workers are highly reliant on the decision making of an AI, they may feel lower levels of competence in their use of it due to little understanding of its functioning. This effect will likely be more acutely felt where workers are expected to understand and explain what the AI is doing. Poor explainability can also create opaque chains of accountability for decisions informed by AI (Dahl, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Dahl, E. S. (2018). Appraising black-boxed technology: The positive prospects. Philosophy &amp; Technology, 31, 571–591." href="/article/10.1007/s10551-023-05339-7#ref-CR21" id="ref-link-section-d20450213e1145">2018</a>) and this risks making workers overly dependent on an AI that they cannot comprehend.</p><h3 class="c-article__sub-heading" id="Sec9">Task Significance</h3><p>Task significance means employees see their work as having positive impacts (Grant, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Grant, A. M. (2008). The significance of task significance: Job performance effects, relational mechanisms, and boundary conditions. Journal of Applied Psychology, 93(1), 108–124." href="/article/10.1007/s10551-023-05339-7#ref-CR34" id="ref-link-section-d20450213e1156">2008</a>) through their service to others (Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e1159">2009</a>), within or outside the organisation (Hackman &amp; Oldham, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1975" title="Hackman, J. R., &amp; Oldham, G. R. (1975). Development of the job diagnostic survey. Journal of Applied Psychology, 60(2), 159–170." href="/article/10.1007/s10551-023-05339-7#ref-CR36" id="ref-link-section-d20450213e1162">1975</a>). Task significance is influenced by how employees assess their <i>job impact</i> <i>on</i> and <i>contact with</i> beneficiaries (Grant, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Grant, A. M. (2007). Relational job design and the motivation to make a prosocial difference. Academy of Management Review, 32(2), 393–417." href="/article/10.1007/s10551-023-05339-7#ref-CR33" id="ref-link-section-d20450213e1175">2007</a>). Job impacts on beneficiaries are shaped by the dimensions of magnitude, scope, frequency, and focus (i.e., preventing harms or promoting benefits) (Grant, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Grant, A. M. (2007). Relational job design and the motivation to make a prosocial difference. Academy of Management Review, 32(2), 393–417." href="/article/10.1007/s10551-023-05339-7#ref-CR33" id="ref-link-section-d20450213e1178">2007</a>). Contact with beneficiaries is shaped by the dimensions of frequency, duration, physical proximity (including virtual proximity), depth, and breadth of contact (Grant, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Grant, A. M. (2007). Relational job design and the motivation to make a prosocial difference. Academy of Management Review, 32(2), 393–417." href="/article/10.1007/s10551-023-05339-7#ref-CR33" id="ref-link-section-d20450213e1181">2007</a>). Given the range of these dimensions, workers’ assessments of task significance can be complex. Evidence suggests that employees can derive task significance from even objectively rote, mundane, and low skill work (the objective element of meaningful work), when that work is framed in the right way (the subjective element of meaningful work). For example, Carton (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Carton, A. M. (2018). I’m not mopping the floors, I’m putting a man on the moon: How NASA leaders enhanced the meaningfulness of work by changing the meaning of work. Administrative Science Quarterly, 63(2), 323–369." href="/article/10.1007/s10551-023-05339-7#ref-CR19" id="ref-link-section-d20450213e1184">2018</a>, p. 323) shows that when leaders at NASA carefully framed the space agency’s goals, workers could connect work such as “mopping the floor” to “helping put a man on the moon”. However, carrying out impactful tasks without opportunities for “personal, emotional connections to the beneficiaries of those tasks” can impede overall experiences of task significance (Grant, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Grant, A. M. (2007). Relational job design and the motivation to make a prosocial difference. Academy of Management Review, 32(2), 393–417." href="/article/10.1007/s10551-023-05339-7#ref-CR33" id="ref-link-section-d20450213e1187">2007</a>, p. 398; Bourmault &amp; Anteby, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bourmault, N., &amp; Anteby, M. (2020). Unpacking the managerial blues: How expectations formed in the past carry into new jobs. Organization Science, 31(6), 1452–1474." href="/article/10.1007/s10551-023-05339-7#ref-CR14" id="ref-link-section-d20450213e1191">2020</a>). This means that both job impact on beneficiaries and contact with them are important to assess. Given this, and following Grant (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Grant, A. M. (2007). Relational job design and the motivation to make a prosocial difference. Academy of Management Review, 32(2), 393–417." href="/article/10.1007/s10551-023-05339-7#ref-CR33" id="ref-link-section-d20450213e1194">2007</a>), we suggest that employees’ global assessments of the impact of AI on their jobs, rather than on specific tasks, is most relevant when assessing perceptions of task significance.</p><p>First, we consider the path of AI taking over <i>simple</i> or <i>complex tasks</i> while workers remain engaged elsewhere. Given our focus here at the job level, if only some simple tasks are assumed by an AI this should have limited impact on task significance, assuming the remaining or new tasks provide opportunities for workers to positively impact and connect with beneficiaries. In contrast, when AI assumes more <i>complex tasks</i>, these are likely significant to an individual’s overall assessments of task significance. This may lead to more extensive and complex sensemaking of this change. To see this, we draw on construal-level theory (CLT), which describes the way individuals cognitively represent people or events at either higher or lower levels of abstraction (Trope &amp; Liberman, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Trope, Y., &amp; Liberman, N. (2003). Temporal construal. Psychological Review, 110(3), 403–421." href="/article/10.1007/s10551-023-05339-7#ref-CR69" id="ref-link-section-d20450213e1209">2003</a>). Higher levels of abstraction involve “mental representations that are relatively broad, inclusive, (and) general”, such as higher-level goals or principles (Wiesenfeld et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Wiesenfeld, B. M., Reyt, J.-N., Brockner, J., &amp; Trope, Y. (2017). Construal level theory in organizational research. Annual Review of Organizational Psychology and Organizational Behavior, 4(1), 367–400." href="/article/10.1007/s10551-023-05339-7#ref-CR74" id="ref-link-section-d20450213e1212">2017</a>, p. 368). Lower levels of abstraction involve “applying relatively specific, detailed, and contextualised representations”, such as focusing on lower-level actions to achieve higher-level goals (Wiesenfeld et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Wiesenfeld, B. M., Reyt, J.-N., Brockner, J., &amp; Trope, Y. (2017). Construal level theory in organizational research. Annual Review of Organizational Psychology and Organizational Behavior, 4(1), 367–400." href="/article/10.1007/s10551-023-05339-7#ref-CR74" id="ref-link-section-d20450213e1216">2017</a>, p. 368). Returning to the earlier AlphaFold example, at a higher level of construal workers may perceive improved task significance regarding job impact as the AI is significantly contributing to the higher-level goal of treating diseases. This could facilitate higher perceptions of magnitude, scope, and frequency of positive impact. At a lower level of construal, the worker may then ask: “but what am I doing to help meet this goal?”. If workers can re-focus on other comparatively significant tasks in the work process, they should experience higher task significance as the AI helps advance the field toward reaching the overarching goal <i>and</i> the worker continues to meaningfully contribute toward that goal. However, where the remaining or new tasks fail, at lower levels of construal, to deliver at least the same experiences of task significance as before, then one’s perceived ability to ‘serve others’ is likely to degrade overall.</p><p>In cases of both simple and complex task change, where AI is used in ways that have sub-optimal, biased, unjust, or harmful outcomes for end users, this could also decrease workers’ perceptions of task significance. For example, where AI provides facial recognition and predictive policing data for law enforcement agencies and the AI’s outputs are biased against minority groups, then workers may see reduced task significance given their organisations’ connections to negative outcomes (via the negative magnitude, scope, and frequency dimensions of job impact). Implicating workers in injustices and harms perpetrated by an AI, through their involvement with or responsibility for the technology, can particularly diminish the experience of serving others and the autonomous ability to act in alignment with one’s values and morals (related to ‘developing and becoming self’), degrading overall work meaningfulness.</p><p>Second, we consider the <i>‘tending the machine’</i> path. In terms of <i>‘managing the machine’</i>, the heightened administrative responsibility associated with such work (Bourmault &amp; Anteby, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bourmault, N., &amp; Anteby, M. (2020). Unpacking the managerial blues: How expectations formed in the past carry into new jobs. Organization Science, 31(6), 1452–1474." href="/article/10.1007/s10551-023-05339-7#ref-CR14" id="ref-link-section-d20450213e1234">2020</a>) should improve task significance through job impact and more opportunities to benefit others, given the expansive duties this work entails (i.e., enhanced scope of impact). However, such work can distance workers from those they serve, diminishing feelings of direct “personal responsibility” (Bourmault &amp; Anteby, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bourmault, N., &amp; Anteby, M. (2020). Unpacking the managerial blues: How expectations formed in the past carry into new jobs. Organization Science, 31(6), 1452–1474." href="/article/10.1007/s10551-023-05339-7#ref-CR14" id="ref-link-section-d20450213e1237">2020</a>, p. 1453) or feelings of having a direct and significant impact on the lives of others, which can reduce task significance. For example, when replaced by autonomously driven trains and moved to ‘managing the machine’ work, metro train drivers experienced enhanced administrative responsibility but diminished personal responsibility, alongside lower task significance overall, as they were no longer directly responsible for commuters’ safety (Bourmault &amp; Anteby, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bourmault, N., &amp; Anteby, M. (2020). Unpacking the managerial blues: How expectations formed in the past carry into new jobs. Organization Science, 31(6), 1452–1474." href="/article/10.1007/s10551-023-05339-7#ref-CR14" id="ref-link-section-d20450213e1240">2020</a>).</p><p>In terms of <i>‘minding the machine’</i> work we suggest that task significance will generally be reduced. This is because such fragmented work means workers may have little idea of the point of their labour and its impacts, potentially limiting all job impact dimensions. As they may also be working in isolation from others because of outsourcing (Tubaro et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Tubaro, P., Casilli, A. A., &amp; Coville, M. (2020). The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence. Big Data &amp; Society, 7(1). &#xA;                  https://doi.org/10.1177/2053951720919776&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR70" id="ref-link-section-d20450213e1250">2020</a>), potentially limiting all contact with beneficiaries, this further disconnects workers’ tasks from the end user benefits generated, eroding task significance.</p><p>Third, when AI <i>amplifies</i> a worker’s abilities this should have significant and positive implications for task significance, particularly through the magnitude and focus dimensions of job impact and the duration and depth dimensions of contact with beneficiaries. Here, the AI is not focused on substantially changing the range of tasks in a work process, but rather on improving something that humans were already doing in that process, leading to better outcomes for beneficiaries. Drawing on earlier amplification examples, where AI can support police officers by collating and analysing new data sources to help them better prevent incidences of domestic violence (assuming it does not do so in unfair or biased ways), then this should heighten perceptions of both being able to achieve higher-level goals (e.g., preventing crime) and seeing the importance and connection of lower-level tasks to reaching that goal (e.g., through interpreting better predictive analytics). Use of AI in this way can also help reduce human biases in decision making, such as through building fairness principles into AI systems (see Selbst et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Selbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., &amp; Vertesi, J. (2019). Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 59–68)." href="/article/10.1007/s10551-023-05339-7#ref-CR203" id="ref-link-section-d20450213e1259">2019</a>). In recruitment, for example, AI can limit the impact of unconscious human biases and various other human constraints on rational decision making by assessing all candidates’ applications against standard criteria and providing auditable, transparent, and explainable decision trails (see Hagras, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Hagras, H. (2018). Toward human-understandable, explainable AI. Computer, 51(9), 28–36." href="/article/10.1007/s10551-023-05339-7#ref-CR39" id="ref-link-section-d20450213e1262">2018</a>; Bankins et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2022" title="Bankins, S., Formosa, P., Griep, Y., &amp; Richards, D. (2022). AI decision making with dignity? Contrasting workers' justice perceptions of human and AI decision making in a human resource management context. Information Systems Frontiers, 24(3), 857–875." href="/article/10.1007/s10551-023-05339-7#ref-CR9" id="ref-link-section-d20450213e1265">2022</a>). This path demonstrates that a significant potential benefit of AI is that it can elevate humans’ abilities to address complex problems, enhance the impact of their work, and thus better serve others, through its analysis of large datasets to identify novel insights.</p><h3 class="c-article__sub-heading" id="Sec10">Autonomy</h3><p>Autonomy means self-rule. Individually, that means being able to do what you really want to do. In addition to the freedom from interference needed to rule yourself, autonomy is also commonly taken to include <i>competency</i> (i.e., you have the skills and capacities needed to rule yourself) and <i>authenticity</i> (i.e., your ends are authentically your own and not the result of oppression, manipulation, or coercion) conditions (Formosa, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Formosa, P. (2021). Robot autonomy vs human autonomy: Social robots, artificial intelligence (AI), and the nature of autonomy. Minds and Machines, 31, 595–616." href="/article/10.1007/s10551-023-05339-7#ref-CR28" id="ref-link-section-d20450213e1283">2021</a>). In the workplace, autonomy refers to “the degree to which the job provides substantial freedom, independence, and discretion to the individual in scheduling the work and in determining the procedures to be used in carrying it out” (Hackman &amp; Oldham, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1976" title="Hackman, J. R., &amp; Oldham, G. R. (1976). Motivation through the design of work: Test of a theory. Organizational Behavior and Human Performance, 16(2), 250–279." href="/article/10.1007/s10551-023-05339-7#ref-CR37" id="ref-link-section-d20450213e1286">1976</a>, p. 258). AI’s impact on individuals’ autonomy is a key issue for the ethical AI literature. A particular concern is that ceding authority to AI diminishes human autonomy (Floridi et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e1289">2018</a>). However, potential benefits for human autonomy can also accrue from increasing AI’s autonomy. We assess these different impacts of AI at work as either <i>promoting</i> or <i>diminishing</i> autonomy across <i>competency</i> and <i>authenticity</i> conditions.</p><p>In terms of promoting human autonomy, this depends on what work the AI assumes but also, and more importantly, on what work takes its place and what control and input workers have over AI deployment. When AI assumes <i>simple</i> or <i>complex tasks</i> that workers find boring or repetitive, then this potentially promotes autonomy by freeing up time for workers to build their autonomy competencies through doing other more challenging or authentic work. For example, if an AI prioritises a worker’s emails so that she only sees those requiring a response, this may free her to work on other more valuable tasks. In terms of <i>‘managing the machine’</i>, this path could promote autonomy if new work is more skilful and engaging than the work it replaces, and if workers have a degree of control over how that work is done. Where AI <i>amplifies</i> workers by giving them more power and useful information, then this can improve worker autonomy by helping them to better achieve their self-given ends.</p><p>In terms of diminishing human autonomy, these impacts are partly the converse of the above. In our first path, if <i>complex</i>, interesting, and creative tasks that workers want to do are assumed by AIs, this potentially diminishes autonomy. There may also be good reasons why humans should remain engaged in certain complex tasks and decisions, such as due to their moral complexity. This means that where AI assumes these tasks it can diminish human achievement of valuable ends, degrade important human skills, and limit opportunities for moral development (Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e1326">2009</a>). For example, when we delegate to AI decisions regarding ethically sensitive aspects of human resource management, the skills associated with that work can degrade and thereby diminish important autonomy competencies. AI can also make our autonomy more vulnerable by making us dependent on it, which means our autonomy can diminish if access to the technology is removed. Across the <i>‘tending the machine’</i> path, through <i>‘managing the machine’</i> work AI can diminish worker autonomy by filtering and potentially restricting the information that is made available for humans to view and use (Kellogg et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Kellogg, K. C., Valentine, M. A., &amp; Christin, A. (2020). Algorithms at work: The new contested terrain of control. Academy of Management Annals, 14(1), 366–410." href="/article/10.1007/s10551-023-05339-7#ref-CR46" id="ref-link-section-d20450213e1335">2020</a>). Such constraints can limit the ability for workers to authentically develop themselves and their capabilities at work. Broader autonomy concerns also exist with <i>‘minding the machine’</i> work, which is itself mundane and boring, making workers feel like a ‘slave to the machine’ (Engel, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Engel, S. (2019). Minding machines: A note on alienation. Fast Capitalism, 16(2), 129–139." href="/article/10.1007/s10551-023-05339-7#ref-CR24" id="ref-link-section-d20450213e1342">2019</a>) and thereby experiencing diminished autonomy at work.</p><p>Across all paths, a more pernicious threat to autonomy may exist through surveillance and manipulation by AI. This reflects what Foucault calls the rise of a “surveillance society”, which seeks to control bodies through making people feel permanently monitored (Abrams, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Abrams, J. J. (2004). Pragmatism, artificial intelligence, and posthuman bioethics: Shusterman, Rorty, Foucault. Human Studies, 27(3), 241–258." href="/article/10.1007/s10551-023-05339-7#ref-CR1" id="ref-link-section-d20450213e1348">2004</a>). When people are surveilled they tend to feel constrained and act in less authentic and autonomous ways (Molitorisz, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Molitorisz, S. (2020). Net privacy: How we can be free in an age of surveillance. McGill-Queen’s University Press: Canada." href="/article/10.1007/s10551-023-05339-7#ref-CR54" id="ref-link-section-d20450213e1351">2020</a>). The use of AI to surveil workers will likely have similar impacts and can be a way for employers to use their power to exert control over employees. For example, the use of AI-powered cameras to surveil Amazon delivery drivers could make them more self-conscious in their trucks, which could lead them to feel more constrained and unable to act autonomously (Asher-Schapiro, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Asher-Schapiro, A. (2021). Amazon AI van cameras spark surveillance concerns. News.Trust.Org. &#xA;                  https://news.trust.org/item/20210205132207-c0mz7/&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR4" id="ref-link-section-d20450213e1354">2021</a>). A similar example is when AI is implemented to monitor online meetings and measure whether workers are engaged and contributing to the discussion (see Pardes, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Pardes, A. (2020, November). AI can run your work meetings now. Wired. &#xA;                  https://www.wired.com/story/ai-can-run-work-meetings-now-headroom-clockwise/&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR57" id="ref-link-section-d20450213e1357">2020</a>), which could lead to stress and inauthentic behaviour. Such monitoring could also result in workers engaging in intentional “deviance” to challenge the control of surveillance (Abrams, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Abrams, J. J. (2004). Pragmatism, artificial intelligence, and posthuman bioethics: Shusterman, Rorty, Foucault. Human Studies, 27(3), 241–258." href="/article/10.1007/s10551-023-05339-7#ref-CR1" id="ref-link-section-d20450213e1360">2004</a>), by trying to “game” the AI by matching or openly flouting what the AI is expecting in terms of eye contact and body language (Pardes, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Pardes, A. (2020, November). AI can run your work meetings now. Wired. &#xA;                  https://www.wired.com/story/ai-can-run-work-meetings-now-headroom-clockwise/&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR57" id="ref-link-section-d20450213e1364">2020</a>), or finding other ways to operate outside the gaze of the surveillance system.</p><h3 class="c-article__sub-heading" id="Sec11">Belongingness</h3><p>Belongingness refers to “the meaningfulness of working together with other human beings” (Lips-Wiersma &amp; Wright, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Lips-Wiersma, M., &amp; Wright, S. (2012). Measuring the meaning of meaningful work: Development and validation of the comprehensive meaningful work scale. Group &amp; Organization Management, 37(5), 655–685." href="/article/10.1007/s10551-023-05339-7#ref-CR50" id="ref-link-section-d20450213e1375">2012</a>, p. 673). Across all our paths, we argue that AI may impact workers’ belongingness in two main ways: through generating the conditions for more or less meaningful connections and a sense of unity with others; and through its implementation creating differences across workers that undermines solidarity.</p><p>In terms of the first way, where AI assumes tasks that may otherwise have required in-person and face-to-face interaction with other workers or customers, this can create less human contact in the workplace. For example, where an AI chatbot allows workers to access information previously provided by a human worker, this lessens that worker’s interactions with other humans and reduces opportunities for forming connections with others that are the bedrock for generating a sense of belonging (Seppala et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Seppala, E., Rossomando, T., &amp; Doty, J. R. (2013). Social connection and compassion: Important predictors of health and well-being. Social Research, 80(2), 411–430." href="/article/10.1007/s10551-023-05339-7#ref-CR64" id="ref-link-section-d20450213e1381">2013</a>). In contrast, AI use may increase opportunities for human interaction, for example through ‘managing the machine’ work where workers are responsible for supervising AI deployment that requires extensive human-to-human training.</p><p>In terms of the second way, a key concern in the ethical AI literature is how AI use may disproportionately and negatively affect lower-skilled and lower-paid workers, while its benefits may disproportionately accrue to those with higher skills and wages (Ernst et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Ernst, E., Merola, R., &amp; Samaan, D. (2018). The economics of artificial intelligence. International Labour Organization. &#xA;                  https://www.ilo.org/wcmsp5/groups/public/dgreports/cabinet/documents/publication/wcms_647306.pdf&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR25" id="ref-link-section-d20450213e1387">2018</a>), effectively creating new types of workplace in-groups and out-groups. For example, many of the negative impacts of AI at work, such as surveillance and simplistic ‘minding the machine’ work, will tend to fall on less skilled ‘blue collar’ workers, whereas more of the amplifying and autonomy-enhancing benefits associated with taking on even more interesting and engaging work will tend to fall to already privileged workers. This creates justice concerns around how the benefits and burdens of AI in workplaces are being distributed, potentially undermining solidarity between those who benefit from AI’s introduction and those who do not. For example, in a call centre context an AI may be used to monitor and evaluate the calls of every call centre operator. Such heightened surveillance may be perceived by operators as intrusive and diminishing their autonomy. However, using AI in this way may amplify the work of quality assurance staff in the same organisation, providing them with more information and assisting them in better training and managing operators. This shows how AI may generate distinct groups experiencing very different impacts, such as being viewed as unnecessary surveillance by some but as an amplifying source of information by others. Such outcomes particularly threaten the ability to create a sense of belongingness and shared values (Lips-Wiersma &amp; Morris, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ Journal of Business Ethics, 88(3), 491–511." href="/article/10.1007/s10551-023-05339-7#ref-CR49" id="ref-link-section-d20450213e1390">2009</a>), which underpins the ‘unity with others’ dimension of meaningful work.</p></div></div></section><section data-title="Ethical Implications: AI and Meaningful Work"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Ethical Implications: AI and Meaningful Work</h2><div class="c-article-section__content" id="Sec12-content"><p>We have analysed how the three paths of AI deployment may enhance or diminish opportunities for meaningful work across five dimensions. We now surface the ethical implications of this analysis via the five principles of the AI4People ethical AI framework (Floridi et al, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. Minds and Machines, 28(4), 689–707." href="/article/10.1007/s10551-023-05339-7#ref-CR26" id="ref-link-section-d20450213e1403">2018</a>): beneficence; non-maleficence; autonomy; justice; and explicability. As with any principlist framework there are potential conflicts and tensions between principles (Formosa et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Formosa, P., Wilson, M., &amp; Richards, D. (2021). A principlist framework for cybersecurity ethics. Computers &amp; Security, 109, 102382." href="/article/10.1007/s10551-023-05339-7#ref-CR30" id="ref-link-section-d20450213e1406">2021</a>). For example, there may be benefits for some from AI deployment (beneficence) while others suffer harm (non-maleficence) or interference with their autonomy. As identified earlier, the provision of meaningful work is not always the only or most important ethical value at stake, and so less meaningful work may not be ethically worse overall if there are other ethical benefits, such as improved wellbeing for others through higher productivity.</p><p>To assess ethical implications, we synthesise and summarise how the three paths (replacing, ‘tending the machine’, and amplifying) support or limit experiences of meaningful work and so contribute to, or diminish, meeting the AI4People principles. We summarise these impacts in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s10551-023-05339-7#Tab1">1</a> across the five ethical principles (beneficence and non-maleficence are combined in the Table as the latter reflects the converse of the former), while noting the main deployment pathways through which these impacts occur.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Ethical impacts of AI for enhancing or diminishing meaningful work</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s10551-023-05339-7/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>In terms of the <i>beneficence principle</i>, there can be significant benefits for employees when AI use supports the various dimensions of meaningful work. When AI <i>amplifies</i> a worker’s skills it can support them to complete their tasks, undertake more complex tasks, and utilise higher-order thinking and analysis skills (task integrity and skill cultivation and use). It can also afford workers the opportunity to achieve better outcomes and enhance the positive impact of their work on beneficiaries (task significance), give them more control over their work through improved access to information (autonomy), and potentially generate new connections with other workers and stakeholders (belongingness). Similarly, when AI assumes some <i>simple or complex</i> tasks and the human worker can re-focus on other important and challenging tasks in the work process, then positive experiences across all dimensions of meaningful work should be maintained or improved. <i>‘Managing the machine’</i> work can also improve meaningfulness through a wider scope of enriched work (task integrity and skill cultivation and use) and a wider positive job impact within and outside the organisation (task significance), as well as greater interaction with a range of stakeholders through coordination and supervisory work (belongingness).</p><p>In terms of the <i>non-maleficence principle</i>, we also show the harms that AI can create when it is deployed in ways that lead to less (or no) meaningful work, or other related harms. Two paths generate greatest risk of harms through significantly reducing experiences of meaningful work. First, when AI replaces some tasks, the risk of degraded task integrity, deskilling, reduced task significance, and constrained autonomy is greatest when it assumes more <i>complex</i> tasks and the worker is not afforded any new comparable or more interesting work. This is because complex tasks generally constitute a large and significant part of the work process and undertaking them exercises a range of important skills. Being removed from such work can also distance workers from the output of their labour and lower perceptions of beneficiary impact. In the worst case, it could involve the complete loss of paid meaningful work where AI replaces whole jobs, which removes workers from important social relationships and denies them the opportunity to skilfully utilise their talents to help others. Second, <i>‘minding the machine’</i> work, as we have characterised its fragmented, piecemeal, and micro-work nature, threatens these same aspects of meaningful work and feelings of belongingness when work is outsourced to disconnected workers. Other paths can also generate harms, but arguably at lower levels. For example, we identified that while <i>‘managing the machine’</i> work may increase meaningful work experiences overall through heightened administrative responsibility, it can lessen feelings of task significance by increasing distance between workers and their beneficiaries and reducing feelings of personal responsibility.</p><p>In terms of the <i>autonomy principle,</i> across each path we show how autonomy is supported when AI is used to free up humans to focus their time on other more valued tasks, allows them to develop new or enhanced autonomy competencies, and gives them more control over their work. In particular, the <i>task replacement</i>, <i>‘managing the machine’</i>, and <i>amplifying</i> paths that afford employees access to better data and information, the opportunity to engage in more interesting work, and exercise more control over how their work is done, can all promote autonomy as a dimension of meaningful work. However, many of these positive impacts also depend on whether workers have input into how AI is deployed in their organisations. A particular risk to autonomy is the use of AI to surveil and monitor, which can undermine authenticity and encourage workers to align their behaviours with the AI’s implicit expectations or seek ways to subvert or avoid its control.</p><p>The <i>justice principle</i> centres on ensuring fair, just, and non-discriminatory outcomes from AI and requires a focus on how the benefits and burdens of AI use are distributed. For example, the <i>amplifying</i> path generally achieves strongly positive outcomes for meaningful work, but there is evidence that such benefits are disproportionately allocated to already privileged workforces (i.e., higher-skilled and higher-paid workers). In contrast, the <i>‘minding the machine’</i> path generally achieves strongly negative outcomes for meaningful work, but such burdens tend to disproportionately impact less privileged workforces (i.e., lower-paid and lower-skilled workers). Lower-skilled workers are also more likely to have their entire jobs replaced by AI (Gibbs, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Gibbs, M. J. (2017). How is new technology changing job design? IZA World of Labor. &#xA;                  https://doi.org/10.15185/izawol.344&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR32" id="ref-link-section-d20450213e1669">2017</a>). This uneven distribution raises important justice concerns and can undermine solidarity and feelings of belongingness within and across work groups. However, AI can also be deployed to promote justice, which can positively impact task significance. For example, when AI is used to minimise bias and maximise evidence-based decision making through giving workers access to new data-driven insights (such as through <i>amplification</i>, <i>‘managing the machine’</i>, or replacing <i>complex tasks</i> paths), this promotes fair outcomes while also enhancing task significance through a greater positive impact on beneficiaries. But the converse also holds when the justice principle is threatened by an AI trained on biased datasets and deployed in workplaces where it generates unjust outcomes that can decrease task significance and implicate workers in injustices.</p><p>Finally, the <i>explicability principle</i> relates to the explainability, transparency, and accountability of AI. In paths where AI plays a significant role alongside human workers, such as the <i>amplifying</i>, <i>‘managing the machine’</i>, and the replacement of <i>complex tasks</i> paths, an inability of workers to understand an AI’s operation, particularly where they are highly reliant upon it and are accountable for it, can constrain skill use and feelings of competence. This could potentially undermine the benefits AI may otherwise bring. This suggests that training workers not only in what AI does but also how it does it, and making chains of accountability clear, will be important for supporting experiences of meaningfulness at work.</p></div></div></section><section data-title="Practical Implications"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Practical Implications</h2><div class="c-article-section__content" id="Sec13-content"><p>Organisational use of AI can reap many benefits through improved service range and quality, efficiency, and profitability. However, the ethical deployment of AI requires weighing up its many costs and benefits. We help articulate some of those costs and benefits for workers in terms of AI’s impacts on meaningful work. Practically, this is important because some authors suggest an emerging trend is for organisations to use AI for full automation (Acemoglu &amp; Restrepo, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Acemoglu, D., &amp; Restrepo, P. (2020). The wrong kind of AI? Artificial intelligence and the future of labour demand. Cambridge Journal of Regions, Economy and Society, 13, 25–35." href="/article/10.1007/s10551-023-05339-7#ref-CR2" id="ref-link-section-d20450213e1705">2020</a>), without also considering opportunities to use it for enhancing human work, and then poorly preparing their workforces for the changes that AI use entails (Halloran &amp; Andrews, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Halloran, L. &amp; Andrews, J. (2018). Will you wait for the future to happen? Ernst and Young. &#xA;                  https://www.ey.com/en_au/workforce/will-you-shape-the-future-of-work-or-will-it-shape-you&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR40" id="ref-link-section-d20450213e1708">2018</a>). For organisations we highlight those pathways, such as <i>‘minding the machine’</i> work, that are likely to significantly limit opportunities for meaningful work, which implies that other considerations such as efficiency benefits must strongly outweigh the harms to workers that AI used in this way can generate, in order to justify its use. We also highlight that, when considering meaningfulness, it is insufficient to focus only on the AI itself, as the implications of its deployment are strongly driven by what work remains for humans, which is something that organisations can directly influence and decide. Overall, we offer guidance on how organisations can maintain or build opportunities for meaningful work when they implement AI and point leaders toward specific areas for intervention to support meaningful work experiences. For example, task significance is critical for meaningful work (Grant, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Grant, A. M. (2007). Relational job design and the motivation to make a prosocial difference. Academy of Management Review, 32(2), 393–417." href="/article/10.1007/s10551-023-05339-7#ref-CR33" id="ref-link-section-d20450213e1714">2007</a>), yet the ways AI can distance workers from beneficiaries threatens these experiences. However, there are ways in which organisations can remedy this, such as by sharing end users’ positive stories with workers (Grant, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Grant, A. M. (2008). The significance of task significance: Job performance effects, relational mechanisms, and boundary conditions. Journal of Applied Psychology, 93(1), 108–124." href="/article/10.1007/s10551-023-05339-7#ref-CR34" id="ref-link-section-d20450213e1717">2008</a>).</p></div></div></section><section data-title="Future Research Directions"><div class="c-article-section" id="Sec14-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec14">Future Research Directions</h2><div class="c-article-section__content" id="Sec14-content"><p>Although we did not frame explicit propositions from our conceptual work, there are several relationships we suggest warrant empirical examination. For example, assessing whether AI performing <i>simple tasks</i> enhances task integrity, but AI performing <i>complex tasks</i> degrades this dimension and perceptions of task significance, and examining whether the <i>‘managing the machine’</i> and <i>amplifying</i> paths enhance task integrity and skill cultivation and use overall, but <i>‘minding the machine’</i> work diminishes these aspects. We also suggest several contingencies will affect these relationships, such as what other or new work employees do following AI implementation (task-related factors) and how aspects of the technology, such as its explainability or potential for bias, shape workers’ experiences of it (technology-related factors).</p><p>While we adapted Langlois’ (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. Journal of Economic Psychology, 24(2), 167–187." href="/article/10.1007/s10551-023-05339-7#ref-CR47" id="ref-link-section-d20450213e1746">2003</a>) work to develop our three pathways, these may manifest in different ways and will likely overlap. Future research could explore how each path operates in workplaces, how they may differ from our conceptualisation, and whether there are other path configurations to AI deployment that our framework does not capture. There may also be nuances within pathways that warrant investigation. For example, Jarrahi (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Jarrahi, M. H. (2018). Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making. Business Horizons, 61(4), 577–586." href="/article/10.1007/s10551-023-05339-7#ref-CR43" id="ref-link-section-d20450213e1749">2018</a>, p. 3) suggests that advances in AI could create new forms of “human–machine symbiosis” that result in “both parties (becoming) smarter over time”. This could generate new forms of human skills, tasks, and perhaps whole jobs that have not yet been imagined, with implications for meaningful work.</p><p>Another area for future work is examining how leaders construct and influence subjective perceptions of the meaningfulness of work, particularly through the values, strategies, and vision that underpin how they implement AI (Pratt &amp; Ashforth, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Pratt, M. G., &amp; Ashforth, B. E. (2003). Fostering meaningfulness in working and at work. In K. Cameron, J. E. Dutton, &amp; R. E. Quinn (Eds.), Positive organizational scholarship: Foundations of a new discipline (pp. 308–327). Berrett-Koehler: San Francisco." href="/article/10.1007/s10551-023-05339-7#ref-CR59" id="ref-link-section-d20450213e1755">2003</a>). For example, if an organisation is focused on full automation and replacing human workers, it will likely deploy AI toward this end and degrade opportunities for meaningful work. But if leaders adopt multi-stakeholder governance approaches that support ethical AI deployment (Wright &amp; Schultz, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Wright, S. A., &amp; Schultz, A. E. (2018). The rising tide of artificial intelligence and business automation: Developing an ethical framework. Business Horizons, 61(6), 823–832." href="/article/10.1007/s10551-023-05339-7#ref-CR77" id="ref-link-section-d20450213e1758">2018</a>), such participatory practices may enhance perceptions of meaningful work following AI deployment.</p><p>Finally, while we centred our analysis on the meaningful work implications of narrow AI, future work could utilise conceptual tools such as thought experiments (Bankins &amp; Formosa, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bankins, S., &amp; Formosa, P. (2020). When AI meets PC: Exploring the implications of workplace social robots and a human-robot psychological contract. European Journal of Work and Organizational Psychology, 29(2), 215–229." href="/article/10.1007/s10551-023-05339-7#ref-CR7" id="ref-link-section-d20450213e1764">2020</a>) and work on posthumanism (Gladden, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Gladden, M. E. (2016). Posthuman management: Creating effective organizations in an age of social robotics, ubiquitous AI, human augmentation, and virtual worlds. Defragmenter Media: USA." href="/article/10.1007/s10551-023-05339-7#ref-CR201" id="ref-link-section-d20450213e1767">2016</a>) to prospectively analyse the impacts of potential future forms and deployments of more advanced AI. For example, developments in virtual and augmented reality are creating movements toward a metaverse, or a persistent form of virtual world that is accessible through various devices and that people combine with their existence in the physical world (Ravenscraft, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Ravenscraft, E. (25 November, 2021). What is the metaverse, exactly? Wired. Retrieved from: &#xA;                  https://www.wired.com/story/what-is-the-metaverse/&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR61" id="ref-link-section-d20450213e1770">2021</a>). Such technologies have the potential to transform the nature of social interactions and thus impact the belongingness dimension of meaningful work. Likewise, advances in natural language processing and speech interfaces could result in workers having multiple “digital assistants” (Zhou et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Zhou, L., Paul, S., Demirkan, H., Yuan, L., Spohrer, J., Zhou, M., &amp; Basu, J. (2021). Intelligence augmentation: Towards building human-machine symbiotic relationship. AIS Transactions on Human-Computer Interaction, 13(2), 243–264." href="/article/10.1007/s10551-023-05339-7#ref-CR78" id="ref-link-section-d20450213e1773">2021</a>, p. 258), which will impact the nature of workers’ tasks and relationships and the skills they will require in the future.</p><p>Extending even further, artificial general intelligence (AGI) would constitute “a new general-purpose technology” (Naudé &amp; Dimitri, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Naudé, W., &amp; Dimitri, N. (2020). The race for an artificial general intelligence: Implications for public policy. AI &amp; Society, 35, 367–379." href="/article/10.1007/s10551-023-05339-7#ref-CR55" id="ref-link-section-d20450213e1780">2020</a>) that has been predicted to pose existential threats such as eradicating large swathes of human work (Bruun &amp; Duka, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Bruun, E., &amp; Duka, A. (2018). Artificial intelligence, jobs and the future of work. Basic Income Studies, 13(2), 1–15." href="/article/10.1007/s10551-023-05339-7#ref-CR16" id="ref-link-section-d20450213e1783">2018</a>) and even risking humanity’s annihilation (Torres, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Torres, P. (2019). The possibility and risks of artificial general intelligence. Bulletin of the Atomic Scientists, 75(3), 105–108." href="/article/10.1007/s10551-023-05339-7#ref-CR68" id="ref-link-section-d20450213e1786">2019</a>). The reality of such technologies would inevitably lead to more extreme conclusions for the future of meaningful work than we have generated here through our focus on narrow AI, as they would likely render all but our <i>replacing</i> path largely obsolete. The possibilities of such technologies may therefore lead us back to substantive discussions on the value of work generally, and what forms of human work we believe must be preserved or newly created no matter what technologies are developed. This also raises questions of what broader social changes, such as increased volunteering, provision of other forms of meaningful activity, or a Universal Basic Income (Hughes, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Hughes, J. (2014). A strategic opening for a basic income guarantee in the global crisis being created by AI, robots, desktop manufacturing and biomedicine. Journal of Ethics and Emerging Technologies, 24(1), 45–61." href="/article/10.1007/s10551-023-05339-7#ref-CR42" id="ref-link-section-d20450213e1792">2014</a>), will be required to cushion negative impacts should AGI deployment ever become a reality. It also augurs the potential for heavier regulation of the development and use of AI (and potentially AGI) to maintain meaningful forms of human employment, and to place limits on where, how, and why AI is used. However, at this point the discussion relies on largely technical questions about whether AGI is indeed possible (Boden, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Boden, M. A. (2016). AI. Oxford University Press: UK." href="/article/10.1007/s10551-023-05339-7#ref-CR12" id="ref-link-section-d20450213e1796">2016</a>). In the meantime, the impacts of narrow AI on meaningful work are ones we need to address here and now.</p></div></div></section><section data-title="Conclusion"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">Conclusion</h2><div class="c-article-section__content" id="Sec15-content"><p>This paper focused on a neglected aspect of the ethical implications of AI deployment, namely the impacts of AI on meaningful work. This is an important contribution as the ethical AI literature, while focused on the impacts of unemployment resulting from AI, needs to also attend to the impacts of AI on meaningful work for the remaining workforce. Given the ethical importance of meaningful work and its considerable impacts on human wellbeing, autonomy, and flourishing, this is a significant omission that we help to remedy. We have done so by examining the impacts of three paths of AI deployment (replacing tasks, ‘tending the machine’, and amplifying) across five dimensions of meaningful work (task integrity, skill cultivation and use, task significance, autonomy, and belongingness). Using this approach, we identify specific ways in which AI can both promote and diminish experiences of meaningful work across these dimensions and draw out the ethical implications of this by utilising five key ethical AI principles. Finally, we offer practical guidance for organisations by articulating the ways that AI can be implemented to support meaningful work and suggest opportunities for future research. Overall, we show that AI has the potential to make work more meaningful for some workers by undertaking less meaningful tasks for them and amplifying their capabilities, but that it can also make work less meaningful for others by creating new boring tasks, restricting worker autonomy, and unfairly distributing the benefits of AI away from less-skilled workers. This suggests that AI’s future impacts on meaningful work will be both significant and mixed.</p></div></div></section>
                                </div>
                        
                    

                    
                        
                    

                    
                        
                    

                    
                    <section data-title="Change history"><div class="c-article-section" id="change-history-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="change-history">Change history</h2><div class="c-article-section__content" id="change-history-content"><ul class="c-article-change-list"><li class="c-article-change-list__item u-mb-24" id="chg1"><ins datetime="2023-02-27"><h3 class="c-article-change-list__heading u-h3 u-pr-8 u-display-inline">27 February 2023</h3><div class="c-article-change-list__details"><p>The original online version of this article was revised: Missing Open Access funding information has been added in the Funding Note.</p></div></ins></li></ul></div></div></section><section data-title="Notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1" data-counter="1."><div class="c-article-footnote--listed__content"><p>Pratt and Ashforth (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Pratt, M. G., &amp; Ashforth, B. E. (2003). Fostering meaningfulness in working and at work. In K. Cameron, J. E. Dutton, &amp; R. E. Quinn (Eds.), Positive organizational scholarship: Foundations of a new discipline (pp. 308–327). Berrett-Koehler: San Francisco." href="/article/10.1007/s10551-023-05339-7#ref-CR59" id="ref-link-section-d20450213e650">2003</a>) also discuss meaningfulness <i>at</i> work, or the ways leaders craft and convey organisational values to build feelings of organisational membership. To maintain a manageable scope, our analysis only examines meaning <i>in</i> work, which is largely driven by job design.</p></div></li><li class="c-article-footnote--listed__item" id="Fn2" data-counter="2."><div class="c-article-footnote--listed__content"><p>The job characteristics model also includes feedback. We draw on the model’s first three aspects as they are theorised to directly generate the psychological state of experienced meaningfulness at work, and both autonomy and belongingness are viewed in the wider literature as other critical components of meaningful work. See Parker and Grote (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2022" title="Parker, S. K., &amp; Grote, G. (2022). Automation, algorithms, and beyond: Why work design matters more than ever in a digital world. Applied Psychology, 71(4), 1171–1204." href="/article/10.1007/s10551-023-05339-7#ref-CR58" id="ref-link-section-d20450213e683">2022</a>) for an assessment of technology’s impact on feedback at work.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3" data-counter="3."><div class="c-article-footnote--listed__content"><p>Of course, Sisyphus’ story is more complicated than this, with Camus (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1955" title="Camus, A. (1955). The myth of Sisyphus and other essays. Hamish Hamilton." href="/article/10.1007/s10551-023-05339-7#ref-CR18" id="ref-link-section-d20450213e747">1955</a>) arguing that Sisyphus finds a form of happiness in his scornful embrace of the absurdity of his condition.</p></div></li><li class="c-article-footnote--listed__item" id="Fn4" data-counter="4."><div class="c-article-footnote--listed__content"><p>We do not significantly detail the effects of AI fully replacing a worker because, at least currently, AI is unlikely to predominantly automate entire jobs (Chui et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Chui, M., Manyika, J., &amp; Miremadi, M. (2015). The four fundamentals of workplace automation. McKinsey. &#xA;                  http://www.mckinsey.com/business-functions/digital-mckinsey/our-insights/four-fundamentals-of-workplace-automation&#xA;                  &#xA;                " href="/article/10.1007/s10551-023-05339-7#ref-CR20" id="ref-link-section-d20450213e917">2015</a>). But where this does occur the impacts are clear, the unemployed worker has lost meaningful paid work until they can find another job (which may offer more opportunities for meaningful work, see Cheney et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Cheney, G., Zorn Jr, T. E., Planalp, S., &amp; Lair, D. J. (2008). Meaningful work and personal/social well-being organizational communication engages the meanings of work. Annals of the International Communication Association, 32(1), 137–185." href="/article/10.1007/s10551-023-05339-7#ref-CR200" id="ref-link-section-d20450213e920">2008</a>). This also raises broader issues, beyond our scope, around other sources of meaningfulness if increasingly sophisticated AI makes paid meaningful work rarer (see Bruun &amp; Duka, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Bruun, E., &amp; Duka, A. (2018). Artificial intelligence, jobs and the future of work. Basic Income Studies, 13(2), 1–15." href="/article/10.1007/s10551-023-05339-7#ref-CR16" id="ref-link-section-d20450213e923">2018</a>).</p></div></li><li class="c-article-footnote--listed__item" id="Fn5" data-counter="5."><div class="c-article-footnote--listed__content"><p>We acknowledge that other forms of new human work are also likely to emerge (see Acemoglu &amp; Restrepo, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Acemoglu, D., &amp; Restrepo, P. (2020). The wrong kind of AI? Artificial intelligence and the future of labour demand. Cambridge Journal of Regions, Economy and Society, 13, 25–35." href="/article/10.1007/s10551-023-05339-7#ref-CR2" id="ref-link-section-d20450213e966">2020</a>), but its nature remains speculative. New work associated with AI management already exists or is emerging, aligning with our focus on near-term work implications of AI.</p></div></li><li class="c-article-footnote--listed__item" id="Fn6" data-counter="6."><div class="c-article-footnote--listed__content"><p>Although in practice such predictive policing systems have been shown to risk biased outcomes against minority groups, driven by over-representation of those groups in policing statistics (Berk, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Berk, R. A. (2021). Artificial intelligence, predictive policing, and risk assessment for law enforcement. Annual Review of Criminology, 4(1), 209–237." href="/article/10.1007/s10551-023-05339-7#ref-CR11" id="ref-link-section-d20450213e1134">2021</a>). We discuss these issues in a later section.</p></div></li></ol></div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ul class="c-article-references" data-track-component="outbound reference" data-track-context="references section"><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR1">Abrams, J. J. (2004). Pragmatism, artificial intelligence, and posthuman bioethics: Shusterman, Rorty, Foucault. <i>Human Studies,</i> <i>27</i>(3), 241–258.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1023/B:HUMA.0000042130.79208.c6" data-track-item_id="10.1023/B:HUMA.0000042130.79208.c6" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1023%2FB%3AHUMA.0000042130.79208.c6" aria-label="Article reference 1" data-doi="10.1023/B:HUMA.0000042130.79208.c6">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Pragmatism%2C%20artificial%20intelligence%2C%20and%20posthuman%20bioethics%3A%20Shusterman%2C%20Rorty%2C%20Foucault&amp;journal=Human%20Studies&amp;doi=10.1023%2FB%3AHUMA.0000042130.79208.c6&amp;volume=27&amp;issue=3&amp;pages=241-258&amp;publication_year=2004&amp;author=Abrams%2CJJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR2">Acemoglu, D., &amp; Restrepo, P. (2020). The wrong kind of AI? Artificial intelligence and the future of labour demand. <i>Cambridge Journal of Regions, Economy and Society, 13</i>, 25–35.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/cjres/rsz022" data-track-item_id="10.1093/cjres/rsz022" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fcjres%2Frsz022" aria-label="Article reference 2" data-doi="10.1093/cjres/rsz022">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20wrong%20kind%20of%20AI%3F%20Artificial%20intelligence%20and%20the%20future%20of%20labour%20demand&amp;journal=Cambridge%20Journal%20of%20Regions%2C%20Economy%20and%20Society.&amp;doi=10.1093%2Fcjres%2Frsz022&amp;volume=13&amp;pages=25-35&amp;publication_year=2020&amp;author=Acemoglu%2CD&amp;author=Restrepo%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR3">Allan, B. A., Batz-Barbarich, C., Sterling, H. M., &amp; Tay, L. (2019). Outcomes of meaningful work: A meta-analysis. <i>Journal of Management Studies,</i> <i>56</i>(3), 500–528.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1111/joms.12406" data-track-item_id="10.1111/joms.12406" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1111%2Fjoms.12406" aria-label="Article reference 3" data-doi="10.1111/joms.12406">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Outcomes%20of%20meaningful%20work%3A%20A%20meta-analysis&amp;journal=Journal%20of%20Management%20Studies&amp;doi=10.1111%2Fjoms.12406&amp;volume=56&amp;issue=3&amp;pages=500-528&amp;publication_year=2019&amp;author=Allan%2CBA&amp;author=Batz-Barbarich%2CC&amp;author=Sterling%2CHM&amp;author=Tay%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR4">Asher-Schapiro, A. (2021). <i>Amazon AI van cameras spark surveillance concerns</i>. News.Trust.Org. <a href="https://news.trust.org/item/20210205132207-c0mz7/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://news.trust.org/item/20210205132207-c0mz7/">https://news.trust.org/item/20210205132207-c0mz7/</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR5">Bailey, C., Yeoman, R., Madden, A., Thompson, M., &amp; Kerridge, G. (2019). A review of the empirical literature on meaningful work: Progress and research agenda. <i>Human Resource Development Review,</i> <i>18</i>(1), 83–113.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/1534484318804653" data-track-item_id="10.1177/1534484318804653" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F1534484318804653" aria-label="Article reference 5" data-doi="10.1177/1534484318804653">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20review%20of%20the%20empirical%20literature%20on%20meaningful%20work%3A%20Progress%20and%20research%20agenda&amp;journal=Human%20Resource%20Development%20Review&amp;doi=10.1177%2F1534484318804653&amp;volume=18&amp;issue=1&amp;pages=83-113&amp;publication_year=2019&amp;author=Bailey%2CC&amp;author=Yeoman%2CR&amp;author=Madden%2CA&amp;author=Thompson%2CM&amp;author=Kerridge%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR6">Bankins, S. (2021). The ethical use of artificial intelligence in human resource management: A decision-making framework. <i>Ethics and Information Technology,</i> <i>23</i>, 841–854.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s10676-021-09619-6" data-track-item_id="10.1007/s10676-021-09619-6" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s10676-021-09619-6" aria-label="Article reference 6" data-doi="10.1007/s10676-021-09619-6">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20ethical%20use%20of%20artificial%20intelligence%20in%20human%20resource%20management%3A%20A%20decision%20making%20framework&amp;journal=Ethics%20and%20Information%20Technology&amp;doi=10.1007%2Fs10676-021-09619-6&amp;volume=23&amp;pages=841-854&amp;publication_year=2021&amp;author=Bankins%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR7">Bankins, S., &amp; Formosa, P. (2020). When AI meets PC: Exploring the implications of workplace social robots and a human-robot psychological contract. <i>European Journal of Work and Organizational Psychology,</i> <i>29</i>(2), 215–229.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/1359432X.2019.1620328" data-track-item_id="10.1080/1359432X.2019.1620328" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F1359432X.2019.1620328" aria-label="Article reference 7" data-doi="10.1080/1359432X.2019.1620328">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=When%20AI%20meets%20PC%3A%20Exploring%20the%20implications%20of%20workplace%20social%20robots%20and%20a%20human-robot%20psychological%20contract&amp;journal=European%20Journal%20of%20Work%20and%20Organizational%20Psychology&amp;doi=10.1080%2F1359432X.2019.1620328&amp;volume=29&amp;issue=2&amp;pages=215-229&amp;publication_year=2020&amp;author=Bankins%2CS&amp;author=Formosa%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR8">Bankins, S., &amp; Formosa, P. (2021). Ethical AI at work: The social contract for artificial intelligence and its implications for the workplace psychological contract. In: M. Coetzee &amp; A. Deas (Eds.), <i>Redefining the Psychological Contract in the Digital Era: Issues for Research and Practice</i> (pp. 55–72). Springer: Switzerland.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR9">Bankins, S., Formosa, P., Griep, Y., &amp; Richards, D. (2022). AI decision making with dignity? Contrasting workers' justice perceptions of human and AI decision making in a human resource management context. <i>Information Systems Frontiers</i>, <i>24</i>(3), 857–875.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=AI%20decision%20making%20with%20dignity%3F%20Contrasting%20workers%27%20justice%20perceptions%20of%20human%20and%20AI%20decision%20making%20in%20a%20human%20resource%20management%20context.&amp;pages=857-875&amp;publication_year=2022&amp;author=Bankins%2CS&amp;author=Formosa%2CP&amp;author=Griep%2CY&amp;author=Richards%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR10">Bekey, G. A. (2012). Current trends in robotics. In P. Lin, K. Abney, &amp; G. A. Bekey (Eds.), <i>Robot ethics</i> (pp. 17–34). MIT Press: Cambridge, Mass.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Current%20trends%20in%20robotics&amp;pages=17-34&amp;publication_year=2012&amp;author=Bekey%2CGA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR11">Berk, R. A. (2021). Artificial intelligence, predictive policing, and risk assessment for law enforcement. <i>Annual Review of Criminology,</i> <i>4</i>(1), 209–237.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1146/annurev-criminol-051520-012342" data-track-item_id="10.1146/annurev-criminol-051520-012342" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-criminol-051520-012342" aria-label="Article reference 11" data-doi="10.1146/annurev-criminol-051520-012342">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Artificial%20intelligence%2C%20predictive%20policing%2C%20and%20risk%20assessment%20for%20law%20enforcement&amp;journal=Annual%20Review%20of%20Criminology&amp;doi=10.1146%2Fannurev-criminol-051520-012342&amp;volume=4&amp;issue=1&amp;pages=209-237&amp;publication_year=2021&amp;author=Berk%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR12">Boden, M. A. (2016). <i>AI</i>. Oxford University Press: UK.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=AI&amp;publication_year=2016&amp;author=Boden%2CMA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR14">Bourmault, N., &amp; Anteby, M. (2020). Unpacking the managerial blues: How expectations formed in the past carry into new jobs. <i>Organization Science,</i> <i>31</i>(6), 1452–1474.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1287/orsc.2020.1361" data-track-item_id="10.1287/orsc.2020.1361" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1287%2Forsc.2020.1361" aria-label="Article reference 13" data-doi="10.1287/orsc.2020.1361">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Unpacking%20the%20managerial%20blues%3A%20How%20expectations%20formed%20in%20the%20past%20carry%20into%20new%20jobs&amp;journal=Organization%20Science&amp;doi=10.1287%2Forsc.2020.1361&amp;volume=31&amp;issue=6&amp;pages=1452-1474&amp;publication_year=2020&amp;author=Bourmault%2CN&amp;author=Anteby%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR15">Bowie, N. E. (1998). A Kantian theory of meaningful work. <i>Journal of Business Ethics,</i> <i>17</i>, 1083–1092.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1023/A:1006023500585" data-track-item_id="10.1023/A:1006023500585" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1023%2FA%3A1006023500585" aria-label="Article reference 14" data-doi="10.1023/A:1006023500585">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Kantian%20theory%20of%20meaningful%20work&amp;journal=Journal%20of%20Business%20Ethics&amp;doi=10.1023%2FA%3A1006023500585&amp;volume=17&amp;pages=1083-1092&amp;publication_year=1998&amp;author=Bowie%2CNE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR16">Bruun, E., &amp; Duka, A. (2018). Artificial intelligence, jobs and the future of work. <i>Basic Income Studies,</i> <i>13</i>(2), 1–15.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1515/bis-2018-0018" data-track-item_id="10.1515/bis-2018-0018" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1515%2Fbis-2018-0018" aria-label="Article reference 15" data-doi="10.1515/bis-2018-0018">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Artificial%20intelligence%2C%20jobs%20and%20the%20future%20of%20work&amp;journal=Basic%20Income%20Studies&amp;doi=10.1515%2Fbis-2018-0018&amp;volume=13&amp;issue=2&amp;pages=1-15&amp;publication_year=2018&amp;author=Bruun%2CE&amp;author=Duka%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR18">Camus, A. (1955). <i>The myth of Sisyphus and other essays</i>. Hamish Hamilton.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20myth%20of%20Sisyphus%20and%20other%20essays&amp;publication_year=1955&amp;author=Camus%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR19">Carton, A. M. (2018). I’m not mopping the floors, I’m putting a man on the moon: How NASA leaders enhanced the meaningfulness of work by changing the meaning of work. <i>Administrative Science Quarterly,</i> <i>63</i>(2), 323–369.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/0001839217713748" data-track-item_id="10.1177/0001839217713748" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F0001839217713748" aria-label="Article reference 17" data-doi="10.1177/0001839217713748">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=I%E2%80%99m%20not%20mopping%20the%20floors%2C%20I%E2%80%99m%20putting%20a%20man%20on%20the%20moon%3A%20How%20NASA%20leaders%20enhanced%20the%20meaningfulness%20of%20work%20by%20changing%20the%20meaning%20of%20work&amp;journal=Administrative%20Science%20Quarterly&amp;doi=10.1177%2F0001839217713748&amp;volume=63&amp;issue=2&amp;pages=323-369&amp;publication_year=2018&amp;author=Carton%2CAM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR200">Cheney, G., Zorn Jr, T. E., Planalp, S., &amp; Lair, D. J. (2008). Meaningful work and personal/social well-being organizational communication engages the meanings of work. <i>Annals of the International Communication Association, 32</i>(1), 137–185.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR20">Chui, M., Manyika, J., &amp; Miremadi, M. (2015). <i>The four fundamentals of workplace automation</i>. McKinsey. <a href="http://www.mckinsey.com/business-functions/digital-mckinsey/our-insights/four-fundamentals-of-workplace-automation" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="http://www.mckinsey.com/business-functions/digital-mckinsey/our-insights/four-fundamentals-of-workplace-automation">http://www.mckinsey.com/business-functions/digital-mckinsey/our-insights/four-fundamentals-of-workplace-automation</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR21">Dahl, E. S. (2018). Appraising black-boxed technology: The positive prospects. <i>Philosophy &amp; Technology,</i> <i>31</i>, 571–591.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s13347-017-0275-1" data-track-item_id="10.1007/s13347-017-0275-1" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s13347-017-0275-1" aria-label="Article reference 20" data-doi="10.1007/s13347-017-0275-1">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Appraising%20black-boxed%20technology%3A%20The%20positive%20prospects&amp;journal=Philosophy%20%26%20Technology&amp;doi=10.1007%2Fs13347-017-0275-1&amp;volume=31&amp;pages=571-591&amp;publication_year=2018&amp;author=Dahl%2CES">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR22">Dastin, J. (2018, October 11). Amazon scraps secret AI recruiting tool that showed bias against women. <i>Reuters</i>. <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR23">Daugherty, P. R., &amp; Wilson, H. J. (2018). <i>Human + Machine: Reimagining work in the age of AI.</i> Harvard Business Review Press.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20%2B%20Machine%3A%20Reimagining%20work%20in%20the%20age%20of%20AI&amp;publication_year=2018&amp;author=Daugherty%2CPR&amp;author=Wilson%2CHJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR24">Engel, S. (2019). Minding machines: A note on alienation. <i>Fast Capitalism,</i> <i>16</i>(2), 129–139.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.32855/fcapital.201902.012" data-track-item_id="10.32855/fcapital.201902.012" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.32855%2Ffcapital.201902.012" aria-label="Article reference 23" data-doi="10.32855/fcapital.201902.012">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Minding%20machines%3A%20A%20note%20on%20alienation&amp;journal=Fast%20Capitalism&amp;doi=10.32855%2Ffcapital.201902.012&amp;volume=16&amp;issue=2&amp;pages=129-139&amp;publication_year=2019&amp;author=Engel%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR25">Ernst, E., Merola, R., &amp; Samaan, D. (2018). <i>The economics of artificial intelligence</i>. International Labour Organization. <a href="https://www.ilo.org/wcmsp5/groups/public/dgreports/cabinet/documents/publication/wcms_647306.pdf" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.ilo.org/wcmsp5/groups/public/dgreports/cabinet/documents/publication/wcms_647306.pdf">https://www.ilo.org/wcmsp5/groups/public/dgreports/cabinet/documents/publication/wcms_647306.pdf</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR26">Floridi, L., et al. (2018). AI4People - An ethical framework for a good AI society. <i>Minds and Machines,</i> <i>28</i>(4), 689–707.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s11023-018-9482-5" data-track-item_id="10.1007/s11023-018-9482-5" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s11023-018-9482-5" aria-label="Article reference 25" data-doi="10.1007/s11023-018-9482-5">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=AI4People%20-%20An%20ethical%20framework%20for%20a%20good%20AI%20society&amp;journal=Minds%20and%20Machines&amp;doi=10.1007%2Fs11023-018-9482-5&amp;volume=28&amp;issue=4&amp;pages=689-707&amp;publication_year=2018&amp;author=Floridi%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR27">Formosa, P. (2017). <i>Kantian ethics, dignity and perfection</i>. Cambridge University Press: Cambridge.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1017/9781316987308" data-track-item_id="10.1017/9781316987308" data-track-value="book reference" data-track-action="book reference" href="https://doi.org/10.1017%2F9781316987308" aria-label="Book reference 26" data-doi="10.1017/9781316987308">Book</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Kantian%20ethics%2C%20dignity%20and%20perfection&amp;doi=10.1017%2F9781316987308&amp;publication_year=2017&amp;author=Formosa%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR28">Formosa, P. (2021). Robot autonomy vs human autonomy: Social robots, artificial intelligence (AI), and the nature of autonomy. <i>Minds and Machines, 31,</i> 595–616.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR29">Formosa, P., &amp; Ryan, M. (2021). Making moral machines: Why we need artificial moral agents. <i>AI &amp; Society,</i> <i>36</i>, 839–851.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s00146-020-01089-6" data-track-item_id="10.1007/s00146-020-01089-6" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s00146-020-01089-6" aria-label="Article reference 28" data-doi="10.1007/s00146-020-01089-6">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Making%20moral%20machines%3A%20Why%20we%20need%20artificial%20moral%20agents&amp;journal=AI%20%26%20Society&amp;doi=10.1007%2Fs00146-020-01089-6&amp;volume=36&amp;pages=839-851&amp;publication_year=2021&amp;author=Formosa%2CP&amp;author=Ryan%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR30">Formosa, P., Wilson, M., &amp; Richards, D. (2021). A principlist framework for cybersecurity ethics. <i>Computers &amp; Security,</i> <i>109</i>, 102382.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.cose.2021.102382" data-track-item_id="10.1016/j.cose.2021.102382" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cose.2021.102382" aria-label="Article reference 29" data-doi="10.1016/j.cose.2021.102382">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20principlist%20framework%20for%20cybersecurity%20ethics&amp;journal=Computers%20%26%20Security&amp;doi=10.1016%2Fj.cose.2021.102382&amp;volume=109&amp;publication_year=2021&amp;author=Formosa%2CP&amp;author=Wilson%2CM&amp;author=Richards%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR31">Frey, C. B., &amp; Osborne, M. A. (2017). The future of employment: How susceptible are jobs to computerisation? <i>Technological Forecasting and Social Change,</i> <i>114</i>, 254–280.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.techfore.2016.08.019" data-track-item_id="10.1016/j.techfore.2016.08.019" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.techfore.2016.08.019" aria-label="Article reference 30" data-doi="10.1016/j.techfore.2016.08.019">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20future%20of%20employment%3A%20How%20susceptible%20are%20jobs%20to%20computerisation%3F&amp;journal=Technological%20Forecasting%20and%20Social%20Change&amp;doi=10.1016%2Fj.techfore.2016.08.019&amp;volume=114&amp;pages=254-280&amp;publication_year=2017&amp;author=Frey%2CCB&amp;author=Osborne%2CMA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR32">Gibbs, M. J. (2017). How is new technology changing job design? <i>IZA World of Labor</i>. <a href="https://doi.org/10.15185/izawol.344" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.15185/izawol.344">https://doi.org/10.15185/izawol.344</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.15185/izawol.344" data-track-item_id="10.15185/izawol.344" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.15185%2Fizawol.344" aria-label="Article reference 31" data-doi="10.15185/izawol.344">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20is%20new%20technology%20changing%20job%20design%3F&amp;journal=IZA%20World%20of%20Labor&amp;doi=10.15185%2Fizawol.344&amp;publication_year=2017&amp;author=Gibbs%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR201">Gladden, M. E. (2016). <i>Posthuman management: Creating effective organizations in an age of social robotics, ubiquitous AI, human augmentation, and virtual worlds</i>. Defragmenter Media: USA.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR33">Grant, A. M. (2007). Relational job design and the motivation to make a prosocial difference. <i>Academy of Management Review,</i> <i>32</i>(2), 393–417.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.5465/amr.2007.24351328" data-track-item_id="10.5465/amr.2007.24351328" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.5465%2Famr.2007.24351328" aria-label="Article reference 33" data-doi="10.5465/amr.2007.24351328">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Relational%20job%20design%20and%20the%20motivation%20to%20make%20a%20prosocial%20difference&amp;journal=Academy%20of%20Management%20Review&amp;doi=10.5465%2Famr.2007.24351328&amp;volume=32&amp;issue=2&amp;pages=393-417&amp;publication_year=2007&amp;author=Grant%2CAM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR34">Grant, A. M. (2008). The significance of task significance: Job performance effects, relational mechanisms, and boundary conditions. <i>Journal of Applied Psychology,</i> <i>93</i>(1), 108–124.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/0021-9010.93.1.108" data-track-item_id="10.1037/0021-9010.93.1.108" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F0021-9010.93.1.108" aria-label="Article reference 34" data-doi="10.1037/0021-9010.93.1.108">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20significance%20of%20task%20significance%3A%20Job%20performance%20effects%2C%20relational%20mechanisms%2C%20and%20boundary%20conditions&amp;journal=Journal%20of%20Applied%20Psychology&amp;doi=10.1037%2F0021-9010.93.1.108&amp;volume=93&amp;issue=1&amp;pages=108-124&amp;publication_year=2008&amp;author=Grant%2CAM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR35">Grogger, J., Ivandic, R., &amp; Kirchmaier, T. (2020). Comparing conventional and machine-learning approaches to risk assessment in domestic abuse cases. <i>Journal of Empirical Legal Studies,</i> <i>18</i>(1), 90–130.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1111/jels.12276" data-track-item_id="10.1111/jels.12276" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1111%2Fjels.12276" aria-label="Article reference 35" data-doi="10.1111/jels.12276">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparing%20conventional%20and%20machine-learning%20approaches%20to%20risk%20assessment%20in%20domestic%20abuse%20cases&amp;journal=Journal%20of%20Empirical%20Legal%20Studies&amp;doi=10.1111%2Fjels.12276&amp;volume=18&amp;issue=1&amp;pages=90-130&amp;publication_year=2020&amp;author=Grogger%2CJ&amp;author=Ivandic%2CR&amp;author=Kirchmaier%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR36">Hackman, J. R., &amp; Oldham, G. R. (1975). Development of the job diagnostic survey. <i>Journal of Applied Psychology,</i> <i>60</i>(2), 159–170.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/h0076546" data-track-item_id="10.1037/h0076546" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2Fh0076546" aria-label="Article reference 36" data-doi="10.1037/h0076546">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20of%20the%20job%20diagnostic%20survey&amp;journal=Journal%20of%20Applied%20Psychology&amp;doi=10.1037%2Fh0076546&amp;volume=60&amp;issue=2&amp;pages=159-170&amp;publication_year=1975&amp;author=Hackman%2CJR&amp;author=Oldham%2CGR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR37">Hackman, J. R., &amp; Oldham, G. R. (1976). Motivation through the design of work: Test of a theory. <i>Organizational Behavior and Human Performance,</i> <i>16</i>(2), 250–279.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0030-5073(76)90016-7" data-track-item_id="10.1016/0030-5073(76)90016-7" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0030-5073%2876%2990016-7" aria-label="Article reference 37" data-doi="10.1016/0030-5073(76)90016-7">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Motivation%20through%20the%20design%20of%20work%3A%20Test%20of%20a%20theory&amp;journal=Organizational%20Behavior%20and%20Human%20Performance&amp;doi=10.1016%2F0030-5073%2876%2990016-7&amp;volume=16&amp;issue=2&amp;pages=250-279&amp;publication_year=1976&amp;author=Hackman%2CJR&amp;author=Oldham%2CGR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR38">Hagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. <i>Minds and Machines, 30</i>, 99–120.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s11023-020-09517-8" data-track-item_id="10.1007/s11023-020-09517-8" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s11023-020-09517-8" aria-label="Article reference 38" data-doi="10.1007/s11023-020-09517-8">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20ethics%20of%20AI%20ethics%3A%20An%20evaluation%20of%20guidelines&amp;journal=Minds%20and%20Machines&amp;doi=10.1007%2Fs11023-020-09517-8&amp;volume=30&amp;pages=99-120&amp;publication_year=2020&amp;author=Hagendorff%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR39">Hagras, H. (2018). Toward human-understandable, explainable AI. <i>Computer,</i> <i>51</i>(9), 28–36.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/MC.2018.3620965" data-track-item_id="10.1109/MC.2018.3620965" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FMC.2018.3620965" aria-label="Article reference 39" data-doi="10.1109/MC.2018.3620965">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Toward%20human-understandable%2C%20explainable%20AI&amp;journal=Computer&amp;doi=10.1109%2FMC.2018.3620965&amp;volume=51&amp;issue=9&amp;pages=28-36&amp;publication_year=2018&amp;author=Hagras%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR40">Halloran, L. &amp; Andrews, J. (2018). <i>Will you wait for the future to happen?</i> Ernst and Young. <a href="https://www.ey.com/en_au/workforce/will-you-shape-the-future-of-work-or-will-it-shape-you" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.ey.com/en_au/workforce/will-you-shape-the-future-of-work-or-will-it-shape-you">https://www.ey.com/en_au/workforce/will-you-shape-the-future-of-work-or-will-it-shape-you</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR41">Hassabis, D., &amp; Revell, T. (2021). With AI, you might unlock some of the secrets about how life works. <i>New Scientist,</i> <i>249</i>(3315), 44–49.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/S0262-4079(20)32269-7" data-track-item_id="10.1016/S0262-4079(20)32269-7" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2FS0262-4079%2820%2932269-7" aria-label="Article reference 41" data-doi="10.1016/S0262-4079(20)32269-7">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=With%20AI%2C%20you%20might%20unlock%20some%20of%20the%20secrets%20about%20how%20life%20works&amp;journal=New%20Scientist&amp;doi=10.1016%2FS0262-4079%2820%2932269-7&amp;volume=249&amp;issue=3315&amp;pages=44-49&amp;publication_year=2021&amp;author=Hassabis%2CD&amp;author=Revell%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR42">Hughes, J. (2014). A strategic opening for a basic income guarantee in the global crisis being created by AI, robots, desktop manufacturing and biomedicine. <i>Journal of Ethics and Emerging Technologies,</i> <i>24</i>(1), 45–61.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.55613/jeet.v24i1.12" data-track-item_id="10.55613/jeet.v24i1.12" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.55613%2Fjeet.v24i1.12" aria-label="Article reference 42" data-doi="10.55613/jeet.v24i1.12">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20strategic%20opening%20for%20a%20basic%20income%20guarantee%20in%20the%20global%20crisis%20being%20created%20by%20AI%2C%20robots%2C%20desktop%20manufacturing%20and%20biomedicine&amp;journal=Journal%20of%20Ethics%20and%20Emerging%20Technologies&amp;doi=10.55613%2Fjeet.v24i1.12&amp;volume=24&amp;issue=1&amp;pages=45-61&amp;publication_year=2014&amp;author=Hughes%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR43">Jarrahi, M. H. (2018). Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making. <i>Business Horizons,</i> <i>61</i>(4), 577–586.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.bushor.2018.03.007" data-track-item_id="10.1016/j.bushor.2018.03.007" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.bushor.2018.03.007" aria-label="Article reference 43" data-doi="10.1016/j.bushor.2018.03.007">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Artificial%20intelligence%20and%20the%20future%20of%20work%3A%20Human-AI%20symbiosis%20in%20organizational%20decision%20making&amp;journal=Business%20Horizons&amp;doi=10.1016%2Fj.bushor.2018.03.007&amp;volume=61&amp;issue=4&amp;pages=577-586&amp;publication_year=2018&amp;author=Jarrahi%2CMH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR44">Jarrahi, M. H. (2019). In the age of the smart artificial intelligence: AI's dual capacities for automating and informating work. <i>Business Information Review,</i> <i>36</i>(4), 178–187.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/0266382119883999" data-track-item_id="10.1177/0266382119883999" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F0266382119883999" aria-label="Article reference 44" data-doi="10.1177/0266382119883999">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=In%20the%20age%20of%20the%20smart%20artificial%20intelligence%3A%20AI%27s%20dual%20capacities%20for%20automating%20and%20informating%20work&amp;journal=Business%20Information%20Review&amp;doi=10.1177%2F0266382119883999&amp;volume=36&amp;issue=4&amp;pages=178-187&amp;publication_year=2019&amp;author=Jarrahi%2CMH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR45">Jobin, A., Ienca, M., &amp; Vayena, E. (2019). The global landscape of AI ethics guidelines. <i>Nature Machine Intelligence,</i> <i>1</i>(9), 389–399.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s42256-019-0088-2" data-track-item_id="10.1038/s42256-019-0088-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs42256-019-0088-2" aria-label="Article reference 45" data-doi="10.1038/s42256-019-0088-2">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20global%20landscape%20of%20AI%20ethics%20guidelines&amp;journal=Nature%20Machine%20Intelligence&amp;doi=10.1038%2Fs42256-019-0088-2&amp;volume=1&amp;issue=9&amp;pages=389-399&amp;publication_year=2019&amp;author=Jobin%2CA&amp;author=Ienca%2CM&amp;author=Vayena%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR46">Kellogg, K. C., Valentine, M. A., &amp; Christin, A. (2020). Algorithms at work: The new contested terrain of control. <i>Academy of Management Annals,</i> <i>14</i>(1), 366–410.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.5465/annals.2018.0174" data-track-item_id="10.5465/annals.2018.0174" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.5465%2Fannals.2018.0174" aria-label="Article reference 46" data-doi="10.5465/annals.2018.0174">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Algorithms%20at%20work%3A%20The%20new%20contested%20terrain%20of%20control&amp;journal=Academy%20of%20Management%20Annals&amp;doi=10.5465%2Fannals.2018.0174&amp;volume=14&amp;issue=1&amp;pages=366-410&amp;publication_year=2020&amp;author=Kellogg%2CKC&amp;author=Valentine%2CMA&amp;author=Christin%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR47">Langlois, R. N. (2003). Cognitive comparative advantage and the organization of work: Lessons from Herbert Simon's vision of the future. <i>Journal of Economic Psychology,</i> <i>24</i>(2), 167–187.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/S0167-4870(02)00201-5" data-track-item_id="10.1016/S0167-4870(02)00201-5" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2FS0167-4870%2802%2900201-5" aria-label="Article reference 47" data-doi="10.1016/S0167-4870(02)00201-5">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Cognitive%20comparative%20advantage%20and%20the%20organization%20of%20work%3A%20Lessons%20from%20Herbert%20Simon%27s%20vision%20of%20the%20future&amp;journal=Journal%20of%20Economic%20Psychology&amp;doi=10.1016%2FS0167-4870%2802%2900201-5&amp;volume=24&amp;issue=2&amp;pages=167-187&amp;publication_year=2003&amp;author=Langlois%2CRN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR48">Leicht-Deobald, U., et al. (2019). The challenges of algorithm-based HR decision-making for personal integrity. <i>Journal of Business Ethics,</i> <i>160</i>, 377–392.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s10551-019-04204-w" data-track-item_id="10.1007/s10551-019-04204-w" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s10551-019-04204-w" aria-label="Article reference 48" data-doi="10.1007/s10551-019-04204-w">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20challenges%20of%20algorithm-based%20HR%20decision-making%20for%20personal%20integrity&amp;journal=Journal%20of%20Business%20Ethics&amp;doi=10.1007%2Fs10551-019-04204-w&amp;volume=160&amp;pages=377-392&amp;publication_year=2019&amp;author=Leicht-Deobald%2CU">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR49">Lips-Wiersma, M., &amp; Morris, L. (2009). Discriminating between ‘meaningful work’ and the ‘management of meaning.’ <i>Journal of Business Ethics,</i> <i>88</i>(3), 491–511.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s10551-009-0118-9" data-track-item_id="10.1007/s10551-009-0118-9" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s10551-009-0118-9" aria-label="Article reference 49" data-doi="10.1007/s10551-009-0118-9">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Discriminating%20between%20%E2%80%98meaningful%20work%E2%80%99%20and%20the%20%E2%80%98management%20of%20meaning%E2%80%99&amp;journal=Journal%20of%20Business%20Ethics&amp;doi=10.1007%2Fs10551-009-0118-9&amp;volume=88&amp;issue=3&amp;pages=491-511&amp;publication_year=2009&amp;author=Lips-Wiersma%2CM&amp;author=Morris%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR50">Lips-Wiersma, M., &amp; Wright, S. (2012). Measuring the meaning of meaningful work: Development and validation of the comprehensive meaningful work scale. <i>Group &amp; Organization Management,</i> <i>37</i>(5), 655–685.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/1059601112461578" data-track-item_id="10.1177/1059601112461578" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F1059601112461578" aria-label="Article reference 50" data-doi="10.1177/1059601112461578">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20the%20meaning%20of%20meaningful%20work%3A%20Development%20and%20validation%20of%20the%20comprehensive%20meaningful%20work%20scale&amp;journal=Group%20%26%20Organization%20Management&amp;doi=10.1177%2F1059601112461578&amp;volume=37&amp;issue=5&amp;pages=655-685&amp;publication_year=2012&amp;author=Lips-Wiersma%2CM&amp;author=Wright%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR51">Lysova, E. I., Allan, B. A., Dik, B. J., Duffy, R. D., &amp; Steger, M. F. (2019). Fostering meaningful work in organizations: A multi-level review and integration. <i>Journal of Vocational Behavior,</i> <i>110</i>, 374–389.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.jvb.2018.07.004" data-track-item_id="10.1016/j.jvb.2018.07.004" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jvb.2018.07.004" aria-label="Article reference 51" data-doi="10.1016/j.jvb.2018.07.004">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Fostering%20meaningful%20work%20in%20organizations%3A%20A%20multi-level%20review%20and%20integration&amp;journal=Journal%20of%20Vocational%20Behavior&amp;doi=10.1016%2Fj.jvb.2018.07.004&amp;volume=110&amp;pages=374-389&amp;publication_year=2019&amp;author=Lysova%2CEI&amp;author=Allan%2CBA&amp;author=Dik%2CBJ&amp;author=Duffy%2CRD&amp;author=Steger%2CMF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR52">Martela, F., &amp; Riekki, T. J. J. (2018). Autonomy, competence, relatedness, and beneficence: A multicultural comparison of the four pathways to meaningful work. <i>Frontiers in Psychology, 9</i>, 1157.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR202">Mazmanian, M., Orlikowski, W. J., &amp; Yates, J. (2013). The autonomy paradox: The implications of mobile email devices for knowledge professionals. <i>Organization Science, 24</i>(5), 1337–1357.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR53">Michaelson, C., Pratt, M. G., Grant, A. M., &amp; Dunn, C. P. (2014). Meaningful work: Connecting business ethics and organization studies. <i>Journal of Business Ethics,</i> <i>121</i>, 77–90.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s10551-013-1675-5" data-track-item_id="10.1007/s10551-013-1675-5" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s10551-013-1675-5" aria-label="Article reference 54" data-doi="10.1007/s10551-013-1675-5">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=Meaningful%20work%3A%20Connecting%20business%20ethics%20and%20organization%20studies&amp;journal=Journal%20of%20Business%20Ethics&amp;doi=10.1007%2Fs10551-013-1675-5&amp;volume=121&amp;pages=77-90&amp;publication_year=2014&amp;author=Michaelson%2CC&amp;author=Pratt%2CMG&amp;author=Grant%2CAM&amp;author=Dunn%2CCP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR54">Molitorisz, S. (2020). <i>Net privacy: How we can be free in an age of surveillance</i>. McGill-Queen’s University Press: Canada.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1515/9780228002888" data-track-item_id="10.1515/9780228002888" data-track-value="book reference" data-track-action="book reference" href="https://doi.org/10.1515%2F9780228002888" aria-label="Book reference 55" data-doi="10.1515/9780228002888">Book</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Net%20privacy%3A%20How%20we%20can%20be%20free%20in%20an%20age%20of%20surveillance&amp;doi=10.1515%2F9780228002888&amp;publication_year=2020&amp;author=Molitorisz%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR55">Naudé, W., &amp; Dimitri, N. (2020). The race for an artificial general intelligence: Implications for public policy. <i>AI &amp; Society,</i> <i>35</i>, 367–379.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s00146-019-00887-x" data-track-item_id="10.1007/s00146-019-00887-x" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s00146-019-00887-x" aria-label="Article reference 56" data-doi="10.1007/s00146-019-00887-x">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20race%20for%20an%20artificial%20general%20intelligence%3A%20Implications%20for%20public%20policy&amp;journal=AI%20%26%20Society&amp;doi=10.1007%2Fs00146-019-00887-x&amp;volume=35&amp;pages=367-379&amp;publication_year=2020&amp;author=Naud%C3%A9%2CW&amp;author=Dimitri%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR56">Nussbaum, M. C. (2011). <i>Creating capabilities: The human development approach</i>. Harvard University Press: USA.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.4159/harvard.9780674061200" data-track-item_id="10.4159/harvard.9780674061200" data-track-value="book reference" data-track-action="book reference" href="https://doi.org/10.4159%2Fharvard.9780674061200" aria-label="Book reference 57" data-doi="10.4159/harvard.9780674061200">Book</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 57" href="http://scholar.google.com/scholar_lookup?&amp;title=Creating%20capabilities%3A%20The%20human%20development%20approach&amp;doi=10.4159%2Fharvard.9780674061200&amp;publication_year=2011&amp;author=Nussbaum%2CMC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR57">Pardes, A. (2020, November). AI can run your work meetings now. <i>Wired</i>. <a href="https://www.wired.com/story/ai-can-run-work-meetings-now-headroom-clockwise/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.wired.com/story/ai-can-run-work-meetings-now-headroom-clockwise/">https://www.wired.com/story/ai-can-run-work-meetings-now-headroom-clockwise/</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR58">Parker, S. K., &amp; Grote, G. (2022). Automation, algorithms, and beyond: Why work design matters more than ever in a digital world. <i>Applied Psychology, 71</i>(4), 1171–1204.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1111/apps.12241" data-track-item_id="10.1111/apps.12241" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1111%2Fapps.12241" aria-label="Article reference 59" data-doi="10.1111/apps.12241">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 59" href="http://scholar.google.com/scholar_lookup?&amp;title=Automation%2C%20algorithms%2C%20and%20beyond%3A%20Why%20work%20design%20matters%20more%20than%20ever%20in%20a%20digital%20world&amp;journal=Applied%20Psychology&amp;doi=10.1111%2Fapps.12241&amp;volume=71&amp;issue=4&amp;pages=1171-1204&amp;publication_year=2022&amp;author=Parker%2CSK&amp;author=Grote%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR59">Pratt, M. G., &amp; Ashforth, B. E. (2003). <i>Fostering meaningfulness in working and at work</i>. In K. Cameron, J. E. Dutton, &amp; R. E. Quinn (Eds.), <i>Positive organizational scholarship: Foundations of a new discipline</i> (pp. 308–327). Berrett-Koehler: San Francisco.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR60">Pulse+IT. (2020). The San using AI to automate multidisciplinary team meetings. <i>Pulse+IT.</i> <a href="https://www.pulseitmagazine.com.au:443/australian-ehealth/5558-the-san-using-ai-to-automate-multidisciplinary-team-meetings" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.pulseitmagazine.com.au:443/australian-ehealth/5558-the-san-using-ai-to-automate-multidisciplinary-team-meetings">https://www.pulseitmagazine.com.au:443/australian-ehealth/5558-the-san-using-ai-to-automate-multidisciplinary-team-meetings</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR61">Ravenscraft, E. (25 November, 2021). What is the metaverse, exactly? <i>Wired</i>. Retrieved from: <a href="https://www.wired.com/story/what-is-the-metaverse/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.wired.com/story/what-is-the-metaverse/">https://www.wired.com/story/what-is-the-metaverse/</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR62">Roberts, P. (2020). Working smarter with data. <i>Australian Manufacturing Forum</i>. <a href="https://www.aumanufacturing.com.au/working-smarter-with-data-ai-gives-agriculture-the-competitive-edge" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.aumanufacturing.com.au/working-smarter-with-data-ai-gives-agriculture-the-competitive-edge">https://www.aumanufacturing.com.au/working-smarter-with-data-ai-gives-agriculture-the-competitive-edge</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR63">Ryan, M., &amp; Stahl, B. C. (2020). Artificial intelligence ethics guidelines for developers and users: Clarifying their content and normative implications. <i>Journal of Information, Communication and Ethics in Society, 19</i>(1), 61–86.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1108/JICES-12-2019-0138" data-track-item_id="10.1108/JICES-12-2019-0138" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1108%2FJICES-12-2019-0138" aria-label="Article reference 64" data-doi="10.1108/JICES-12-2019-0138">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=Artificial%20intelligence%20ethics%20guidelines%20for%20developers%20and%20users%3A%20Clarifying%20their%20content%20and%20normative%20implications&amp;journal=Journal%20of%20Information%2C%20Communication%20and%20Ethics%20in%20Society.&amp;doi=10.1108%2FJICES-12-2019-0138&amp;volume=19&amp;issue=1&amp;pages=61-86&amp;publication_year=2020&amp;author=Ryan%2CM&amp;author=Stahl%2CBC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR203">Selbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., &amp; Vertesi, J. (2019). Fairness and abstraction in sociotechnical systems. In <i>Proceedings of the Conference on Fairness, Accountability, and Transparency</i> (pp. 59–68).</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR204">Selenko, E., Bankins, S., Shoss, M., Warburton, J., &amp; Restubog, S. L. D. (2022). Artificial intelligence and the future of work: A functional-identity perspective. <i>Current Directions in Psychological Science, 31</i>(3), 272–279.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR64">Seppala, E., Rossomando, T., &amp; Doty, J. R. (2013). Social connection and compassion: Important predictors of health and well-being. <i>Social Research,</i> <i>80</i>(2), 411–430.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1353/sor.2013.0027" data-track-item_id="10.1353/sor.2013.0027" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1353%2Fsor.2013.0027" aria-label="Article reference 67" data-doi="10.1353/sor.2013.0027">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=Social%20connection%20and%20compassion%3A%20Important%20predictors%20of%20health%20and%20well-being&amp;journal=Social%20Research&amp;doi=10.1353%2Fsor.2013.0027&amp;volume=80&amp;issue=2&amp;pages=411-430&amp;publication_year=2013&amp;author=Seppala%2CE&amp;author=Rossomando%2CT&amp;author=Doty%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR65">Smids, J., Nyholm, S., &amp; Berkers, H. (2020). Robots in the workplace: A threat to - or opportunity for - meaningful work? <i>Philosophy &amp; Technology,</i> <i>33</i>, 503–522.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s13347-019-00377-4" data-track-item_id="10.1007/s13347-019-00377-4" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s13347-019-00377-4" aria-label="Article reference 68" data-doi="10.1007/s13347-019-00377-4">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=Robots%20in%20the%20workplace%3A%20A%20threat%20to%20-%20or%20opportunity%20for%20-%20meaningful%20work%3F&amp;journal=Philosophy%20%26%20Technology&amp;doi=10.1007%2Fs13347-019-00377-4&amp;volume=33&amp;pages=503-522&amp;publication_year=2020&amp;author=Smids%2CJ&amp;author=Nyholm%2CS&amp;author=Berkers%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR66">Susser, D., Roessler, B., &amp; Nissenbaum, H. (2019). Technology, autonomy, and manipulation. <i>Internet Policy Review</i>. <a href="https://doi.org/10.14763/2019.2.1410" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.14763/2019.2.1410">https://doi.org/10.14763/2019.2.1410</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.14763/2019.2.1410" data-track-item_id="10.14763/2019.2.1410" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.14763%2F2019.2.1410" aria-label="Article reference 69" data-doi="10.14763/2019.2.1410">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 69" href="http://scholar.google.com/scholar_lookup?&amp;title=Technology%2C%20autonomy%2C%20and%20manipulation&amp;journal=Internet%20Policy%20Review&amp;doi=10.14763%2F2019.2.1410&amp;publication_year=2019&amp;author=Susser%2CD&amp;author=Roessler%2CB&amp;author=Nissenbaum%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR205">Symon, G., &amp; Whiting, R. (2019). The sociomaterial negotiation of social entrepreneurs’ meaningful work. <i>Journal of Management Studies, 56</i>(3), 655–684.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR67">Thaler, R., &amp; Sunstein, C. (2008). <i>Nudge:  Improving decisions about health, wealth, and happiness</i>. Yale University Press: New Haven, CT.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 71" href="http://scholar.google.com/scholar_lookup?&amp;title=Nudge%3A%20Improving%20decisions%20about%20health%2C%20wealth%2C%20and%20happiness&amp;publication_year=2008&amp;author=Thaler%2CR&amp;author=Sunstein%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR68">Torres, P. (2019). The possibility and risks of artificial general intelligence. <i>Bulletin of the Atomic Scientists,</i> <i>75</i>(3), 105–108.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/00963402.2019.1604873" data-track-item_id="10.1080/00963402.2019.1604873" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F00963402.2019.1604873" aria-label="Article reference 72" data-doi="10.1080/00963402.2019.1604873">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 72" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20possibility%20and%20risks%20of%20artificial%20general%20intelligence&amp;journal=Bulletin%20of%20the%20Atomic%20Scientists&amp;doi=10.1080%2F00963402.2019.1604873&amp;volume=75&amp;issue=3&amp;pages=105-108&amp;publication_year=2019&amp;author=Torres%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR69">Trope, Y., &amp; Liberman, N. (2003). Temporal construal. <i>Psychological Review,</i> <i>110</i>(3), 403–421.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/0033-295X.110.3.403" data-track-item_id="10.1037/0033-295X.110.3.403" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.110.3.403" aria-label="Article reference 73" data-doi="10.1037/0033-295X.110.3.403">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 73" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal%20construal&amp;journal=Psychological%20Review&amp;doi=10.1037%2F0033-295X.110.3.403&amp;volume=110&amp;issue=3&amp;pages=403-421&amp;publication_year=2003&amp;author=Trope%2CY&amp;author=Liberman%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR70">Tubaro, P., Casilli, A. A., &amp; Coville, M. (2020). The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence. <i>Big Data &amp; Society, 7</i>(1). <a href="https://doi.org/10.1177/2053951720919776" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1177/2053951720919776">https://doi.org/10.1177/2053951720919776</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR71">Vallor, S. (2015). Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character. <i>Philosophy &amp; Technology,</i> <i>28</i>(1), 107–124.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s13347-014-0156-9" data-track-item_id="10.1007/s13347-014-0156-9" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s13347-014-0156-9" aria-label="Article reference 75" data-doi="10.1007/s13347-014-0156-9">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="http://scholar.google.com/scholar_lookup?&amp;title=Moral%20deskilling%20and%20upskilling%20in%20a%20new%20machine%20age%3A%20Reflections%20on%20the%20ambiguous%20future%20of%20character&amp;journal=Philosophy%20%26%20Technology&amp;doi=10.1007%2Fs13347-014-0156-9&amp;volume=28&amp;issue=1&amp;pages=107-124&amp;publication_year=2015&amp;author=Vallor%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR73">Walsh, T., Levy, N., Bell, G., Elliott, A., Maclaurin, J., Mareels, I., &amp; Wood, Fiona. (2019). The effective and ethical development of artificial intelligence. <i>ACOLA</i>. <a href="https://acola.org/wp-content/uploads/2019/07/hs4_artificial-intelligence-report.pdf" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://acola.org/wp-content/uploads/2019/07/hs4_artificial-intelligence-report.pdf">https://acola.org/wp-content/uploads/2019/07/hs4_artificial-intelligence-report.pdf</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR209">Wang, P. (2019). On defining artificial intelligence. <i>Journal of Artificial General Intelligence, 10</i>(2), 1–37.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR206">Webster, C., &amp; Ivanov, S. (2020). <i>Robotics, artificial intelligence, and the evolving nature of work</i>. In: B. George &amp; J. Paul (Eds.), Digital Transformation in Business and Society. Palgrave Macmillan, Cham.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR74">Wiesenfeld, B. M., Reyt, J.-N., Brockner, J., &amp; Trope, Y. (2017). Construal level theory in organizational research. <i>Annual Review of Organizational Psychology and Organizational Behavior,</i> <i>4</i>(1), 367–400.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1146/annurev-orgpsych-032516-113115" data-track-item_id="10.1146/annurev-orgpsych-032516-113115" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-orgpsych-032516-113115" aria-label="Article reference 79" data-doi="10.1146/annurev-orgpsych-032516-113115">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 79" href="http://scholar.google.com/scholar_lookup?&amp;title=Construal%20level%20theory%20in%20organizational%20research&amp;journal=Annual%20Review%20of%20Organizational%20Psychology%20and%20Organizational%20Behavior&amp;doi=10.1146%2Fannurev-orgpsych-032516-113115&amp;volume=4&amp;issue=1&amp;pages=367-400&amp;publication_year=2017&amp;author=Wiesenfeld%2CBM&amp;author=Reyt%2CJ-N&amp;author=Brockner%2CJ&amp;author=Trope%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR75">Wolf, S. (2010). <i>Meaning in life and why it matters</i>. Princeton University Press: New Jersey.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.2307/j.ctt7t3cm" data-track-item_id="10.2307/j.ctt7t3cm" data-track-value="book reference" data-track-action="book reference" href="https://doi.org/10.2307%2Fj.ctt7t3cm" aria-label="Book reference 80" data-doi="10.2307/j.ctt7t3cm">Book</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 80" href="http://scholar.google.com/scholar_lookup?&amp;title=Meaning%20in%20life%20and%20why%20it%20matters&amp;doi=10.2307%2Fj.ctt7t3cm&amp;publication_year=2010&amp;author=Wolf%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR207">World Economic Forum. (2018). <i>The future of jobs report</i>. Centre for the New Economy and Society: Geneva, Switzerland.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR76">Wright, D. (2011). A framework for the ethical impact assessment of information technology. <i>Ethics and Information Technology,</i> <i>13</i>, 199–226.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s10676-010-9242-6" data-track-item_id="10.1007/s10676-010-9242-6" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s10676-010-9242-6" aria-label="Article reference 82" data-doi="10.1007/s10676-010-9242-6">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 82" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20framework%20for%20the%20ethical%20impact%20assessment%20of%20information%20technology&amp;journal=Ethics%20and%20Information%20Technology&amp;doi=10.1007%2Fs10676-010-9242-6&amp;volume=13&amp;pages=199-226&amp;publication_year=2011&amp;author=Wright%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR77">Wright, S. A., &amp; Schultz, A. E. (2018). The rising tide of artificial intelligence and business automation: Developing an ethical framework. <i>Business Horizons,</i> <i>61</i>(6), 823–832.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.bushor.2018.07.001" data-track-item_id="10.1016/j.bushor.2018.07.001" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.bushor.2018.07.001" aria-label="Article reference 83" data-doi="10.1016/j.bushor.2018.07.001">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 83" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20rising%20tide%20of%20artificial%20intelligence%20and%20business%20automation%3A%20Developing%20an%20ethical%20framework&amp;journal=Business%20Horizons&amp;doi=10.1016%2Fj.bushor.2018.07.001&amp;volume=61&amp;issue=6&amp;pages=823-832&amp;publication_year=2018&amp;author=Wright%2CSA&amp;author=Schultz%2CAE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR78">Zhou, L., Paul, S., Demirkan, H., Yuan, L., Spohrer, J., Zhou, M., &amp; Basu, J. (2021). Intelligence augmentation: Towards building human-machine symbiotic relationship. <i>AIS Transactions on Human-Computer Interaction,</i> <i>13</i>(2), 243–264.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.17705/1thci.00149" data-track-item_id="10.17705/1thci.00149" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.17705%2F1thci.00149" aria-label="Article reference 84" data-doi="10.17705/1thci.00149">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 84" href="http://scholar.google.com/scholar_lookup?&amp;title=Intelligence%20augmentation&amp;journal=AIS%20Transactions%20on%20Human-Computer%20Interaction%3A%20Towards%20building%20human-machine%20symbiotic%20relationship&amp;doi=10.17705%2F1thci.00149&amp;volume=13&amp;issue=2&amp;pages=243-264&amp;publication_year=2021&amp;author=Zhou%2CL&amp;author=Paul%2CS&amp;author=Demirkan%2CH&amp;author=Yuan%2CL&amp;author=Spohrer%2CJ&amp;author=Zhou%2CM&amp;author=Basu%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR79">Zuboff, S. (1988). <i>In the age of the smart machine: The future of work and power</i>. Basic Books: New York.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 85" href="http://scholar.google.com/scholar_lookup?&amp;title=In%20the%20age%20of%20the%20smart%20machine%3A%20The%20future%20of%20work%20and%20power&amp;publication_year=1988&amp;author=Zuboff%2CS">
                    Google Scholar</a> 
                </p></li></ul><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/s10551-023-05339-7?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors would like to sincerely thank the Special Issue Guest Editors, their Action Editor Associate Professor Luke Fletcher, and the anonymous reviewers for their insightful and constructive feedback during the review process.</p></div></div></section><section data-title="Funding"><div class="c-article-section" id="Fun-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Fun">Funding</h2><div class="c-article-section__content" id="Fun-content"><p>Open Access funding enabled and organized by CAUL and its Member Institutions.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Management, Macquarie Business School, Macquarie University, North Ryde Campus, Sydney, NSW, 2109, Australia</p><p class="c-article-author-affiliation__authors-list">Sarah Bankins</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Philosophy, Faculty of Arts, Macquarie University, North Ryde Campus, Sydney, NSW, 2109, Australia</p><p class="c-article-author-affiliation__authors-list">Paul Formosa</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Sarah-Bankins-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Sarah Bankins</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Sarah%20Bankins" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Sarah%20Bankins" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Sarah%20Bankins%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Paul-Formosa-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Paul Formosa</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Paul%20Formosa" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Paul%20Formosa" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Paul%20Formosa%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" aria-label="email Sarah Bankins" href="mailto:sarah.bankins@mq.edu.au">Sarah Bankins</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
              
                <h3 class="c-article__sub-heading" id="FPar1">Conflict of interest</h3>
                <p>The authors have no conflicts of interest to declare that are relevant to the content of this article.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Publisher's Note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20Ethical%20Implications%20of%20Artificial%20Intelligence%20%28AI%29%20For%20Meaningful%20Work&amp;author=Sarah%20Bankins%20et%20al&amp;contentID=10.1007%2Fs10551-023-05339-7&amp;copyright=The%20Author%28s%29&amp;publication=0167-4544&amp;publicationDate=2023-02-11&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10551-023-05339-7" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10551-023-05339-7" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Bankins, S., Formosa, P. The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work.
                    <i>J Bus Ethics</i> <b>185</b>, 725–740 (2023). https://doi.org/10.1007/s10551-023-05339-7</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/s10551-023-05339-7?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-02-17">17 February 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2023-01-25">25 January 2023</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2023-02-11">11 February 2023</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2023-07">July 2023</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1007/s10551-023-05339-7</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy shareable link to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span><a href="/search?query=Meaningful%20work&amp;facet-discipline=&#34;Philosophy&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Meaningful work</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Artificial%20intelligence%20%28AI%29&amp;facet-discipline=&#34;Philosophy&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Artificial intelligence (AI)</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Ethical%20AI&amp;facet-discipline=&#34;Philosophy&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Ethical AI</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Future%20of%20work&amp;facet-discipline=&#34;Philosophy&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Future of work</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Technology%20and%20work&amp;facet-discipline=&#34;Philosophy&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Technology and work</a></span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>

                    
    <div id="researcher-profile-container">
        <h3>Profiles</h3>
        <ol>
            
                <li data-test="researcher-profile-data"  data-profile-index="1">
                    <span data-test="researcher-profile-name">Paul Formosa</span>
                    <a class="js-cta-popup-link c-article-authors-search__cta-link" href="/researchers/21930341SN" data-track="click_view_profile" data-test="researcher-profile-link">
                        <span class="eds-c-button eds-c-button--primary">
                            <svg class="c-article-authors-search__cta-icon" aria-hidden="true" focusable="false" width="24" height="24">
                                <use xlink:href="#icon-eds-i-user-single-medium"></use>
                            </svg><span>View author profile</span>
                        </span>
                    </a>
                </li>
            
        </ol>
    </div>


                    
                </div>
            </main>

            <div class="c-article-sidebar u-text-sm u-hide-print l-with-sidebar__sidebar" id="sidebar"
                 data-container-type="reading-companion" data-track-component="reading companion">
                <aside aria-label="reading companion">
                    

                    
                        
    <div class="app-card-service" data-test="article-checklist-banner">
        <div>
            <a class="app-card-service__link" data-track="click_presubmission_checklist" data-track-context="article page top of reading companion" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=10551"
            data-test="article-checklist-banner-link">
            <span class="app-card-service__link-text">Use our pre-submission checklist</span>
            <svg class="app-card-service__link-icon" aria-hidden="true" focusable="false"><use xlink:href="#icon-eds-i-arrow-right-small"></use></svg>
            </a>
            <p class="app-card-service__description">Avoid common mistakes on your manuscript.</p>
        </div>
        <div class="app-card-service__icon-container">
            <svg class="app-card-service__icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-clipboard-check-medium"></use>
            </svg>
        </div>
    </div>

                    

                    
                        <div data-test="collections">
                            
    
        <div class="c-article-associated-content__container">
            <h2 class="c-article-associated-content__title u-h3 u-mb-24 u-visually-hidden">Associated Content</h2>
            
                <div class="c-article-associated-content__collection collection u-mb-24">
                    
                    <p class="c-article-associated-content__collection-label u-sans-serif u-text-bold u-mb-8">Part of a collection:</p>
                    
                    <h3 class="c-article-associated-content__collection-title u-mt-0 u-h3 u-mb-8" itemprop="name headline">
                        <a href="/collections/fdaaibeagd"
                           data-track="click" data-track-action="view collection" data-track-label="link"><b>Special Issue - Ethics and the Future of Meaningful Work</b></a>
                    </h3>
                </div>
            
        </div>

        <script>
        window.dataLayer = window.dataLayer || [];
        window.dataLayer[0] = window.dataLayer[0] || {};
        window.dataLayer[0].content = window.dataLayer[0].content || {};
        window.dataLayer[0].content.collections = 'fdaaibeagd';
        </script>
    

                        </div>
                    

                    <div data-test="editorial-summary">
                        
                    </div>

                    <div class="c-reading-companion">
                        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky"
                             data-test="reading-companion-sticky">
                            
                            
                                
                                    
                                
                            
                            <div
                                class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active"
                                id="tabpanel-sections">
                                <div class="u-lazy-ad-wrapper u-mt-16 u-hide"
                                     data-component-mpu><div class="c-ad c-ad--300x250">
    <div class="c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-MPU1"
             class="div-gpt-ad grade-c-hide"
             data-pa11y-ignore
             data-gpt
             data-gpt-unitpath="/270604982/springerlink/10551/article"
             data-gpt-sizes="300x250" data-test="MPU1-ad"
             data-gpt-targeting="pos=MPU1;articleid=s10551-023-05339-7;">
        </div>
    </div>
</div>

<script>
    window.SN = window.SN || {};
    window.SN.libs = window.SN.libs || {};
    window.SN.libs.ads = window.SN.libs.ads || {};
    window.SN.libs.ads.slotConfig = window.SN.libs.ads.slotConfig || {};
    window.SN.libs.ads.slotConfig['MPU1'] = {
        'pos': 'MPU1',
        'type': 'MPU1',
    };
    window.SN.libs.ads.slotConfig['unitPath'] = '/270604982/springerlink/10551/article';
</script>

</div>
                            </div>
                            <div
                                class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width"
                                id="tabpanel-figures"></div>
                            <div
                                class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width"
                                id="tabpanel-references"></div>
                        </div>
                    </div>
                </aside>
            </div>
        </div>
    </article>
    <div class="app-elements" data-test="footer">
    <nav aria-label="expander navigation">



    
        <div class="eds-c-header__expander eds-c-header__expander--search" id="eds-c-header-popup-search">
            <h2 class="eds-c-header__heading">Search</h2>
            <div class="u-container">
                <search class="eds-c-header__search" role="search" aria-label="Search from the header">
                    <form method="GET" action="//link.springer.com/search"
                        
                            data-test="header-search"
                        
                            data-track="search"
                        
                            data-track-context="search from header"
                        
                            data-track-action="submit search form"
                        
                            data-track-category="unified header"
                        
                            data-track-label="form"
                        
					>
                        <label for="eds-c-header-search" class="eds-c-header__search-label">Search by keyword or author</label>
                        <div class="eds-c-header__search-container">
                            <input id="eds-c-header-search" class="eds-c-header__search-input" autocomplete="off" name="query" type="search" value="" required>
                            <button class="eds-c-header__search-button" type="submit">
                                <svg class="eds-c-header__icon" aria-hidden="true" focusable="false">
                                    <use xlink:href="#icon-eds-i-search-medium"></use>
                                </svg>
                                <span class="u-visually-hidden">Search</span>
                            </button>
                        </div>
                    </form>
                </search>
            </div>
        </div>
    


<div class="eds-c-header__expander eds-c-header__expander--menu" id="eds-c-header-nav">
    
        <h2 class="eds-c-header__heading">Navigation</h2>
        <ul class="eds-c-header__list">
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://link.springer.com/journals/"
                        
                            data-track="nav_find_a_journal"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click find a journal"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Find a journal
                    </a>
                </li>
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://www.springernature.com/gp/authors"
                        
                            data-track="nav_how_to_publish"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click publish with us link"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Publish with us
                    </a>
                </li>
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://link.springernature.com/home/"
                        
                            data-track="nav_track_your_research"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click track your research"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Track your research
                    </a>
                </li>
            
        </ul>
    
</div>
</nav>
    <footer >
	<div class="eds-c-footer"
		
	>
		
			
				<div class="eds-c-footer__container">
		<div class="eds-c-footer__grid eds-c-footer__group--separator">
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Discover content</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/journals/a/1" data-track="nav_journals_a_z" data-track-action="journals a-z" data-track-context="unified footer" data-track-label="link">Journals A-Z</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/books/a/1" data-track="nav_books_a_z" data-track-action="books a-z" data-track-context="unified footer" data-track-label="link">Books A-Z</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Publish with us</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/journals" data-track="nav_journal_finder" data-track-action="journal finder" data-track-context="unified footer" data-track-label="link">Journal finder</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/authors" data-track="nav_publish_your_research" data-track-action="publish your research" data-track-context="unified footer" data-track-label="link">Publish your research</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://authorservices.springernature.com/go/sn/?utm_source&#x3D;SNLinkfooter&amp;utm_medium&#x3D;Web&amp;utm_campaign&#x3D;SNReferral" data-track="nav_language_editing" data-track-action="language editing" data-track-context="unified footer" data-track-label="link">Language editing</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research" data-track="nav_open_access_publishing" data-track-action="open access publishing" data-track-context="unified footer" data-track-label="link">Open access publishing</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Products and services</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/products" data-track="nav_our_products" data-track-action="our products" data-track-context="unified footer" data-track-label="link">Our products</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/librarians" data-track="nav_librarians" data-track-action="librarians" data-track-context="unified footer" data-track-label="link">Librarians</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/societies" data-track="nav_societies" data-track-action="societies" data-track-context="unified footer" data-track-label="link">Societies</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/partners" data-track="nav_partners_and_advertisers" data-track-action="partners and advertisers" data-track-context="unified footer" data-track-label="link">Partners and advertisers</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Our brands</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springer.com/" data-track="nav_imprint_Springer" data-track-action="Springer" data-track-context="unified footer" data-track-label="link">Springer</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.nature.com/" data-track="nav_imprint_Nature_Portfolio" data-track-action="Nature Portfolio" data-track-context="unified footer" data-track-label="link">Nature Portfolio</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/brands/bmc" data-track="nav_imprint_BMC" data-track-action="BMC" data-track-context="unified footer" data-track-label="link">BMC</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.palgrave.com/" data-track="nav_imprint_Palgrave_Macmillan" data-track-action="Palgrave Macmillan" data-track-context="unified footer" data-track-label="link">Palgrave Macmillan</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.apress.com/" data-track="nav_imprint_Apress" data-track-action="Apress" data-track-context="unified footer" data-track-label="link">Apress</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/brands/discover" data-track="nav_imprint_Discover" data-track-action="Discover" data-track-context="unified footer" data-track-label="link">Discover</a></li>
					
				</ul>
			</div>
			
		</div>
	</div>

		
		
		<div class="eds-c-footer__container">
	
		<nav aria-label="footer navigation">
			<ul class="eds-c-footer__links">
				
					<li class="eds-c-footer__item">
						
						
							<button class="eds-c-footer__link" data-cc-action="preferences"
								 data-track="dialog_manage_cookies" data-track-action="Manage cookies" data-track-context="unified footer" data-track-label="link"><span class="eds-c-footer__button-text">Your privacy choices/Manage cookies</span></button>
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://www.springernature.com/gp/legal/ccpa"
								 data-track="nav_california_privacy_statement" data-track-action="california privacy statement" data-track-context="unified footer" data-track-label="link">Your US state privacy rights</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/accessibility"
								 data-track="nav_accessibility_statement" data-track-action="accessibility statement" data-track-context="unified footer" data-track-label="link">Accessibility statement</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/termsandconditions"
								 data-track="nav_terms_and_conditions" data-track-action="terms and conditions" data-track-context="unified footer" data-track-label="link">Terms and conditions</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/privacystatement"
								 data-track="nav_privacy_policy" data-track-action="privacy policy" data-track-context="unified footer" data-track-label="link">Privacy policy</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://support.springernature.com/en/support/home"
								 data-track="nav_help_and_support" data-track-action="help and support" data-track-context="unified footer" data-track-label="link">Help and support</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/legal-notice"
								 data-track="nav_legal_notice" data-track-action="legal notice" data-track-context="unified footer" data-track-label="link">Legal notice</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://support.springernature.com/en/support/solutions/articles/6000255911-subscription-cancellations"
								 data-track-action="cancel contracts here">Cancel contracts here</a>
						
						
					</li>
				
			</ul>
		</nav>
	
	
		
			<div class="eds-c-footer__user">
				<p class="eds-c-footer__user-info">
					
					<span data-test="footer-user-ip">143.58.199.91</span>
				</p>
				<p class="eds-c-footer__user-info" data-test="footer-business-partners">Not affiliated</p>
			</div>
		
	
	
		<a href="https://www.springernature.com/" class="eds-c-footer__link">
			<img src="/oscar-static/images/logo-springernature-white-19dd4ba190.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
		</a>
	
	<p class="eds-c-footer__legal" data-test="copyright">&copy; 2025 Springer Nature</p>
</div>

	</div>
</footer>
</div>


    </body>
</html>


