<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond</title>
<!--Generated on Sat Aug 16 07:33:46 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.8.2.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.8.2.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.0.8.2.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2508.11957v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S1" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S2" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S2.SS1" title="In 2 Related Work ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Past Reviews on AI Agents</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S3" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S3.SS1" title="In 3 Methodology ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Search Strategy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S3.SS2" title="In 3 Methodology ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Exclusion Criteria</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S3.SS3" title="In 3 Methodology ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Data Extraction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS1" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Architectures and Learning Paradigms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS2" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Core Components of Modern AI Agent Architectures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS3" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Planning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS4" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Memory</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS5" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Tools</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS6" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>Perception Modules</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS7" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7 </span>Representation and Abstraction Layers</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS8" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.8 </span>Planning and Reasoning Engines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.SS9" title="In 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.9 </span>Interaction and Communication Interfaces</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Applications of AI Agents</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS1" title="In 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Healthcare</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS1.SSS1" title="In 5.1 Healthcare ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Diagnostic and Decision-Support Agents</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS1.SSS2" title="In 5.1 Healthcare ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Patient-Facing Virtual Assistants and Chatbots</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS1.SSS3" title="In 5.1 Healthcare ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>Robotic and Surgical AI Agents</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS2" title="In 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Business and Industry</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS2.SSS1" title="In 5.2 Business and Industry ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Customer Service and Engagement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS2.SSS2" title="In 5.2 Business and Industry ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Supply Chain Optimization and Operation Management</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS2.SSS3" title="In 5.2 Business and Industry ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.3 </span>Financial Decision-Making and Risk Management</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS3" title="In 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Education</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS3.SSS1" title="In 5.3 Education ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.1 </span>Student engagement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS3.SSS2" title="In 5.3 Education ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.2 </span>Educator workload</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS4" title="In 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Science and Research</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS4.SSS1" title="In 5.4 Science and Research ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.1 </span>Automated Laboratories in Biology and Chemistry</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS4.SSS2" title="In 5.4 Science and Research ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.2 </span>AI Researchers</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS5" title="In 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Public Services and Urban Planning</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS5.SSS1" title="In 5.5 Public Services and Urban Planning ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.1 </span>Land Use and Urban Resource Management</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS5.SSS2" title="In 5.5 Public Services and Urban Planning ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.2 </span>Collaborative Decision-making AI Agents in Public Administration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS5.SSS3" title="In 5.5 Public Services and Urban Planning ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.3 </span>Transport routing optimization AI agents</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS6" title="In 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6 </span>Entertainment and Creativity</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS6.SSS1" title="In 5.6 Entertainment and Creativity ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6.1 </span>Visual Design and Storytelling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS6.SSS2" title="In 5.6 Entertainment and Creativity ‣ 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6.2 </span>Video games</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S5.SS7" title="In 5 Applications of AI Agents ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.7 </span>Societal Impact and Considerations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S6" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>AI Agent Design</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S6.SS1" title="In 6 AI Agent Design ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Cognitive-Inspired Architectures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S6.SS2" title="In 6 AI Agent Design ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Hierarchical and Modular Approaches</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS1" title="In 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Discussion and a Step-by-Step Guide</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS2" title="In 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Challenges and Limitations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS2.SSS1" title="In 7.2 Challenges and Limitations ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.1 </span>Safety and Robustness</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS2.SSS2" title="In 7.2 Challenges and Limitations ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.2 </span>Explainability and Interpretability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS2.SSS3" title="In 7.2 Challenges and Limitations ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.3 </span>Ethical and Social Considerations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS2.SSS4" title="In 7.2 Challenges and Limitations ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.4 </span>Generalization and Transfer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS2.SSS5" title="In 7.2 Challenges and Limitations ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.5 </span>Scalability and Resource Efficiency</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS3" title="In 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Future Directions and Emerging Opportunities</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS3.SSS1" title="In 7.3 Future Directions and Emerging Opportunities ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.1 </span>Neuroscience-Inspired Mechanisms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS3.SSS2" title="In 7.3 Future Directions and Emerging Opportunities ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.2 </span>Interactive and Continual Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS3.SSS3" title="In 7.3 Future Directions and Emerging Opportunities ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.3 </span>Hybrid Symbolic-Subsymbolic Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S7.SS3.SSS4" title="In 7.3 Future Directions and Emerging Opportunities ‣ 7 Discussion ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.4 </span>Multi-Agent Governance and Coordination</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S8" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#A1" title="In A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaodong Qu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andrews Damoah
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Maryland, College Park
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joshua Sherwood
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Peiyan Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Christian Shun Jin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Independent Researcher
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lulu Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Minjie Shen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nawwaf Aleisa
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zeyuan Hou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chenyu Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lifu Gao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yanshu Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Brown University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qikai Yang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Illinois Urbana-Champaign
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qun Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">San Francisco State University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cristabelle De Souza
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Stanford University
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Artificial Intelligence (AI) agents have rapidly evolved from specialized, rule-based programs to versatile, learning-driven autonomous systems capable of perception, reasoning, and action in complex environments. The explosion of data, advances in deep learning, reinforcement learning, and multi-agent coordination have accelerated this transformation. Yet, designing and deploying unified AI agents that seamlessly integrate cognition, planning, and interaction remains a grand challenge. In this review, we systematically examine the architectural principles, foundational components, and emergent paradigms that define the landscape of contemporary AI agents. We synthesize insights from cognitive science-inspired models, hierarchical reinforcement learning frameworks, and large language model-based reasoning. Moreover, we discuss the pressing ethical, safety, and interpretability concerns associated with deploying these agents in real-world scenarios. By highlighting major breakthroughs, persistent challenges, and promising research directions, this review aims to guide the next generation of AI agent systems toward more robust, adaptable, and trustworthy autonomous intelligence.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p">The development of artificial intelligence (AI) agents—autonomous systems capable of perceiving their surroundings, reasoning about possible courses of action, and executing decisions—has evolved significantly in recent decades. Early AI agents, rooted in the symbolic reasoning systems of the 1950s and 1960s, relied on hand-crafted rules and logic-based methods, excelling in constrained domains but struggling with adaptability and uncertainty<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib2" title="">2</a>]</cite>. The introduction of statistical learning and probabilistic reasoning in the 1980s and 1990s enhanced reliability, while the rise of reinforcement learning (RL) allowed agents to learn policies through trial-and-error interactions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib6" title="">6</a>]</cite>. The integration of deep neural networks with RL (DeepRL) led to breakthroughs such as superhuman performance in Atari games and Go <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib8" title="">8</a>]</cite>. With growing computational power, recent advancements in statistical methods and machine learning, AI agents have incorporated advanced perception, natural language sequence modeling, and cognitive-inspired principles, enabling them to adapt, collaborate, and mirror aspects of human reasoning in dynamic environments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib14" title="">14</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p">Contemporary AI agents are increasingly deployed in high-stakes, real-world contexts: self-driving cars navigating congested urban environments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib16" title="">16</a>]</cite>, autonomous laboratories accelerating scientific discovery <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib18" title="">18</a>]</cite>, virtual assistants managing complex user queries <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib19" title="">19</a>]</cite>, and automated trading agents operating in financial markets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib20" title="">20</a>]</cite>. Underpinning these successes are developments in deep learning for perception <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib2" title="">2</a>]</cite>, reinforcement learning (RL) for decision-making <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib22" title="">22</a>]</cite>, large language models (LLMs) for communication and reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib12" title="">12</a>]</cite>, and multi-agent frameworks that orchestrate coordination and competition among numerous entities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib23" title="">23</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p">However, forging truly unified AI agents presents an array of open problems. Such agents must integrate perception, abstract reasoning, hierarchical planning, and flexible communication while ensuring safety, interpretability, and adherence to ethical standards. In this systematic review, we synthesize a broad literature on AI agents, examining foundational methods, current paradigms, and emerging architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib24" title="">24</a>]</cite>. We highlight key breakthroughs from cognitive-inspired models to LLM-driven reasoning engines, from hierarchical RL to multimodal sensor fusion, and from single-agent solutions to scalable multi-agent frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib25" title="">25</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p">We also identify critical gaps and challenges. Robustness under domain shift, explainability of complex decision-making, and value alignment with human norms remain unsolved. Achieving human-level adaptability, transparency, resource efficiency, and trustworthy autonomy calls for deeper interdisciplinary research, from cognitive science to ethics, neuroscience, and economics.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p">With the recent popularity of AI agents in both research and industry, alongside rapid advancements within this domain, we have begun to see an emergence of literature reviews attempting to consolidate and analyze the history and progress made within this evolving field.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Past Reviews on AI Agents</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p">The review by Wang et al. takes a holistic approach when discussing the evolution of LLM-based agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib26" title="">26</a>]</cite>. The authors focus on analyzing three main aspects including the foundations of AI agent construction, applications within various fields, and common evaluation strategies for benchmarking performance. They cover many of the core components and technology fueling AI agents, proposing a unified framework encompassing early development strategies, as well as the diverse applications of these agents in fields such as social science, natural science, and engineering. They also look at various strategies for evaluating AI agent performance, ranging from subjective evaluation, such as human annotations and Turing tests, to more objective metrics such as success rate and accuracy. Their review provides a comprehensive look into the development of AI agents and their domain applications within the current day.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p">The paper by Guo et al. conducts a similar review, focusing more on multi-agent systems, specifically for simulation research  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib27" title="">27</a>]</cite>. The study takes an in-depth look at the fundamental aspects of multi-agent systems, common domains that utilize multi-agent systems for simulations, and the challenges within this field. The authors compare differences in functionality between single-agent and multi-agent systems, specifically in the context of profiling, communications, and decision-making. They highlight the two main applications of multi-agent systems: problem-solving, which leverages collaboration to address complex tasks, and world simulation, where agents are used to replicate social environments to reproduce real-world interactions. The authors also address many of the common challenges within the field such as hallucinations, scaling, and lack of multi-modal support <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib28" title="">28</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p">The study conducted by Xi et al. investigates the role LLMs play as foundational models for AI agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib29" title="">29</a>]</cite>. Through this lens, the authors detail the origins of LLM-based agents, applications in agent-to-agent (both human and artificial) interactions, and open questions in the field. They highlight key properties that validate LLMs as suitable foundations for agentic systems, such as autonomy and adaptability. They also highlight the importance of natural language processing, a key aspect of LLMs, in an agent’s ability to reason and communicate. The authors discuss the deployment of AI agents in various scenarios including single-agent, multi-agent, and human-agent settings, as well as practical applications of each. They extend this methodology to agentic societies, where multiple agents interact to create an artificial society. This framework builds upon individual agent behaviors and environments to construct fully realistic, artificial societies.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p">The work detailed in the paper by Xie et al. focuses on a review of LLM-based agents specifically in the multimodal domain <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib30" title="">30</a>]</cite>. They highlight the impact and challenges of multimodality on design frameworks, evaluation methods, and applications. The authors discuss how the core components of an AI agent, such as the planning and memory modules, require integration of textual, image, and audio capabilities into their architectures in multimodal settings. They also discuss the need for robust evaluation methods, especially for multimodal agents, that are capable of assessing the agent’s capabilities across multiple domains and how they interact to allow for complex reasons and problem-solving. The authors also discuss the extensive and diverse applications of multimodal agents in fields like autonomous driving, game development, and robotics. They emphasize the importance of multimodality in driving human-computer interaction between humans and autonomous agents by enabling their use in more complex, nuanced settings.</p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p">As a collective, past reviews on AI agents develop a comprehensive assessment of the technology and provide an in-depth analysis of foundational elements, diverse applications, current evaluation paradigms, and future
prospects of autonomous agents. Although many of these studies are suitable for people with prior knowledge in the field, few provide a simplified framework to understand these concepts, specifically targeting new researchers.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p">We conducted a systematic literature review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines to ensure a thorough and transparent approach. This method helped identify, screen, and select relevant studies focused on AI agents.
<br class="ltx_break"/></p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="381" id="S3.F1.g1" src="diagrams/PRISMA.png" width="393"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The PRISMA review was conducted independently by authors on each topic relating to core components, applications, and paradigm-shifting designs within the AI agent space, and combined into one diagram.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Search Strategy</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p">Following the PRISMA guidelines, we conducted our literature review process to identify relevant papers on foundational frameworks, current trends, and breakthrough advancements in AI agent research. Employing this strategy allowed us to conduct a rigorous analysis of relevant research, aligning with methodologies utilized in previous works. We used Google Scholar to conduct our review of emergent technologies in the AI agent space and 4 application domains: business, education, science, and entertainment. All queries were conducted using search terms related to AI agents and the individual topics. Common search terms included: ”Autonomous Agent”, ”Reinforcement Learning Agent”, and ”Multi-Agent System”, with ”AI Agent” being the prime term used across all contributors’ searches. The full list of queries by topic can be found in Appendix A.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p">The review process included three stages:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Google Scholar Search</span>: The records resulting from the query were examined by page, and full pages were included in order of relevancy (by Google Scholar’s algorithm) until no results on the given page were relevant, based on titles.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Initial Screening</span>: Titles and abstracts were reviewed to exclude irrelevant papers.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Full-Text Review</span>: Full papers were reviewed to exclude irrelevant papers.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Exclusion Criteria</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p">To ensure the relevance and accessibility of our selected studies, we applied a rigorous set of exclusion criteria. One of the primary considerations was the availability of the full text. Studies that were only accessible as abstracts, summaries, or paywalled content without institutional or open-access availability were excluded. This step was necessary to ensure that all reviewed studies could be thoroughly analyzed, preventing misinterpretations or incomplete evaluations based on limited information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib31" title="">31</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p">Additionally, we filtered out publications that were not directly focused on AI agents or fell outside the intended scope of our review. Given the broad application of artificial intelligence across various domains, many papers may reference AI agents tangentially without providing substantial insights into their architectures, methodologies, or applications. To maintain a focused and cohesive analysis, we prioritized studies that directly contributed to AI agent research, whether in foundational theory, implementation strategies, or domain-specific applications.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p">Language accessibility was another key factor in our selection process. Since our review was conducted in English, we excluded papers published in other languages due to the potential for misinterpretation and difficulty in verifying content accuracy. While we acknowledge that valuable research exists in multiple languages, our methodology required consistency in analysis and comprehension, which was best achieved by limiting our review to English-language publications.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p">By implementing these exclusion criteria, we refined our dataset to ensure a high-quality and relevant selection of literature. Each filtered study contributed meaningfully to our analysis, helping to create a structured and comprehensive review of AI agents while avoiding redundancy and extraneous content <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib32" title="">32</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Data Extraction</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p">To systematically analyze the selected studies, we conducted a structured data extraction process, ensuring that each paper contributed valuable insights into AI agent research. The primary focus of this extraction was identifying the core methodologies used in AI agent development. This included examining the underlying frameworks and architectures employed in various studies, as well as the algorithms and techniques utilized for reasoning, decision-making, and adaptation. Understanding these methodological foundations allowed us to categorize and compare different approaches in AI agent design.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p">In addition to methodologies, we documented each study’s key findings and contributions to the field. This involved assessing the significance of their results, novel approaches, and the broader implications for AI agent research. Whether a study introduced a new decision-making framework, improved reinforcement learning strategies, or proposed a novel integration of multi-agent coordination, we aimed to capture its unique contribution to advancing AI intelligence and autonomy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib33" title="">33</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p">Furthermore, we evaluated the relevance of each study to the progression of AI agent research. Studies that addressed pressing challenges, introduced paradigm-shifting ideas, or explored new application areas were given particular attention. By focusing on research that actively pushed the boundaries of AI agent capabilities, we ensured that our review highlighted the most impactful and forward-thinking work in the field.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Architectures and Learning Paradigms</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p">Modern AI agent architectures integrate diverse components, from memory systems to decision-making frameworks. For instance, <span class="ltx_text ltx_font_italic">Lilian Weng’s blog</span> provides a detailed exploration of agent architectures, emphasizing the interplay between memory, planning, and tool use. The <span class="ltx_text ltx_font_italic">Stanford HAI overview</span> highlights how computational agents are beginning to exhibit human-like behaviors, underscoring their potential for real-world applications. These studies collectively illustrate the shift toward more holistic and adaptive agent designs.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Core Components of Modern AI Agent Architectures</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p">AI agent architectures include components designed to enable perception, reasoning, decision-making, and interaction. Our review provides a deep dive of these core components, highlighting key breakthroughs and future opportunities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p">The system contains four major components - memory, tools, actions and planning. Memory is divided into short-term and long-term memories, offering both contextual and enduring information. The Agent is also capable of employing a wide range of tools, such as calendars, calculators, code interpreters, and search functions to execute specialized tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib35" title="">35</a>]</cite>. Planning encompasses sophisticated techniques such as reflection, self-evaluation, chain of thought reasoning, and sub-goal breakdown, enabling the Agent to enhance its decision-making and tackle intricate challenges effectively.
(see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#S4.F2" title="Figure 2 ‣ 4.2 Core Components of Modern AI Agent Architectures ‣ 4 Results ‣ A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond"><span class="ltx_text ltx_ref_tag">2</span></a>):</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="234" id="S4.F2.g1" src="diagrams/agent-overview.png" width="589"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of an AI Agent’s core components  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib36" title="">36</a>]</cite></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Planning</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p">Inspired by classical AI planning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib4" title="">4</a>]</cite>, modern agents integrate symbolic and subsymbolic methods to reason about future states, causal dependencies, and long-term goals. Hierarchical RL structures decision-making at multiple levels of abstraction, improving sample efficiency and interpretability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib38" title="">38</a>]</cite>. Additionally, model-based RL, graph-based planning, and hybrid neural-symbolic reasoning approaches allow agents to perform sophisticated problem-solving.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p">Chain-of-thought  .<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib39" title="">39</a>]</cite> is a milestone technique to significantly improve the ability of large language models (LLMs) to perform complex reasoning tasks. The framework provides the models with examples of step-by-step reasoning (a ”chain of thought”) in the prompt, guiding them to break down complex problems into intermediate steps before arriving at the final answer. This helps the model perform better on tasks requiring multi-step reasoning.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p">Agents must adapt policies over time. Reinforcement learning algorithms, from value-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib21" title="">21</a>]</cite> to policy gradient techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib41" title="">41</a>]</cite>, enable agents to learn through interaction.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p">Reflexion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib42" title="">42</a>]</cite> is a framework designed to enhance AI Agents through reinforcement learning. It has a self-reflection architecture that leverages the heuristic function and linguistic feedback to improve reasoning skills. Reflexion represents a significant step forward in enabling LLM-based agents to learn from trial and error through verbal self-reflection. The framework’s ability to improve performance across diverse tasks without requiring extensive fine-tuning makes it a promising approach for future research in autonomous agents.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="305" id="S4.F3.g1" src="diagrams/reflexion_diagram.png" width="589"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An overview of the Reflexion framework  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib42" title="">42</a>]</cite></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p">Chain of Hindsight(CoH) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib43" title="">43</a>]</cite> is another framework that helps LLM agents improve their outputs by training with historical datasets that contain past sequential outputs with feedback. The framework aligns large language models with human feedback more effectively than traditional methods such as supervised fine-tuning (SFT) or reinforcement learning with human feedback (RLHF). The CoH algorithm trains the model to maximize the likelihood of predicting tokens in sequences <math alttext="x=[x_{1},x_{2},\ldots,x_{n}]" class="ltx_Math" display="inline" id="S4.SS3.p5.m1"><semantics><mrow><mi>x</mi><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">x=[x_{1},x_{2},\ldots,x_{n}]</annotation></semantics></math>, using a causal Transformer architecture:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="logp(x)=\sum_{i=1}^{n}\log p(x_{i}\mid x_{&lt;i})" class="ltx_Math" display="block" id="S4.Ex1.m1"><semantics><mrow><mrow><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>g</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.111em">=</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mi>p</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mi></mi><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">logp(x)=\sum_{i=1}^{n}\log p(x_{i}\mid x_{&lt;i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">The training sequence contains model outputs combined with feedback. To make sure the model will only be trained to predict non-feedback tokens, a masking technique is adopted such that:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="logp(x)=\sum_{i=1}^{n}\mathbb{1}_{O(x)}(x_{i})\log p(x_{i}\mid x_{&lt;i})" class="ltx_Math" display="block" id="S4.Ex2.m1"><semantics><mrow><mrow><mi>l</mi><mo lspace="0em" rspace="0em">​</mo><mi>o</mi><mo lspace="0em" rspace="0em">​</mo><mi>g</mi><mo lspace="0em" rspace="0em">​</mo><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.111em">=</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mn>𝟙</mn><mrow><mi>O</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mo lspace="0.167em" rspace="0em">​</mo><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mi>p</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mi></mi><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">logp(x)=\sum_{i=1}^{n}\mathbb{1}_{O(x)}(x_{i})\log p(x_{i}\mid x_{&lt;i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\mathbb{1}_{O(x)}(x_{i})" class="ltx_Math" display="inline" id="S4.SS3.p5.m2"><semantics><mrow><msub><mn>𝟙</mn><mrow><mi>O</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbb{1}_{O(x)}(x_{i})</annotation></semantics></math> is 1 if <math alttext="x_{i}" class="ltx_Math" display="inline" id="S4.SS3.p5.m3"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_{i}</annotation></semantics></math> is not part of the feedback and 0 otherwise. Comprehensive experiments on summarization and dialogue datasets demonstrate that CoH significantly surpasses RLHF and other baseline methods.</p>
</div>
<div class="ltx_para" id="S4.SS3.p6">
<p class="ltx_p">Meta-learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib44" title="">44</a>]</cite> and continual learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib45" title="">45</a>]</cite> approaches allow agents to generalize across tasks and accumulate knowledge without catastrophic forgetting.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Memory</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p">Memory processing in AI agents is crucial for enhancing their effectiveness. Much like human memory, it enables the acquisition, storage, retention, and retrieval of information for future use <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib36" title="">36</a>]</cite>. Memory is categorized into short-term or textual, constrained by the context window of the underlying transformer models, and long-term or parametric, encompassing declarative (facts and events) and procedural (unconscious skills) memory <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib46" title="">46</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="235" id="S4.F4.g1" src="diagrams/memory.png" width="589"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span> An overview of the sources, forms, and operations of the memory in LLM-based agents.  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib47" title="">47</a>]</cite></figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p">Memory-enhanced agents have demonstrated significant capabilities in maintaining context, emulating human-like behavior, and tackling complex tasks by effectively utilizing both short-term and long-term memory. However, despite these advancements, challenges remain in scalability, efficiency, and the seamless integration of external knowledge for LLM-based AI agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib48" title="">48</a>]</cite>. Addressing these limitations is crucial for advancing LLM-based agents toward artificial general intelligence (AGI), enhancing their robustness and efficiency in real-world applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib47" title="">47</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Tools</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p">One of the hallmarks of human intelligence is the ability to use tools that reflect advanced cognitive functions such as problem-solving, adaptability, and foresight. Equipping LLMs with external tools can significantly extend model capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib36" title="">36</a>]</cite>. In fact, LLM-based AI agents can be defined as systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they perform tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib50" title="">50</a>]</cite>. Tools are external modules that LLMs can call to gather information or perform actions. Examples include information retrieval systems, search engines, code interpreters, and robotic arms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib51" title="">51</a>]</cite>. The key challenges for tool-augmented LLMs, as highlighted in the paper, revolve around hallucinations, planning complexity, and input errors, which greatly impact their viability in practical settings. These challenges underscore the necessity for more rigorous adherence to API documentation, enhanced planning algorithms, and broader, more inclusive training datasets to improve the robustness and reliability of AI agents in practical, real-world applications involving tool use <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib53" title="">53</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Perception Modules</h3>
<div class="ltx_para" id="S4.SS6.p1">
<p class="ltx_p">Perception converts raw sensory data (e.g., images, audio, text, LiDAR scans) into structured representations. Vision backbones rely on convolutional neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib11" title="">11</a>]</cite> and vision transformers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib2" title="">2</a>]</cite>, while speech recognition and language processing leverage transformer-based LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib12" title="">12</a>]</cite>. Sensor fusion merges multiple modalities to form a holistic, environmental understanding.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>Representation and Abstraction Layers</h3>
<div class="ltx_para" id="S4.SS7.p1">
<p class="ltx_p">Agents require compact, meaningful representations. Self-supervised and contrastive learning approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib56" title="">56</a>]</cite> extract latent features from high-dimensional data. LLMs construct rich language embeddings that capture semantic and syntactic nuances, enabling agents to interpret instructions, query knowledge, and generate natural language outputs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib57" title="">57</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.8 </span>Planning and Reasoning Engines</h3>
<div class="ltx_para" id="S4.SS8.p1">
<p class="ltx_p">Inspired by classical AI planning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib58" title="">58</a>]</cite>, modern agents integrate symbolic and subsymbolic methods to reason about future states, causal dependencies, and long-term goals. Hierarchical RL structures decision-making at multiple levels of abstraction, improving sample efficiency and interpretability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib38" title="">38</a>]</cite>. Additionally, model-based RL, graph-based planning, and hybrid neural-symbolic reasoning approaches allow agents to perform sophisticated problem-solving.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.9 </span>Interaction and Communication Interfaces</h3>
<div class="ltx_para" id="S4.SS9.p1">
<p class="ltx_p">For agents to collaborate effectively, they must communicate. Natural language interfaces <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib12" title="">12</a>]</cite>, emergent communication protocols in MAS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib59" title="">59</a>]</cite>, grounded language acquisition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib60" title="">60</a>]</cite>, and embodiment enable richer, more flexible multi-agent interactions and human-agent cooperation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Applications of AI Agents</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p">AI agents have begun to influence a broad spectrum of real-world applications, serving as critical components in complex decision-making processes and enhancing human capabilities. They integrate advances in perception, reasoning, communication, and control to provide adaptive and context-sensitive solutions that were once out of reach for traditional software systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib62" title="">62</a>]</cite>.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Healthcare</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p">AI agents—digital systems capable of perceiving their environment, reasoning about what they perceive, and taking actions - have begun to make a remarkable impact in healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib63" title="">63</a>]</cite>. As medical practices face growing patient demands, clinician burnout, and data complexity, these agents promise to lighten workloads, improve care quality, and augment the clinical decision-making process. While the concept of AI in medicine has existed for decades, recent advancements in computational power, machine learning algorithms, and the availability of large, high-quality datasets have accelerated progress, transforming what was once science fiction into everyday reality.
The development of AI agents in healthcare did not happen overnight. The rise of machine learning—particularly deep learning—over the past decade has dramatically changed the landscape. With the proliferation of electronic health records (EHRs), medical imaging databases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib64" title="">64</a>]</cite>, and wearable sensors, healthcare organizations today have unprecedented access to vast and varied datasets. This data revolution, combined with cheaper and more powerful cloud computing services, has allowed modern AI agents to become more accurate, context-aware, and integrated into existing healthcare workflows <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib66" title="">66</a>]</cite>. By the late 2010s, AI agents began to show promise in detecting diseases from imaging scans, triaging patient queries, and even assisting in surgical interventions.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Diagnostic and Decision-Support Agents</h4>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p">Diagnostic and Decision-Support Agents
AI-driven clinical decision support systems (CDSS) harness large repositories of medical knowledge and patient data to guide clinicians <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib67" title="">67</a>]</cite>. For example, agents trained on vast numbers of radiology images can highlight suspicious regions in a chest X-ray or mammogram, alerting a physician to potential conditions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib68" title="">68</a>]</cite>. In dermatology, AI agents analyzing skin lesion images can help detect melanoma, while in ophthalmology, they can identify signs of diabetic retinopathy. These agents reduce the cognitive load on physicians, enhance diagnostic accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib69" title="">69</a>]</cite>, and potentially catch conditions earlier, leading to better patient outcomes.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Patient-Facing Virtual Assistants and Chatbots</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p">On the patient side, AI-based virtual assistants and chatbots are becoming increasingly common. These conversational agents help patients book appointments, remind them to take medication, provide educational information, and even guide them through symptom checking <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib70" title="">70</a>]</cite>. By offering round-the-clock support, such agents improve access to care and empower patients to take more control of their health. They are especially helpful in primary care settings, where they can quickly triage simple queries and refer complex questions to healthcare professionals.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Robotic and Surgical AI Agents</h4>
<div class="ltx_para" id="S5.SS1.SSS3.p1">
<p class="ltx_p">Autonomous surgical robots and AI-assisted robotic surgery tools help enhance the precision and dexterity of surgeons. While these technologies still rely on human oversight, AI agents can predict tissue responses, reduce tremors in tool manipulation, and adjust strategies mid-operation for the best possible outcomes. Outside the operating room, robots equipped with AI-powered navigation systems can assist in rehabilitation centers, aiding patients with mobility issues and helping clinicians monitor progress more efficiently <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib71" title="">71</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p2">
<p class="ltx_p">Artificial intelligencetificial intelligence agents are poised to become indispensable partners in healthcare, offering diagnostic support, patient education, and assistance with complex surgical procedures. While the road to fully realizing their potential is paved with challenges such as bias, data privacy, regulatory hurdles, and integration complexities, ongoing research and responsible innovation are making rapid progress <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib72" title="">72</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Business and Industry</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p">Enterprise applications of AI agents span customer service chatbots, supply chain optimization, and strategic decision support. Conversational agents handle routine inquiries, freeing human operators to address more complex tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib12" title="">12</a>]</cite>. AI-driven agents in operations management can forecast demand, manage inventory, and optimize logistics. Financial institutions employ agents for fraud detection, risk assessment, and algorithmic trading <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib20" title="">20</a>]</cite>, reducing costs, improving efficiency, and enhancing overall competitiveness.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Customer Service and Engagement</h4>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p">AI-powered conversational agents, such as chatbots and virtual assistants are streamlining the customer experience by handling routine inquiries, resolving issues and personalizing customers. These agents enable businesses to operate 24/7, providing instant responses and freeing human agents to focus on other complex or sensitive issues. For example, having companies use AI chatbots to guide users through product selection, technical issues and managing post-purchase support<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib73" title="">73</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p2">
<p class="ltx_p">In addition to traditional customer service roles, AI agents are now essential to marketing campaigns. They analyze customer behavior to create targeted advertisements and personalized content. By dynamically adapting to user preferences, these agents help businesses improve conversion rates and create long-term customer loyalty, overall; this empowers businesses to scale operations without compromising quality.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Supply Chain Optimization and Operation Management</h4>
<div class="ltx_para" id="S5.SS2.SSS2.p1">
<p class="ltx_p">AI agents are revolutionizing supply chain management by enabling efficient forecasting, inventory control, and logistics optimization. The complex and dynamic nature of modern supply chains make them an ideal application area for AI as these systems can process vast amounts of data to identify patterns, predict disruptions, and suggest corrective actions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib74" title="">74</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p2">
<p class="ltx_p">Predictive analytics allow businesses to forecast demand with significant accuracy. This capability helps to minimize overproduction and stockouts, leading to significant cost savings. For instance, multinational corporations like Amazon rely on AI agents to manage their inventory globally across warehouses, dynamically adjusting stock levels based on real-time sales. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib75" title="">75</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib76" title="">76</a>]</cite></p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p3">
<p class="ltx_p">When it comes to logistics, route optimization algorithms consider variables such as traffic, weather conditions and delivery deadline to find the most efficient paths for transportation. This not only reduces fuel consumption and delivery times but also contributes to sustainability goals. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib75" title="">75</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib76" title="">76</a>]</cite></p>
</div>
<div class="ltx_para" id="S5.SS2.SSS2.p4">
<p class="ltx_p">Warehouse automation further highlights the role of AI agents. With autonomous robots powered by machine learning and computer vision technologies while managing tasks like sorting, packing and inventory auditing. These innovations reduce human error, improve throughput and enhance overall operational efficiency, making AI agents indispensable in modern supply chain ecosystems. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib77" title="">77</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3 </span>Financial Decision-Making and Risk Management</h4>
<div class="ltx_para" id="S5.SS2.SSS3.p1">
<p class="ltx_p">The financial sector has embraced AI agents for their ability to analyze large datasets,identify trends and make decisions with precision and speed. AI applications in finance range from fraud detection, and credit scoring to algorithmic trading and portfolio management <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib78" title="">78</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS3.p2">
<p class="ltx_p">Fraud detection is a critical section for AI agents to excel. By analyzing patterns in transaction data, these systems can flag anomalies that might indicate fraudulent activity. For example, credit card companies use AI to detect unusual spending behavior in real time, notifying customers, and freezing accounts to prevent losses. These systems continuously learn and adapt, improving their ability to detect types of fraud as they emerge<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib79" title="">79</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib80" title="">80</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS3.p3">
<p class="ltx_p">In credit risk assessment, AI agents evaluate an applicant’s creditworthiness by analyzing traditional metrics alongside alternative data sources, such as social media activity and online behavior. This holistic approach provides lenders with deeper insights, enabling them to make more informed decisions while expanding access to credit for under banked populations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib81" title="">81</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS3.p4">
<p class="ltx_p">AI agents have transformed financial trading by enabling institutions to analyze complex datasets and execute trades with precision and speed. In algorithmic trading AI systems analyze market trends, price movements and macroeconomic indicators to make split-second trading decisions that would be impossible for a human to replicate <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib82" title="">82</a>]</cite>.
These agents optimize strategies by backtesting historical data, identifying profitable patterns and adapting to real-time market changes. For example, reinforcement learning models are increasingly used in trading algorithms to improve performance by learning from past successes and failures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib83" title="">83</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib84" title="">84</a>]</cite>. Such systems enhance profitability while reducing the impact of human bias and error.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS3.p5">
<p class="ltx_p">Risk management is another important area where AI agents are proving to irreplaceable. Advanced risk models powered by machine learning can assess and predict potential market risks by analyzing diverse datasets, including volatility indices, credit spreads, and geopolitical events<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib85" title="">85</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib86" title="">86</a>]</cite>. By identifying correlations and anomalies that humans might overlook, these systems enable traders and portfolio managers to mitigate exposure to adverse market conditions. Additionally, AI agents are used to simulate stress-testing scenarios, helping financial institutions to prepare for extreme market events<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib87" title="">87</a>]</cite>. This ability to provide actionable insights ensures that trading strategies remain robust and adaptive, even in highly uncertain environments.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Education</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p">Recent efforts to implement AI agents in education have targeted elementary <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib88" title="">88</a>]</cite>, middle <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib89" title="">89</a>]</cite>, and upper level <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib90" title="">90</a>]</cite> students. These efforts target diverse areas, including healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib90" title="">90</a>]</cite>, language learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib91" title="">91</a>]</cite>, and computer science <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib92" title="">92</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib93" title="">93</a>]</cite>. Across these domains, use cases can be grouped into 2 main categories: elevating student engagement and reducing instructor workload. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib91" title="">91</a>]</cite> identifies 3 potential strengths of AI agents in education: team teaching, personalized learning suggestions, and data-driven feedback. In their discussion of team teaching, they argue that human teachers should provide knowledge of pedagogy, subject expertise, and emotional intelligence, while the AI agent is utilized for information processing. A main limitation is that the information provided by AI agents may still not be perfectly accurate, and neurodiverse populations are not fully represented in training data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib88" title="">88</a>]</cite>. While acknowledging challenges, authors propose architecture guidelines for AI agent integration into education <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib94" title="">94</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib95" title="">95</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib46" title="">46</a>]</cite> and are generally optimistic about future progress in the area.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>Student engagement</h4>
<div class="ltx_para" id="S5.SS3.SSS1.p1">
<p class="ltx_p">AI agents are commonly implemented in education with a knowledge base containing course materials <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib96" title="">96</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib97" title="">97</a>]</cite>. One study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib92" title="">92</a>]</cite> implemented AI agents as co-learners for asynchronous learning. While the students watched tutorial videos, the agents had access to their screen and mouse movements, and students interacted with the agents through text and voice message. This resulted in improved social and cognitive presence. Cognitive presence is generally defined as meaning derived through sustained reflection and discourse; social presence is perceiving one’s environment to contain others. Another project, Mentigo,<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib89" title="">89</a>]</cite> adaptively responds to student interactions. The agent tracks 3 parameters: creative-problem-solving stage, student state, and selected strategy; after each dialogue round, the agent determines the state and stage, and from these values chooses the appropriate strategy.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p2">
<p class="ltx_p">AI agents can also help to simulate real-world scenarios. For example, in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib90" title="">90</a>]</cite>, students are studying healthcare root cause analysis, and agents representing professional roles—such as pharmacist and prescriber—provides students with the opportunity to participate in more dynamic and representative simulations than they might otherwise have access to. The authors implement a mentor agent which provides feedback to the learner based on every last 5 interactions. This mentor has access to the user’s interactions with all other agents, as well as the course and assignment goals, and is thus able to guide students towards the correct answer without revealing it directly: a key educator design goal for AI agents.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Educator workload</h4>
<div class="ltx_para" id="S5.SS3.SSS2.p1">
<p class="ltx_p">Educators often find themselves without the resources to provide personalized attention to every student. And although full AI agent integration has not yet taken place in education, several groups have identified good practices, conducted initial experiments, and created AI agents focused on education. One group <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib91" title="">91</a>]</cite> created a customized ChatGPT agent. In the system prompt, they provide the model with several steps to use while interacting with the student. For example, this group’s focus was teaching order words, so their first step was ”Explain what are order words?”, part of their fifth step was ”Confirm students’ understanding by asking them the following multiple-choice question…”, and their last step was ”Ask students to describe the story of Snow White in a 5-step story and use appropriate order words to tell their story.”, which is the assignment evaluated by the educator. This process can be iterative, with the educator providing feedback at chosen steps, and the agent guiding students towards meeting the goals of the provided rubric while only providing educator-approved content <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib98" title="">98</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p2">
<p class="ltx_p">Educators may also seek AI agent assistance in managing group dynamics, such as through socially shared regulation of learning (SSRL). <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib99" title="">99</a>]</cite> designed an agent with the task of raising group-level metacognitive awareness as part of improving SSRL, and prompted students when their contribution was not identified as group-oriented or when there were communication issues. Although the initial experiment with the group of 52 pre-service teachers was not considered successful in promoting SSRL, this work is illustrative of the future potential AI agents may have in regulating group settings.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p3">
<p class="ltx_p">AI agents also have the potential to assist with the development of course materials. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib100" title="">100</a>]</cite> presents one method, where the educator provides a set of slides, and the AI agents work to provide lecture notes and other resources dynamically based on student need. The study also supports a modified Massive Open Online Course (MOOC) format, termed MAIC (Massive AI Course) and employs teacher, assistant, classmate, analyzer, and manager agents as part of the core interaction infrastructure, with the additional option of custom agents as requested by the user. They also test their concept with 500 university volunteers and 2 courses, and find promising preliminary results <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib101" title="">101</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Science and Research</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p">Automated laboratories and scientific discovery agents can aid in optimizing laboratory functions by designing experiments, analyzing results, and proposing new hypotheses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib102" title="">102</a>]</cite>. Agents can rapidly process large datasets from genomics, proteomics, materials science, and physics, identifying patterns and suggesting novel solutions to catalyze fundamental research breakthroughs in many fields.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p">AI agents are able to contribute meaningfully to various aspects of the research process by making use of various cognitive and technical skills including, vast knowledge bases, self-management and evaluation, and communication. Research frameworks suggest AI agents can assist heavily in tasks involving data analysis, information retrieval, experimental design, and even the formulation of research questions and hypotheses. Multi-agent systems allow for interactions between individual agents while completing tasks, enabling seamless collaboration between human and AI researchers on all fronts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib103" title="">103</a>]</cite>.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.1 </span>Automated Laboratories in Biology and Chemistry</h4>
<div class="ltx_para" id="S5.SS4.SSS1.p1">
<p class="ltx_p">Research in Biology and Chemistry has seen the benefit of AI agent integration in automating laboratory functions. Leveraging their vast knowledge bases, AI agents can employ domain-specific knowledge when carrying out tasks such as experiment design and analysis of large datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib104" title="">104</a>]</cite>. This can be especially useful in materials sciences where data scarcity and comprehensive knowledge requirements can slow the research process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib105" title="">105</a>]</cite>. Furthermore, combining intelligent AI agent systems with robotics capabilities and laboratory hardware enables these systems to interact with the real world, automating repetitive lab work and minimizing risk when dealing with hazardous biological and chemical materials <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib106" title="">106</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib107" title="">107</a>]</cite>. Multi-agent systems can be utilized to conduct virtual simulations of cellular and molecular environments alongside subsequent analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib108" title="">108</a>]</cite>, accelerating scientific discovery within these fields <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib109" title="">109</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.2 </span>AI Researchers</h4>
<div class="ltx_para" id="S5.SS4.SSS2.p1">
<p class="ltx_p">While the utilization of AI and AI agents for completing specific research tasks has been well studied, there has been a recent effort to expand these agents to assist in the research process more holistically. Current AI research agents are prevalent in computer science and machine learning research. With many LLMs already possessing programming knowledge and capabilities, LLM-based agents can be used to maintain codebases, interact with files, conduct testing, and perform more general research tasks (hypothesis formulation, results analysis and discussion, etc.), mostly out-of-the-box <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib110" title="">110</a>]</cite>. Furthermore, Projects like the ”AI Scientist” have attempted to create an agent capable of fully automating all aspects of research from generating novel research ideas to conducting experiments to publishing their findings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib111" title="">111</a>]</cite>. Despite their remarkable potential, many of these agents still struggle with issues present in LLMS such as hallucinations and explainability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib111" title="">111</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib112" title="">112</a>]</cite>. Nevertheless, as these models improve over time and are better able to synthesize their vast amounts of knowledge, the viability of fully autonomous research agents will only grow.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Public Services and Urban Planning</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p">AI agents also enhance public service delivery, from optimizing public transportation schedules to managing energy grids and water distribution systems. Urban planners use AI-driven simulations to forecast the impact of infrastructure projects, assess environmental policies, and develop sustainable city layouts. By integrating data from diverse sources, agents can balance competing objectives such as cost, efficiency, and social equity.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS5.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.1 </span>Land Use and Urban Resource Management</h4>
<div class="ltx_para" id="S5.SS5.SSS1.p1">
<p class="ltx_p">Sustainable urban growth requires efficient resource management and land utilization. In parks and gardens, sensors keep an eye on irrigation-related parameters to guarantee effective water use. Energy conservation is aided by smart street lighting systems that have wireless internet relay capabilities, CCTV, and energy-efficient LED lights. Geographic Information Systems (GIS) and geospatial technologies help with resource allocation and urban planning by offering insights into land use trends<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib113" title="">113</a>]</cite>. AI helps create the best land use plans by striking a balance between environmental sustainability and development requirements. AI also facilitates the installation of green infrastructure, which reduces pollution and enhances urban sustainability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib114" title="">114</a>]</cite>. Examples of this include parks and green roofs. which help mitigate pollution and improve urban sustainability</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS5.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.2 </span>Collaborative Decision-making AI Agents in Public Administration</h4>
<div class="ltx_para" id="S5.SS5.SSS2.p1">
<p class="ltx_p">In public administration, AI and participative sensing technologies greatly improve decision-making. By enabling people to report events or incidents in the city, participatory sensing enhances public administration’s responsiveness and efficacy by sharing the reports with other users<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib113" title="">113</a>]</cite>. AI-driven urban planning offers data-driven insights that assist planners in making well-informed choices to enhance air quality and efficiently control urban growth. Predictive models help public administration improve public safety and allocate resources effectively by forecasting high crime risk locations<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib115" title="">115</a>]</cite>. Data-driven policymaking is supported by AI and GIS technologies, which offer insightful information for public administration and urban planning<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib116" title="">116</a>]</cite>. Policymakers can use these insights to inform policies that minimize pollution and advance sustainable development.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS5.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.3 </span>Transport routing optimization AI agents</h4>
<div class="ltx_para" id="S5.SS5.SSS3.p1">
<p class="ltx_p">AI technologies are essential for optimizing traffic flow and minimizing congestion in urban transport routes. Parking sensors save needless travel and pollution by guiding drivers and detecting available parking places. In order to help with effective traffic management, traffic intensity monitoring devices evaluate vehicle speeds, road occupancy, and traffic volumes. AI optimizes effective transportation flows, forecasts traffic, and examines transportation patterns. Through the support of Transit-Oriented Development (TOD), artificial intelligence (AI) contributes to the development of transit networks that provide high-capacity, safe, and effective modes of transportation while lowering emissions and traffic congestion<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib116" title="">116</a>]</cite>. Furthermore, AI applications in transportation safety improve public safety and optimize transportation routes, for example, by forecasting high-crime risk zones<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib115" title="">115</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Entertainment and Creativity</h3>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p">In the 21st century, people’s entertainment has dramatically shifted from traditional offline mediums to digital platforms, like social media platforms, video/music streaming services, and video games across different platforms and devices. This evolution has further been enhanced by recommendation algorithms specifically designed to personalize user experiences. Nowadays, the integration of AI-agents into the entertainment industry is becoming more popular. It’s a new trend that people start using AI-agents to create a better experience for the users.
In the entertainment industry, AI-agents not only generate personalized content recommendations, but also drive non-player characters in games. They can even assist in creative processes such as music composition, artwork generation, and scriptwriting as well. These creative agents leverage cutting-edge large language models and multimodal generation, along with traditional neural networks and optical character recognition techniques to support and produce results which are tailored to users’ interests and needs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib117" title="">117</a>]</cite>. Such personalized tools opens new paths for innovative approaches to artwork creation and interactive storytelling and significantly boosts players’ engagements and entertainments in games.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS6.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.6.1 </span>Visual Design and Storytelling</h4>
<div class="ltx_para" id="S5.SS6.SSS1.p1">
<p class="ltx_p">Artists and authors have long benefited from artificial intelligence. Tools such as text generation from ChatGPT and image creation from MidJourney and Stable Diffusion have reshaped the production of high-quality artworks and stories by aiding in the visualization of ideas, and reduction of repetitive tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib118" title="">118</a>]</cite> This evolution of workflow is further enhanced by the integration of AI-agents, which has the ability to integrate with multiple tools simultaneously to deliver design inspirations via both visual and textual mediums <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib118" title="">118</a>]</cite>. Additionally, there is Mimisbrunnur, which employs a mixed-initiative system to assist the writers in crafting compelling, high-quality interactive stories <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib119" title="">119</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS6.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.6.2 </span>Video games</h4>
<div class="ltx_para" id="S5.SS6.SSS2.p1">
<p class="ltx_p">Video games stand as a dominating form of entertainment in modern society. Their origin can track back to the 1960s. In order to create a more living environment and interactive experience, the concept of computer-controlled non-player characters (NPCs), inspired by Dungeons and Dragons, was introduced in the late 1970s. In the early years, the decision-making process of NPCs relied heavily on algorithms like Finite State Machines, as seen with Pac-Man’s ghosts, and tree-based methods like decision trees and behavior trees <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib120" title="">120</a>]</cite>. Today, people have seen the potential power of AI-agents and therefore shifted focus toward utilizing AI-agents to create more unique and revolutionary gaming experiences for players. Projects like the Scalable, Instructable, Multiworld Agent (SIMA) aim to develop a generalized AI-agent that can learn and engage with open-world games using a combination of on-screen visuals, text information as inputs, and potential user language directionss <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib121" title="">121</a>]</cite>. Another study explores AI-agents in the game ”Passcode,” where the AI-agent plays the role of the ”giver”, providing clues for the ”guesser”, which is the player, to guess a randomly chose word at the beginning of the game, demonstrating AI-agent’s ability to understand and handle interactive tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib122" title="">122</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS6.SSS2.p2">
<p class="ltx_p">However, while there’s huge potential in integrating AI-agents into the games, such a process still faces significant challenges. Currently, the behavior of AI-agent, particularly those driven by Large Language Models and neural networks, still struggles to reach the skill level of experienced human players. These AI-agents can be easily identified due to their unnatural actions and movements <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib123" title="">123</a>]</cite>. In addition, although they can understand simple commands like ”move forward” and ”stop”, they struggle to understand more complicated tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib121" title="">121</a>]</cite>. Nevertheless, ongoing research still promises a rapid evolution in AI-agent performance within the gaming industry.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.7 </span>Societal Impact and Considerations</h3>
<div class="ltx_para" id="S5.SS7.p1">
<p class="ltx_p">The applications of AI agents show significant promise and, at the same time, the social aspects cannot be ignored. It is crucial to guarantee the fairness, privacy, and inclusion of individuals in the design and decision making processes of AI technologies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib124" title="">124</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib125" title="">125</a>]</cite>. The public, industry leaders, and policymakers must work together to create and establish ethical principles, rules, and regulations that should be followed in the development and use of AI technologies.</p>
</div>
<div class="ltx_para" id="S5.SS7.p2">
<p class="ltx_p">The AI revolution has the potential to surpass the previous industrial and digital revolutions in scale and impact. While the Industrial Revolution mechanized manual tasks and the Digital Revolution automated routine mental tasks, the AI revolution has the potential to replicate and improve nearly all human cognitive functions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib126" title="">126</a>]</cite>. Apparently, AI agents have the most promising role in accelerating the AI revolution because they can invent new products and processes, increase efficiency, and apply them to various sectors.</p>
</div>
<div class="ltx_para" id="S5.SS7.p3">
<p class="ltx_p">However, with these promising opportunities, the AI revolution, driven by the rise of advanced AI agents, would bring significant challenges that governments and societies must address. AI agents, with their ability to automate not just routine but also complex cognitive tasks, can accelerate job displacement across industries. Their integration could disproportionately impact workers whose skills are rendered obsolete, amplifying skill mismatches and economic disruptions, particularly in regions heavily reliant on automation-vulnerable sectors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib126" title="">126</a>]</cite>. Furthermore, as AI agents become integral in decision-making processes, the economic gains they generate are likely to concentrate among those who develop and control these systems, exacerbating wealth inequality both within and across nations.</p>
</div>
<div class="ltx_para" id="S5.SS7.p4">
<p class="ltx_p">Unlike traditional large language models, AI agents operate autonomously and adapt over time, which makes accountability far more complex. Pin down who or what is responsible for an agent’s decisions or actions becomes increasingly difficult as its behavior evolves. Because these agents can interact directly with people, other systems, and even their surroundings, their influence tends to be much broader and more systemic. This amplifies both their potential impact and the risk of unintended outcomes.</p>
</div>
<div class="ltx_para" id="S5.SS7.p5">
<p class="ltx_p">To address the social impacts brought by AI Agents, it is important to develop standardized evaluation methods that ensure consistency and reliability in assessing potential harms and benefits. Transparency in AI development, data usage, and deployment must be established to build trust. Inclusive policies and equitable resource distribution are crucial to mitigating harms and reducing disparities. Furthermore, promoting ethical AI development requires attention to cultural and contextual differences, ensuring that AI systems respect diverse values <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib127" title="">127</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS7.p6">
<p class="ltx_p">In summary, AI agents are transforming a wide range of domains, improving efficiency, accessibility, and personalization. As these agents mature, they hold the potential to address grand challenges in healthcare, education, sustainability, and beyond, provided that developers and stakeholders maintain a steadfast commitment to ethical and human-centric design. Governments should also play a critical role in establishing clear regulatory frameworks, promoting equitable access to AI technologies, and ensuring accountability to safeguard societal interests while fostering innovation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>AI Agent Design</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p">The development of next-generation AI agents:</p>
</div>
<figure class="ltx_figure" id="S6.fig1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_centering ltx_img_landscape" height="329" id="S6.g1" src="diagrams/Agent_Design_Process.png" width="598"/>
</figure>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Cognitive-Inspired Architectures</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p">Hybrid models that combine symbolic reasoning with neural networks are heavily inspired by human cognitive processes, where both structured reasoning and adaptive learning coexist. By leveraging the compositionality and hierarchical structure inherent in symbolic representations, these architectures not only enhance interpretability but also improve generalization capabilities across diverse tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib128" title="">128</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p">These models excel in domains requiring precise reasoning, such as scientific discovery, automated theorem proving, and natural language understanding, where traditional deep learning approaches struggle with ambiguity or long-range dependencies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib14" title="">14</a>]</cite>. The integration of neural networks enables these hybrid systems to process unstructured data like images, audio, and text, while symbolic components offer a framework for logic, abstraction, and transfer learning.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p">Recent advances in hybrid architectures have shown promise in areas such as program synthesis, where symbolic reasoning is used for code generation and verification, and robotics, where symbolic planning enhances decision-making in dynamic environments. Future research is expected to focus on scalable implementations of these systems and developing methods to dynamically balance symbolic and neural components for optimal performance in real-world applications  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib128" title="">128</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Hierarchical and Modular Approaches</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p">Decomposing complex tasks into manageable subtasks and leveraging modular architectures fosters scalability, reusability, and system stability. Hierarchical frameworks enable AI agents to break down high-level goals into smaller, more tractable components, streamlining task execution and improving performance. Modular architectures, on the other hand, allow for the development of specialized submodules, each dedicated to a specific functionality, thereby promoting adaptability and efficient resource allocation.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p">These approaches also enhance interpretability by allowing researchers and practitioners to understand the role and behavior of individual modules, which is particularly critical in safety-critical domains like autonomous vehicles, healthcare, and robotics. Additionally, modular systems simplify failure diagnosis, as issues can often be traced back to specific components rather than requiring analysis of the entire system.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p">Recent advances have demonstrated the utility of hierarchical and modular designs in reinforcement learning, natural language processing, and robotics. For instance, hierarchical reinforcement learning algorithms decompose decision-making processes into macro-actions, enabling agents to solve long-horizon tasks more effectively. Similarly, modular neural networks in natural language processing have been employed to handle tasks like machine translation, sentiment analysis, and summarization within a unified framework.</p>
</div>
<div class="ltx_para" id="S6.SS2.p4">
<p class="ltx_p">Moving forward, future research should focus on enhancing the dynamic interplay between hierarchical control layers and modular subsystems, enabling AI agents to seamlessly adapt to new and unforeseen challenges. Efforts to integrate these approaches with techniques such as meta-learning and transfer learning hold promise for creating robust, scalable, and generalizable AI agents capable of operating in complex, real-world environments  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib129" title="">129</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib130" title="">130</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion</h2>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Discussion and a Step-by-Step Guide</h3>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p">For newcomers, AI agent research can seem overwhelming due to its interdisciplinary nature. This section provides a structured path to help researchers gain foundational knowledge and practical experience. Given its breadth and interdisciplinary nature, newcomers often struggle to find a structured learning path. This guide provides an approach to help researchers navigate challenges, build foundational knowledge, and develop impactful projects.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Step 1: Build a Strong Theoretical Foundation
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para" id="S7.SS1.p3">
<p class="ltx_p">Developing a solid theoretical foundation is the first step. Understanding how AI agents perceive, make decisions, and act is essential before implementation. Topics such as reinforcement learning, multi-agent coordination, planning, and decision theory provide a necessary framework.</p>
</div>
<div class="ltx_para" id="S7.SS1.p4">
<p class="ltx_p">Foundational works such as <span class="ltx_text ltx_font_italic">Multi-Agent Systems: A Survey</span> and <span class="ltx_text ltx_font_italic">Reinforcement Learning: An Introduction</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib6" title="">6</a>]</cite> help researchers grasp core AI agent architectures and methodologies. Online courses and research blogs, such as <span class="ltx_text ltx_font_italic">Lilian Weng’s Blog</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib36" title="">36</a>]</cite>, provide accessible explanations of advanced topics like memory-augmented neural networks and tool-augmented learning.</p>
</div>
<div class="ltx_para" id="S7.SS1.p5">
<p class="ltx_p">Beyond theory, implementing simple reinforcement learning algorithms in controlled environments is crucial. OpenAI Gym and similar frameworks allow hands-on experimentation, helping researchers develop an intuitive understanding of AI agent behavior. Starting with basic agents for navigation, decision-making, and task automation reinforces theoretical knowledge through direct application <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib131" title="">131</a>]</cite>.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S7.SS1.p6">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Step 2: Focus on Measurable Projects
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para" id="S7.SS1.p7">
<p class="ltx_p">AI agent research requires clear success metrics. Unlike traditional supervised learning, AI agents operate in dynamic environments where evaluation methods differ. Researchers should begin with structured projects that allow controlled experimentation and measurable outcomes.</p>
</div>
<div class="ltx_para" id="S7.SS1.p8">
<p class="ltx_p">Single-agent reinforcement learning tasks, such as autonomous navigation and game-playing, provide an excellent starting point. Evaluating performance through reward signals, convergence rates, and task completion times ensures systematic progress tracking. For those interested in multi-agent research, simulation platforms such as CARLA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib132" title="">132</a>]</cite> and PettingZoo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib133" title="">133</a>]</cite> offer controlled settings to study collaborative and competitive agent behaviors.</p>
</div>
<div class="ltx_para" id="S7.SS1.p9">
<p class="ltx_p">Defining evaluation metrics early ensures research remains focused and reproducible. Whether optimizing decision policies, improving sample efficiency, or enhancing interpretability, measurable goals help refine research directions and improve experimental reproducibility.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S7.SS1.p10">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Step 3: Gain Practical Experience with Tools and Iterative Learning
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para" id="S7.SS1.p11">
<p class="ltx_p">Hands-on experience with AI agent frameworks is essential for moving beyond theoretical learning. Simulation environments such as RoboCup Soccer Simulation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib134" title="">134</a>]</cite> and CARLA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib132" title="">132</a>]</cite> allow structured experimentation without extensive development, enabling researchers to focus on agent decision-making, coordination, and adaptability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib135" title="">135</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S7.SS1.p12">
<p class="ltx_p">AI agents learn through repeated interactions rather than fixed datasets. Iterative learning techniques, such as reinforcement learning with self-reflection and hierarchical RL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib36" title="">36</a>]</cite>, help refine agent behavior. Adjusting hyperparameters, modifying architectures, and fine-tuning reward functions improve learning efficiency and stability.</p>
</div>
<div class="ltx_para" id="S7.SS1.p13">
<p class="ltx_p">Engagement with open-source AI communities accelerates learning. Platforms like GitHub host repositories with baseline models and experimental frameworks, allowing new researchers to explore existing implementations and contribute to ongoing projects. Reproducing research paper results is another valuable exercise, helping researchers understand the nuances of implementation and evaluation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib136" title="">136</a>]</cite>.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S7.SS1.p14">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Step 4. Leverage Open-Source Communities and Reproducibility.
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para" id="S7.SS1.p15">
<p class="ltx_p">Engagement with open-source projects accelerates learning and fosters collaboration. Sharing project code and insights within the community not only enhances reproducibility but also allows researchers to build on each other’s work. Platforms like GitHub host numerous repositories for AI agent research, providing access to baseline models and implementations that can serve as starting points for new projects. Projects like CARLA and PettingZoo provide a variety of tools including access to simulation environments, assets, models, and step-by-step instructions, enabling a straightforward process for replicating experiments and streamlining iteration upon existing work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib132" title="">132</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib133" title="">133</a>]</cite>. Projects like RoboCup Soccer Simulation leverage open-source competitions to drive community engagement and accelerate development of cutting-edge AI agent systems. By actively contributing to these communities, researchers can stay informed about emerging trends and gain feedback on their work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib137" title="">137</a>]</cite>.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S7.SS1.p16">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Step 5. Address Broader Research Gaps.
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para" id="S7.SS1.p17">
<p class="ltx_p">The novelty of AI agents means that many areas remain underexplored. Researchers should identify gaps in the literature, such as the integration of advanced planning algorithms with tool-augmented LLMs or the use of hybrid symbolic-subsymbolic approaches for better interpretability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib138" title="">138</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib13" title="">13</a>]</cite>. Exploring these areas can lead to groundbreaking contributions and help establish best practices for the field.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Challenges and Limitations</h3>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p">Despite substantial progress, significant hurdles remain that limit their potential <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib139" title="">139</a>]</cite>. This section examines critical areas of concern, including safety, interpretability, ethics, generalization and acability, and highlights the need for interdisciplinary efforts to address these issues:</p>
</div>
<section class="ltx_subsubsection" id="S7.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.1 </span>Safety and Robustness</h4>
<div class="ltx_para" id="S7.SS2.SSS1.p1">
<p class="ltx_p">Among these, ensuring safety and robustness in dynamic environments is a persistent hurdle. AI agents often struggle with adapting changes in the environment, particularly when exposed to scenarios or data that differ significantly from their training. These vulnerabilities are further compounded by the potential for adversarial attacks, where minor input perturbations can drastically alter agent behavior. resilience to variability and ensure reliable performance even under extreme conditions
Agents often exhibit sensitivity to distributional shifts, adversarial perturbations, and environment changes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib140" title="">140</a>]</cite>. Ensuring safe operation in open-ended and uncertain settings requires improved robustness techniques, formal verification, and worst-case guarantees under extreme conditions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.2 </span>Explainability and Interpretability</h4>
<div class="ltx_para" id="S7.SS2.SSS2.p1">
<p class="ltx_p">As agents grow more complex, their decision-making processes become opaque <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib141" title="">141</a>]</cite>. This lack of interpretability poses significant challenges in fostering user trust, debugging errors, and complying with regulatory requirements, especially in domains such as finance and medicine. Tools for model introspection, attention visualization, causal attribution, and symbolic distillation have been proposed as potential solutions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib142" title="">142</a>]</cite>. These approaches aim to provide clear insight into agent decision-making, enabling stakeholders to better assess and trust system’s outputs. However, current methods remain limited and require further refinement to align with practical needs of end-users and regulatory frameworks.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.3 </span>Ethical and Social Considerations</h4>
<div class="ltx_para" id="S7.SS2.SSS3.p1">
<p class="ltx_p">The deployment of AI agents in sensitive domains introduces ethical and social challenges. Issues such as bias, fairness, privacy, and accountability are pressing concerns as agents often inherit biases present from their training data, perpetuating social inequalities  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib125" title="">125</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib124" title="">124</a>]</cite>. For example, the <span class="ltx_text ltx_font_italic">MDPI review on AI agent challenges</span> discusses these concerns in detail, emphasizing the need for transparent evaluation methods and robust regulatory frameworks. Aligning agents with human values, establishing standards for responsible AI, and developing frameworks for ethical oversight will be crucial as agents increasingly connect and interact with social systems. Without these safeguards, the widespread deployment of AI agents could exacerbate existing disparities and raise concerns about their impact on human autonomy and rights <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib143" title="">143</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib144" title="">144</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.4 </span>Generalization and Transfer</h4>
<div class="ltx_para" id="S7.SS2.SSS4.p1">
<p class="ltx_p">Many agents struggle with out-of-distribution generalization, requiring extensive retraining for new tasks or domains, often requiring extensive training to operate effectively in different environments. This lack of transferability undermines their utility in real-world applications, where agents must adapt quickly to novel scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib145" title="">145</a>]</cite>. For example, an agent trained in a simulated environment may fail to perform effectively in a real-deployment due to subtle but critical differences between two contexts. Advancing methods for domain adaptation, transfer learning, and task-agnostic representations will be essential for creating versatile and agile agents capable of functioning in diverse and unpredictable conditions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib146" title="">146</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib147" title="">147</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS2.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.5 </span>Scalability and Resource Efficiency</h4>
<div class="ltx_para" id="S7.SS2.SSS5.p1">
<p class="ltx_p">Training and deploying state-of-the-art models can be computationally and energy-intensive which represents a barrier to scalability and accessibility. Modern AI agents often require extensive resources, limiting their deployment to organizations with substantial computational infrastructure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib148" title="">148</a>]</cite>. Additionally, the environmental impact of these systems raises concerns about sustainability. Research on model compression, efficient architectures, and distributed learning paradigms aims to reduce resource footprints without sacrificing performance. These advancements are necessary to make AI agents more accessible to smaller organizations and environmentally sustainable for widespread adoption <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib149" title="">149</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib150" title="">150</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib151" title="">151</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Future Directions and Emerging Opportunities</h3>
<div class="ltx_para" id="S7.SS3.p1">
<p class="ltx_p">Despite current challenges in the field of AI agents, several promising frontiers offer opportunities for future advancements in this area. Therefore, this section explores some of these potential applications where AI agents could support and enhance research and production <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib152" title="">152</a>]</cite>:</p>
</div>
<section class="ltx_subsubsection" id="S7.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.1 </span>Neuroscience-Inspired Mechanisms</h4>
<div class="ltx_para" id="S7.SS3.SSS1.p1">
<p class="ltx_p">Recent studies have applied principles from neuroscience into deep learning, particularly focusing on how neurons in the brain utilize cost functions to adapt to diverse contexts by changing their properties. This integration has demonstrated utility in enhancing the performance of deep learning models  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib138" title="">138</a>]</cite>. Consequently, this direction worth future attention to dive deeper into the adoption of additional neuroscience paradigms, including predictive coding, dendritic computations, and synaptic plasticity, into AI agents. Such integration could potentially yield more stable, interpretable, and efficient learning mechanisms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib153" title="">153</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.2 </span>Interactive and Continual Learning</h4>
<div class="ltx_para" id="S7.SS3.SSS2.p1">
<p class="ltx_p">Traditional machine learning approaches are mainly designed for static environments, such as training models to classify predefined categories or to play specific games. A significant drawback of these methods is catastrophic forgetting, where models lose previously learned concepts when exposed to new data or features <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib154" title="">154</a>]</cite>. In response, research has examined the concept of continual learning, an architecture that involves learning from an endless stream of data while retaining previous knowledge  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib155" title="">155</a>]</cite>. This approach has proven useful for machine learning models for keeping a long-term memory on learned features, suggesting that it could enable AI agents to refine their knowledge base through iterative feedback, human demonstrations, and structured curricula, and consequentially making them more robust and versatile  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib156" title="">156</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib157" title="">157</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.3 </span>Hybrid Symbolic-Subsymbolic Models</h4>
<div class="ltx_para" id="S7.SS3.SSS3.p1">
<p class="ltx_p">Symbolic and subsymbolic models represent the two primary types of AI models, categorized by their background features like reasoning and knowledge storage mechanisms. Both types has demonstrated significant success in performing specific tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib158" title="">158</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib159" title="">159</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib160" title="">160</a>]</cite>. Given these strengths, it is worthwhile to explore the integration of these methodologies and leveraging the advantages of both. We believe such an approach of blending the transparency and structure of symbolic reasoning with the pattern recognition capabilities of deep neural networks holds the potential for robust generalization, interpretability, and efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib14" title="">14</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.4 </span>Multi-Agent Governance and Coordination</h4>
<div class="ltx_para" id="S7.SS3.SSS4.p1">
<p class="ltx_p">The architecture of AI agents inherently involves the collaboration of multiple agents, each possessing unique features and advantages. As the scale of an AI agent system grows, the number of participants would increase <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib161" title="">161</a>]</cite>. Thus, the governance and coordination of these agents — which includes task allocation, negotiation protocols, and data race management — are crucial to the system’s performance. Studies have indicated that by implementing suitable protocols within multi-agent deep learning models, system performance can be enhanced <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib162" title="">162</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib163" title="">163</a>]</cite>. Therefore, it is essential to conduct future research focused on these coordination mechanisms to advance the performance of AI agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib164" title="">164</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib165" title="">165</a>]</cite>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p">AI agents have transformed from specialized, rule-bound systems to increasingly integrated, autonomous entities that perceive, reason, act, and collaborate. This review surveyed the historical evolution, core architectural components, and emerging paradigms that define contemporary AI agents. We discussed breakthroughs in reinforcement learning, large language models, hierarchical planning, and embodied intelligence. Yet, critical challenges persist: improving safety, interpretability, and ethical stewardship, as well as achieving robust generalization and resource efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib166" title="">166</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib167" title="">167</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib153" title="">153</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p">The path forward demands interdisciplinary engagement. Insights from cognitive science, neuroscience, sociology, economics, and ethics will inform next-generation agents. By prioritizing human values, transparency, and long-term adaptability, we can usher in an era where AI agents serve as trustworthy partners in scientific research, industrial automation, healthcare, education, and beyond. With sustained collaboration and careful innovation, the future of AI agents holds the promise of more capable, responsible, and beneficial autonomous intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib168" title="">168</a>, <a class="ltx_ref" href="https://arxiv.org/html/2508.11957v1#bib.bib169" title="">169</a>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Competing Interests</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p">The author declares no competing interests.</p>
</div>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p">The first 4 queries were used to query Google Scholar and the last query was used to query Papers with Code:
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Business</span>: <span class="ltx_text ltx_font_italic">(”AI Agent” OR ”ML Agent” OR ”Deep Learning Agent” OR ”Autonomous Agent” OR ”Automated AI” OR ”Generative AI Agent” OR ”Reinforcement Learning Agent” OR ”Intelligent Agent” OR ”Multi-Agent System”)
AND
(”Business” OR ”Industry” OR ”Industrial Applications” OR ”Manufacturing” OR ”Production” OR ”Supply Chain” OR ”Logistics” OR ”Automation” OR ”Process Optimization” OR ”Predictive Maintenance” OR ”Operations Management” OR ”Enterprise AI” OR ”Decision-Making in Industry” OR ”Industrial AI”)”

<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Education</span>: <span class="ltx_text ltx_font_italic">(‘AI Agent’) AND (’Education’) AND (’Learning’ OR ’Teaching’) AND (’Classroom’ OR ’Critical Thinking’ OR ’Curriculum’ OR ’Synchronous’) AND (’Resource’)
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Science</span>: <span class="ltx_text ltx_font_italic">(”AI Agent” OR ”Agent” OR ”Autonomous Agent” OR ”ML Agent” OR ”Multi-Agent System” OR ”Reinforcement Learning Agent” OR ”LLM-Based Agent”) AND (”AI Scientist” OR ”AI Researcher” OR ”Autonomous Researcher” OR ”Autonomous Laboratory” OR ”Scientific Discovery Agent”)
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Entertainment</span>: <span class="ltx_text ltx_font_italic">(”AI Agent” OR “AI-Assisted”) AND (“Entertainment” OR “Design” OR “Game” OR “Storytelling”)
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p6">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Social Impact</span>: <span class="ltx_text ltx_font_italic">(“AI Agent” OR “Generative AI”) AND (“Social Impact” OR “Society” OR “Social Implications”)
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Papers with Code</span>: <span class="ltx_text ltx_font_italic">”AI Agent”</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Peter Stone and Manuela Veloso.

</span>
<span class="ltx_bibblock">Multiagent systems: A survey from a machine learning perspective.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Autonomous Robots</span>, 8(3):345–383, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Alexey et al. Dosovitskiy.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at scale.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Edward A. Feigenbaum and Pamela McCorduck.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The Fifth Generation: Artificial Intelligence and Japan’s Computer Challenge to the World</span>.

</span>
<span class="ltx_bibblock">Addison-Wesley, 1983.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Malik Ghallab, Dana Nau, and Paolo Traverso.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Automated Planning: Theory and Practice</span>.

</span>
<span class="ltx_bibblock">Elsevier, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Leslie Pack Kaelbling, Michael L Littman, and Andrew W Moore.

</span>
<span class="ltx_bibblock">Reinforcement learning: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Journal of artificial intelligence research</span>, 4:237–285, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Richard S Sutton and Andrew G Barto.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Reinforcement Learning: An Introduction</span>.

</span>
<span class="ltx_bibblock">MIT press, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
David et al. Silver.

</span>
<span class="ltx_bibblock">Mastering the game of go with deep neural networks and tree search.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nature</span>, 529:484–489, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
David et al. Silver.

</span>
<span class="ltx_bibblock">Mastering the game of go without human knowledge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nature</span>, 550:354–359, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jacob et al. Devlin.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">NAACL-HLT</span>, pages 4171–4186, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Communications of the ACM</span>, 60(6):84–90, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">CVPR</span>, pages 770–778, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Tom B et al. Brown.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">NeurIPS</span>, 33:1877–1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman.

</span>
<span class="ltx_bibblock">Building machines that learn and think like people.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Behavioral and Brain Sciences</span>, 40:e253, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Gary Marcus.

</span>
<span class="ltx_bibblock">The next decade in ai: Four steps towards robust artificial intelligence.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Medium</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Jingqun Tang, Chunhui Lin, Zhen Zhao, Shu Wei, Binghong Wu, Qi Liu, Hao Feng, Yang Li, Siqi Wang, Lei Liao, et al.

</span>
<span class="ltx_bibblock">Textsquare: Scaling up text-centric visual instruction tuning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2404.12803</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Brian Paden, Michal Čáp, Sze Zheng Yong, Denis Yershov, and Emilio Frazzoli.

</span>
<span class="ltx_bibblock">A survey of motion planning and control techniques for self-driving urban vehicles.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE Transactions on Intelligent Vehicles</span>, 1(1):33–55, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Philip J Kitson, Guillaume Marie, John S Fossey, Paulo Jesus, and Leroy Cronin.

</span>
<span class="ltx_bibblock">Configurable robotic platform for automated synthesis.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nature</span>, 549:70–75, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Zhen Zhao, Jingqun Tang, Binghong Wu, Chunhui Lin, Shu Wei, Hao Liu, Xin Tan, Zhizhong Zhang, Can Huang, and Yuan Xie.

</span>
<span class="ltx_bibblock">Harmonizing visual text comprehension and generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2407.16364</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Gokhan Tür and Renato De Mori.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</span>.

</span>
<span class="ltx_bibblock">Wiley, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Yue Deng, Feng Bao, Youyong Kong, Zhiquan Ren, and Qionghai Dai.

</span>
<span class="ltx_bibblock">Deep direct reinforcement learning for financial signal representation and trading.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE transactions on neural networks and learning systems</span>, 28(3):653–664, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Volodymyr et al. Mnih.

</span>
<span class="ltx_bibblock">Human-level control through deep reinforcement learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nature</span>, 518:529–533, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, et al.

</span>
<span class="ltx_bibblock">Playing atari with deep reinforcement learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">NIPS Deep Learning Workshop</span>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Yaodong et al. Yang.

</span>
<span class="ltx_bibblock">Mean field multi-agent reinforcement learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 5571–5580, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Chenyu Zhao, Mengyi Feng, Martin Gluchman, Xianghe Ma, Jinhao Li, and Hui Wang.

</span>
<span class="ltx_bibblock">Acellular fish skin grafts in the treatment of diabetic wounds: Advantages and clinical translation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Journal of Diabetes</span>, 16(5):e13554, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Chiung-Ting Wu, Minjie Shen, Dongping Du, Zuolin Cheng, Sarah J Parker, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, et al.

</span>
<span class="ltx_bibblock">Cosbin: cosine score-based iterative normalization of biologically diverse samples.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Bioinformatics Advances</span>, 2(1):vbac076, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Jirong Wen.

</span>
<span class="ltx_bibblock">A survey on large language model based autonomous agents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Frontiers of Computer Science</span>, 18(6):186345, March 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang.

</span>
<span class="ltx_bibblock">Large Language Model based Multi-Agents: A Survey of Progress and Challenges, April 2024.

</span>
<span class="ltx_bibblock">arXiv:2402.01680 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Zhen Zhu, Xiaobo Li, Qianwen Ma, Jingsheng Zhai, and Haofeng Hu.

</span>
<span class="ltx_bibblock">Fdnet: Fourier transform guided dual-channel underwater image enhancement diffusion network.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Science China Technological Sciences</span>, 68(1):1100403, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui.

</span>
<span class="ltx_bibblock">The Rise and Potential of Large Language Model Based Agents: A Survey, September 2023.

</span>
<span class="ltx_bibblock">arXiv:2309.07864 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Junlin Xie, Zhihong Chen, Ruifei Zhang, Xiang Wan, and Guanbin Li.

</span>
<span class="ltx_bibblock">Large Multimodal Agents: A Survey, February 2024.

</span>
<span class="ltx_bibblock">arXiv:2402.15116 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Yingzhou Lu, Chiung-Ting Wu, Sarah J Parker, Lulu Chen, Georgia Saylor, Jennifer E Van Eyk, David M Herrington, and Yue Wang.

</span>
<span class="ltx_bibblock">Cot: an efficient python tool for detecting marker genes among many subtypes.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">bioRxiv</span>, pages 2021–01, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Jinran Zhang, Zhelu Mai, Zhuoer Xu, and Zhaomin Xiao.

</span>
<span class="ltx_bibblock">Is llama 3 good at identifying emotion? a comprehensive study.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI)</span>, MLMI ’24, page 128–132, New York, NY, USA, 2024. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Rui-Feng Wang and Wen-Hao Su.

</span>
<span class="ltx_bibblock">The application of deep learning in the whole potato production chain: A comprehensive review.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Agriculture</span>, 14(8):1225, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Zhengle Wang, Ruifeng Wang, Minjuan Wang, Tianyun Lai, and Man Zhang.

</span>
<span class="ltx_bibblock">Self-supervised transformer-based pre-training method with general plant infection dataset.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Chinese Conference on Pattern Recognition and Computer Vision (PRCV)</span>, pages 189–202. Springer, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Tianshi Wang, Qikai Yang, Ruijie Wang, Dachun Sun, Jinyang Li, Yizhuo Chen, Yigong Hu, Chaoqi Yang, Tomoyoshi Kimura, Denizhan Kara, et al.

</span>
<span class="ltx_bibblock">Fine-grained control of generative data augmentation in iot sensing.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 37:32787–32812, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Lilian Weng.

</span>
<span class="ltx_bibblock">Llm-powered autonomous agents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">lilianweng.github.io</span>, Jun 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Tejas D et al. Kulkarni.

</span>
<span class="ltx_bibblock">Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">NeurIPS</span>, pages 3675–3683, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Rohan Chitnis, Tom Silver, and Tomas Lozano-Pérez.

</span>
<span class="ltx_bibblock">Learning quickly to plan quickly using modular meta-learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICRA</span>, pages 7867–7874, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Jason et al. Wei.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">NeurIPS</span>, pages 24824–24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
John et al. Schulman.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv:1707.06347</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Tuomas et al. Haarnoja.

</span>
<span class="ltx_bibblock">Soft actor-critic algorithms and applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv:1812.05905</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.

</span>
<span class="ltx_bibblock">Reflexion: Language agents with verbal reinforcement learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Hao Liu, Carmelo Sferrazza, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Chain of hindsight aligns language models with feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.02676</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Chelsea Finn, Pieter Abbeel, and Sergey Levine.

</span>
<span class="ltx_bibblock">Model-agnostic meta-learning for fast adaptation of deep networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICML</span>, pages 1126–1135, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Matthias et al. De Lange.

</span>
<span class="ltx_bibblock">A continual learning survey: Defying forgetting in classification tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE TPAMI</span>, 44(7):3366–3385, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Yuan-Hao Jiang, Ruijia Li, Yizhou Zhou, Changyong Qi, Hanglei Hu, Yuang Wei, Bo Jiang, and Yonghe Wu.

</span>
<span class="ltx_bibblock">Ai agent for education: Von neumann multi-agent system framework.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 28th Global Chinese Conference on Computers in Education (GCCCE 2024)</span>, pages 77–84, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">A survey on the memory mechanism of large language model based agents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2404.13501</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Zhaochen Su, Jun Zhang, Xiaoye Qu, Tong Zhu, Yanshu Li, Jiashuo Sun, Juntao Li, Min Zhang, and Yu Cheng.

</span>
<span class="ltx_bibblock">Conflictbank: A benchmark for evaluating the influence of knowledge conflicts in llm, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Wensi Xie, Jingwen Dou, Yiran Wang, and Xiaodong Qu.

</span>
<span class="ltx_bibblock">From theory to play: A review of eeg-controlled directional games and evaluation of custom-developed bci games.

</span>
<span class="ltx_bibblock">2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">Building effective agents.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/research/building-effective-agents" title="">https://www.anthropic.com/research/building-effective-agents</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-12-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al.

</span>
<span class="ltx_bibblock">Augmented language models: a survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.07842</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Zhaomin Xiao, Zhelu Mai, Yachen Cui, Zhuoer Xu, and Jiancheng Li.

</span>
<span class="ltx_bibblock">Short interest trend prediction with large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2024 International Conference on Innovation in Artificial Intelligence</span>, ICIAI ’24, page 1, New York, NY, USA, 2024. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li.

</span>
<span class="ltx_bibblock">Api-bank: A comprehensive benchmark for tool-augmented llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.08244</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Jingqun Tang, Wenqing Zhang, Hongye Liu, MingKun Yang, Bo Jiang, Guanglong Hu, and Xiang Bai.

</span>
<span class="ltx_bibblock">Few could be better than all: Feature sampling and grouping for scene text detection.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 4563–4572, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Ting et al. Chen.

</span>
<span class="ltx_bibblock">A simple framework for contrastive learning of visual representations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">ICML</span>, pages 1597–1607, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Jingqun Tang, Wenming Qian, Luchuan Song, Xiena Dong, Lan Li, and Xiang Bai.

</span>
<span class="ltx_bibblock">Optimal boxes: boosting end-to-end scene text recognition by adjusting annotated bounding boxes via reinforcement learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, pages 233–248. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Zhaomin Xiao, Zhelu Mai, Zhuoer Xu, Youngkwang Kwon, and Jiancheng Li.

</span>
<span class="ltx_bibblock">Short interest trend prediction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2024 6th International Conference on Natural Language Processing (ICNLP)</span>, pages 352–356, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Yu-Hao Tu, Rui-Feng Wang, and Wen-Hao Su.

</span>
<span class="ltx_bibblock">Active disturbance rejection control—new trends in agricultural cybernetics in the future: A comprehensive review.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Machines</span>, 13(2):111, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Angeliki Lazaridou and Marco Baroni.

</span>
<span class="ltx_bibblock">Emergent multi-agent communication in the deep learning era.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Neural Computation</span>, 31(5):753–763, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Yonatan et al. Bisk.

</span>
<span class="ltx_bibblock">Experience grounds language.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">EMNLP</span>, pages 8718–8735, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Zilinghan Li, Shilan He, Ze Yang, Minseok Ryu, Kibaek Kim, and Ravi Madduri.

</span>
<span class="ltx_bibblock">Advances in appfl: A comprehensive and extensible federated learning framework.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2409.11585</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Yue Wu, Ben Ehlert, Ahmed A Metwally, Dalia Perelman, Heyjun Park, Andrew Wallace Brooks, Fahim Abbasi, Basil Michael, Alessandra Celli, Caroline Bejikian, et al.

</span>
<span class="ltx_bibblock">Individual variations in glycemic responses to carbohydrates and underlying metabolic physiology.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nature Medicine</span>, pages 1–12, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Yizhi Wang, Yi Fu, Zhen Zhang, Robert Clarke, Sarah J Parker, David M Herrington, Guoqiang Yu, and Yue Wang.

</span>
<span class="ltx_bibblock">iddn: determining trans-omics network structure and rewiring with integrative differential dependency networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Bioinformatics Advances</span>, 5(1):vbaf086, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Chenyu Zhao, Changqian Cen, Ruihan Zhang, Wenjin He, Yiyang Jiao, Zhuoya Chen, Zhaoqi Wu, and Ting Luan.

</span>
<span class="ltx_bibblock">A two-step bayesian mendelian randomization study on cholecystitis and dermatitis.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">medRxiv</span>, pages 2024–09, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Matthew L Key, Tural Mehtiyev, and Xiaodong Qu.

</span>
<span class="ltx_bibblock">Advancing eeg-based gaze prediction using depthwise separable convolution and enhanced pre-processing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Human-Computer Interaction</span>, pages 3–17. Springer, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Lulu Chen, Yingzhou Lu, Chiung-Ting Wu, Robert Clarke, Guoqiang Yu, Jennifer E Van Eyk, David M Herrington, and Yue Wang.

</span>
<span class="ltx_bibblock">Data-driven detection of subtype-specific differentially expressed genes.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Scientific reports</span>, 11(1):332, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Daniel Katz, Christopher Jin, Gregory Smith, Natalie Clark, Gayatri Iyer, Hasmik Keshishian, Patrick Hart, James Sanford, Zidong Zhang, Yongchao Ge, et al.

</span>
<span class="ltx_bibblock">The multi-omic, multi-tissue response to acute endurance and resistance exercise: Results from the molecular transducers of physical activity consortium.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Circulation</span>, 150(Suppl_1):A4143199–A4143199, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Weigeng Li, Neng Zhou, and Xiaodong Qu.

</span>
<span class="ltx_bibblock">Enhancing eye-tracking performance through multi-task learning transformer.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Human-Computer Interaction</span>, pages 31–46. Springer, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Xintao Li, Sibei Liu, Dezhi Yu, Yang Zhang, and Xiaoyu Liu.

</span>
<span class="ltx_bibblock">Predicting 30-day hospital readmission in medicare patients insights from an lstm deep learning model.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2024 3rd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)</span>, pages 61–65, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Dongping Du, Saurabh Bhardwaj, Sarah J Parker, Zuolin Cheng, Zhen Zhang, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, et al.

</span>
<span class="ltx_bibblock">Abds: tool suite for analyzing biologically diverse samples.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">bioRxiv</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Yi Fu, Yingzhou Lu, Yizhi Wang, Bai Zhang, Zhen Zhang, Guoqiang Yu, Chunyu Liu, Robert Clarke, David M Herrington, and Yue Wang.

</span>
<span class="ltx_bibblock">Ddn3. 0: Determining significant rewiring of biological network structure with differential dependency networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Bioinformatics</span>, page btae376, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Han Xu, Jingyang Ye, Yutong Li, and Haipeng Chen.

</span>
<span class="ltx_bibblock">Can speculative sampling accelerate react without compromising reasoning quality?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">The Second Tiny Papers Track at ICLR 2024</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
M Satheesh and Samala Nagaraj.

</span>
<span class="ltx_bibblock">Applications of artificial intelligence on customer experience and service quality of the banking sector.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">International Management Review</span>, 17(1):9–86, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Dongping Du, Saurabh Bhardwaj, Yizhi Wang, Sarah J Parker, Zhen Zhang, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, et al.

</span>
<span class="ltx_bibblock">Embracing the informative missingness and silent gene in analyzing biologically diverse samples.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Scientific Reports</span>, 14(1):28265, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Martin Christopher.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Logistics and supply chain management</span>.

</span>
<span class="ltx_bibblock">Pearson Uk, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Rupa Dash, Mark McMurtrey, Carl Rebman, and Upendra K Kar.

</span>
<span class="ltx_bibblock">Application of artificial intelligence in automation of supply chain management.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Journal of Strategic Innovation and Sustainability</span>, 14(3), 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Thomas H Davenport.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The AI advantage: How to put the artificial intelligence revolution to work</span>.

</span>
<span class="ltx_bibblock">mit Press, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Fang Liu, Shaobo Guo, Qianwen Xing, Xinye Sha, Ying Chen, Yuhui Jin, Qi Zheng, and Chang Yu.

</span>
<span class="ltx_bibblock">Application of an ann and lstm-based ensemble model for stock market prediction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2024 IEEE 7th International Conference on Information Systems and Computer Aided Education (ICISCAE)</span>, pages 390–395. IEEE, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Yang Bao, Gilles Hilary, and Bin Ke.

</span>
<span class="ltx_bibblock">Artificial intelligence and fraud detection.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Innovative Technology at the Interface of Finance and Operations: Volume I</span>, pages 223–247, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Zhuqi Wang, Qinghe Zhang, and Zhuopei Cheng.

</span>
<span class="ltx_bibblock">Application of ai in real-time credit risk detection.

</span>
<span class="ltx_bibblock">2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Shicheng Zhou, Zizhou Zhang, Rong Zhang, Yuchen Yin, Chia Hong Chang, and Qinyan Shen.

</span>
<span class="ltx_bibblock">Regression and forecasting of us stock returns based on lstm.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.05210</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Giuseppe Nuti, Mahnoosh Mirghaemi, Philip Treleaven, and Chaiyakorn Yingsaeree.

</span>
<span class="ltx_bibblock">Algorithmic trading.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Computer</span>, 44(11):61–69, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Yu Cheng, Liyang Wang, Xinye Sha, Qiyuan Tian, Fang Liu, Qianwen Xing, Hao Wang, and Chang Yu.

</span>
<span class="ltx_bibblock">Optimized credit score prediction via an ensemble model and smoteenn integration.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2024 IEEE 7th International Conference on Information Systems and Computer Aided Education (ICISCAE)</span>, pages 355–361, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Haoyang Feng and Yuan Gao.

</span>
<span class="ltx_bibblock">Ad placement optimization algorithm combined with machine learning in internet e-commerce.

</span>
<span class="ltx_bibblock">2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Mustafa Hamid Hassan, Salama A Mostafa, Aida Mustapha, Mohd Helmy Abd Wahab, and Danial Md Nor.

</span>
<span class="ltx_bibblock">A survey of multi-agent system approach in risk assessment.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2018 International Symposium on Agent, Multi-Agent Systems and Robotics (ISAMSR)</span>, pages 1–6. IEEE, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Zong Ke, Shicheng Zhou, Yining Zhou, Chia Hong Chang, and Rong Zhang.

</span>
<span class="ltx_bibblock">Detection of ai deepfake and fraud in online payments using gan-based models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.07033</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Kenniy Olorunnimbe and Herna Viktor.

</span>
<span class="ltx_bibblock">Deep learning in the stock market—a systematic survey of practice, backtesting, and applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Artificial Intelligence Review</span>, 56(3):2057–2109, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Lisa A Dieker, Rebecca Hines, Ilene Wilkins, Charles Hughes, Karyn Hawkins Scott, Shaunn Smith, Kathleen Ingraham, Kamran Ali, Tiffanie Zaugg, and Sachin Shah.

</span>
<span class="ltx_bibblock">Using an artificial intelligence (ai) agent to support teacher instruction and student learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Journal of Special Education Preparation</span>, 4(2):78–88, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Siyu Zha, Yujia Liu, Chengbo Zheng, Jiaqi XU, Fuze Yu, Jiangtao Gong, and Yingqing XU.

</span>
<span class="ltx_bibblock">Mentigo: An intelligent agent for mentoring students in the creative problem solving process.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2409.14228</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Mohammed As’ ad.

</span>
<span class="ltx_bibblock">Intelligent tutoring systems, generative artificial intelligence (ai), and healthcare agents: A proof of concept and dual-layer approach.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Cureus</span>, 16(9):e69710, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Yu-Ju Lan and Nian-Shing Chen.

</span>
<span class="ltx_bibblock">Teachers’ agency in the era of llm and generative ai.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Educational Technology &amp; Society</span>, 27(1):I–XVIII, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Tianjia Wang, Tong Wu, Huayi Liu, Chris Brown, and Yan Chen.

</span>
<span class="ltx_bibblock">Generative co-learners: Enhancing cognitive and social presence of students in asynchronous learning with generative ai.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.04365</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Isshin Yunoki, Guy Berreby, Nicholas D’Andrea, Yuhua Lu, and Xiaodong Qu.

</span>
<span class="ltx_bibblock">Exploring ai music generation: A review of deep learning algorithms and datasets for undergraduate researchers.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Human-Computer Interaction</span>, pages 102–116. Springer, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Tianlong Xu, Richard Tong, Jing Liang, Xing Fan, Haoyang Li, and Qingsong Wen.

</span>
<span class="ltx_bibblock">Foundation models for education: Promises and prospects.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.10959</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Olimpius Istrate.

</span>
<span class="ltx_bibblock">Ai agents in education: An early systematic review of emerging roles, potential, and limitations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Revista de Pedagogie Digitala</span>, 3(1):24–30, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Matilda Isaacs, Anwar Majeed, Karim Moussa, and Dolapo Shodipo.

</span>
<span class="ltx_bibblock">Design and implementation of an ethical ai-based teaching assistant for iot security education.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">African Journal of Inter/Multidisciplinary Studies</span>, 6(1):1–12, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Malni Kumarathunga.

</span>
<span class="ltx_bibblock">Transforming education: A modern ai-driven approach for enhancing student engagement in higher education.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Xiaodong Qu, Joshua Sherwood, Peiyan Liu, and Nawwaf Aleisa.

</span>
<span class="ltx_bibblock">Generative ai tools in higher education: A meta-analysis of cognitive impact.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</span>, pages 1–9, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Justin Edwards, Andy Nguyen, Joni Lämsä, Marta Sobocinski, Ridwan Whitehead, Belle Dang, Anni-Sofia Roberts, and Sanna Järvelä.

</span>
<span class="ltx_bibblock">Human-ai collaboration: Designing artificial agents to facilitate socially shared regulation among learners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">British Journal of Educational Technology</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Jifan Yu, Zheyuan Zhang, Daniel Zhang-li, Shangqing Tu, Zhanxin Hao, Rui Miao Li, Haoxuan Li, Yuanchun Wang, Hanming Li, Linlu Gong, et al.

</span>
<span class="ltx_bibblock">From mooc to maic: Reshaping online teaching and learning through llm-driven agents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2409.03512</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Yunchong Liu, Xiaorui Shen, Yeyubei Zhang, Zhongyan Wang, Yexin Tian, Jianglai Dai, and Yuchen Cao.

</span>
<span class="ltx_bibblock">A systematic review of machine learning approaches for detecting deceptive activities on social media: Methods, challenges, and biases, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
A. Gilad Kusne and Austin McDannald.

</span>
<span class="ltx_bibblock">Scalable multi-agent lab framework for lab optimization.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Matter</span>, 6(6):1880–1893, June 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Kevin G. Yager.

</span>
<span class="ltx_bibblock">Towards a science exocortex.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Digital Discovery</span>, 3(10):1933–1957, 2024.

</span>
<span class="ltx_bibblock">Publisher: Royal Society of Chemistry.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Ofer Shir.

</span>
<span class="ltx_bibblock">Towards AI Research Agents in the Chemical Sciences, January 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Songlin Yu, Nian Ran, and Jianjun Liu.

</span>
<span class="ltx_bibblock">Large-language models: The game-changers for materials science research.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Artificial Intelligence Chemistry</span>, 2(2):100076, December 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
Tao Song, Man Luo, Linjiang Chen, Yan Huang, Qing Zhu, Daobin Liu, Baicheng Zhang, Gang Zou, Fei Zhang, Weiwei Shang, Jun Jiang, and Yi Luo.

</span>
<span class="ltx_bibblock">A multi-agent-driven robotic AI chemist enabling autonomous chemical research on demand, July 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
Simon D. Rihm, Yong Ren Tan, Wilson Ang, Hou Yee Quek, Xinhong Deng, Michael Teguh Laksana, Jiaru Bai, Sebastian Mosbach, Jethro Akroyd, and Markus Kraft.

</span>
<span class="ltx_bibblock">The Digital Lab Facility Manager: Automating operations of research laboratories through “The World Avatar”.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nexus</span>, 1(3), September 2024.

</span>
<span class="ltx_bibblock">Publisher: Elsevier.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
Yingzhou Lu, Chiung-Ting Wu, Sarah J Parker, Zuolin Cheng, Georgia Saylor, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, and Yue Wang.

</span>
<span class="ltx_bibblock">Cot: an efficient and accurate method for detecting marker genes among many subtypes.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Bioinformatics Advances</span>, 2(1):vbac037, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
Shanghua Gao, Ada Fang, Yepeng Huang, Valentina Giunchiglia, Ayush Noori, Jonathan Richard Schwarz, Yasha Ektefaie, Jovana Kondic, and Marinka Zitnik.

</span>
<span class="ltx_bibblock">Empowering biomedical discovery with AI agents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Cell</span>, 187(22):6125–6151, October 2024.

</span>
<span class="ltx_bibblock">Publisher: Elsevier.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
Ruochen Li, Teerth Patel, Qingyun Wang, and Xinya Du.

</span>
<span class="ltx_bibblock">MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents, September 2024.

</span>
<span class="ltx_bibblock">arXiv:2408.14033 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha.

</span>
<span class="ltx_bibblock">The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery, September 2024.

</span>
<span class="ltx_bibblock">arXiv:2408.06292 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
Jon M. Laurent, Joseph D. Janizek, Michael Ruzo, Michaela M. Hinks, Michael J. Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew D. White, and Samuel G. Rodriques.

</span>
<span class="ltx_bibblock">LAB-Bench: Measuring Capabilities of Language Models for Biology Research, July 2024.

</span>
<span class="ltx_bibblock">arXiv:2407.10362 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Martin Bauer, Luis Sanchez, and JaeSeung Song.

</span>
<span class="ltx_bibblock">Iot-enabled smart cities: Evolution and outlook.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Sensors</span>, 21(13):4511, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
Panfeng Li, Qikai Yang, Xieming Geng, Wenjing Zhou, Zhicheng Ding, and Yi Nian.

</span>
<span class="ltx_bibblock">Exploring diverse methods in visual question answering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2024 5th International Conference on Electronic Communication and Artificial Intelligence (ICECAI)</span>, pages 681–685. IEEE, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
Georgios N Kouziokas.

</span>
<span class="ltx_bibblock">The application of artificial intelligence in public administration for forecasting high crime risk transportation areas in urban environment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Transportation research procedia</span>, 24:467–473, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
Xinyue Zheng, Zhenya Ma, and Zhao Yuang.

</span>
<span class="ltx_bibblock">Urban design and pollution using ai: Implications for urban development in china.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Heliyon</span>, 10(18), 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
Markus Schatten.

</span>
<span class="ltx_bibblock">AI and the future of entertainment technology.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu, Yiwu Qiu, and Chunlei Chai.

</span>
<span class="ltx_bibblock">DesignGPT: Multi-agent collaboration in design.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2023 16th International Symposium on Computational Intelligence and Design (ISCID)</span>, pages 204–208.

</span>
<span class="ltx_bibblock">ISSN: 2473-3547.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
Ingibergur Stefnisson and David Thue.

</span>
<span class="ltx_bibblock">Mimisbrunnur: AI-assisted authoring for interactive storytelling.

</span>
<span class="ltx_bibblock">14(1):236–242.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
Muhtar Çağkan Uludağlı and Kaya Oğuz.

</span>
<span class="ltx_bibblock">Non-player character decision-making in computer games.

</span>
<span class="ltx_bibblock">56(12):14159–14191.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
SIMA Team, Maria Abi Raad, Arun Ahuja, Catarina Barros, Frederic Besse, Andrew Bolt, Adrian Bolton, Bethanie Brownfield, and et.al Buttimore.

</span>
<span class="ltx_bibblock">Scaling instructable agents across many simulated worlds.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
Katy Ilonka Gero, Zahra Ashktorab, Casey Dugan, Qian Pan, James Johnson, Werner Geyer, Maria Ruiz, Sarah Miller, David R. Millen, Murray Campbell, Sadhana Kumaravel, and Wei Zhang.

</span>
<span class="ltx_bibblock">Mental models of AI agents in a cooperative game setting.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</span>, CHI ’20, pages 1–12. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
Lawrence B. Holder G. Michael Youngblood.

</span>
<span class="ltx_bibblock">Agent-based players for a first-person entertainment-based real-time artificial environment.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
Thilo Hagendorff.

</span>
<span class="ltx_bibblock">The ethics of ai ethics: An evaluation of guidelines.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Minds and Machines</span>, 30(1):99–120, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
Anna Jobin, Marcello Ienca, and Effy Vayena.

</span>
<span class="ltx_bibblock">The global landscape of ai ethics guidelines.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, 1:389–399, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
Spyros Makridakis.

</span>
<span class="ltx_bibblock">The forthcoming artificial intelligence (ai) revolution: Its impact on society and firms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Futures</span>, 90:46–60, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Canyu Chen, Hal Daumé III, Jesse Dodge, Isabella Duan, et al.

</span>
<span class="ltx_bibblock">Evaluating the social impact of generative ai systems in systems and society.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.05949</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
Sarah Parker, Chunhong Mao, Yizhi Wang, Austin Seals, Do-Kyun Kim, Yingzhou Lu, saurabh bhardwaj, Dongping Du, Genesio Karere, David Caudell, et al.

</span>
<span class="ltx_bibblock">Mapping the molecular progression of human coronary atherosclerosis confirms key role of smooth muscle cell phenotype and highlights novel regulators of phenotypic fate.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Circulation</span>, 150(Suppl_1):A4139230–A4139230, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
Ting et al. Huang.

</span>
<span class="ltx_bibblock">Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICLR</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
Yu Li, Tengfei Ma, and Shengyu Zhu.

</span>
<span class="ltx_bibblock">Learning knowledge graphs with language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv:2301.01037</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
Zhicheng Ding, Panfeng Li, Qikai Yang, and Siyang Li.

</span>
<span class="ltx_bibblock">Enhance image-to-image generation with llava-generated prompts.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2024 5th International Conference on Information Science, Parallel and Distributed Systems (ISPDS)</span>, pages 77–81. IEEE, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
CARLA.

</span>
<span class="ltx_bibblock">Carla (autonomous driving simulator).

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/carla-simulator/carla" title="">https://github.com/carla-simulator/carla</a>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
Farama Foundation.

</span>
<span class="ltx_bibblock">Pettingzoo (multi-agent reinforcement learning environments).

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Farama-Foundation/PettingZoo" title="">https://github.com/Farama-Foundation/PettingZoo</a>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
The RoboCup Soccer Simulator.

</span>
<span class="ltx_bibblock">Robocup soccer simulator.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/rcsoccersim" title="">https://github.com/rcsoccersim</a>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
Qicheng Chen and Xiaodong Qu.

</span>
<span class="ltx_bibblock">Amazon-m2 product recommendation in underrepresented locales using chatgpt4o-mini and gemini models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Human-Computer Interaction</span>, pages 158–170. Springer, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
Nan Hao, Yuangang Li, Kecheng Liu, Songtao Liu, Bohao Xu, Chenhao Li, Jintai Chen, Ling Yue, Tianfan Fu, et al.

</span>
<span class="ltx_bibblock">Artificial intelligence-aided digital twin design: A systematic review.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Preprints</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
Ze Yang, Yihong Jin, and Xinhe Xu.

</span>
<span class="ltx_bibblock">Hades: Hardware accelerated decoding for efficient speculation in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.19925</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
Adam H Marblestone, Greg Wayne, and Konrad P Kording.

</span>
<span class="ltx_bibblock">Toward an integration of deep learning and neuroscience.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Frontiers in Computational Neuroscience</span>, 10:94, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
Yang Zhang, Fa Wang, Xin Huang, Xintao Li, Sibei Liu, and Hansong Zhang.

</span>
<span class="ltx_bibblock">Optimization and application of cloud-based deep learning architecture for multi-source data prediction, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
Dario et al. Amodei.

</span>
<span class="ltx_bibblock">Concrete problems in ai safety.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv:1606.06565</span>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
Finale Doshi-Velez and Been Kim.

</span>
<span class="ltx_bibblock">Towards a rigorous science of interpretable machine learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv:1702.08608</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
Steven Yi, Adam Yee, John Harmon, Frank Meng, and Saurabh Hinduja.

</span>
<span class="ltx_bibblock">Enhance wound healing monitoring through a thermal imaging based smartphone app.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Medical imaging 2018: Imaging informatics for healthcare, research, and applications</span>, volume 10579, pages 438–441. SPIE, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
Jing Su, Chufeng Jiang, Xin Jin, Yuxin Qiao, Tingsong Xiao, Hongda Ma, Rong Wei, Zhi Jing, Jiajun Xu, and Junhong Lin.

</span>
<span class="ltx_bibblock">Large language models for forecasting and anomaly detection: A systematic literature review.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.10350</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
Yihong Jin and Ze Yang.

</span>
<span class="ltx_bibblock">Scam detection for ethereum smart contracts: Leveraging graph representation learning for secure blockchain.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.12370</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
Yanli et al. Zhao.

</span>
<span class="ltx_bibblock">Towards domain-agnostic and open-domain generalization of vision and language agents.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">NeurIPS</span>, pages 19567–19578, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
Dong Liu, Yanxuan Yu, Lianghao Tan, Wenjun Wu, Bide Zhao, Zichao Li, Bingjie Lu, and Yijie Wen.

</span>
<span class="ltx_bibblock">Seamcarver: Llm-enhanced content-aware image resizing.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
Ziheng Chen, Fabrizio Silvestri, Jia Wang, He Zhu, Hongshik Ahn, and Gabriele Tolomei.

</span>
<span class="ltx_bibblock">Relax: Reinforcement learning agent explainer for arbitrary predictive models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 31st ACM international conference on information &amp; knowledge management</span>, pages 252–261, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
Emma Strubell, Ananya Ganesh, and Andrew McCallum.

</span>
<span class="ltx_bibblock">Energy and policy considerations for deep learning in nlp.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">ACL</span>, pages 3645–3650, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
Jinlin Xiang and Eli Shlizerman.

</span>
<span class="ltx_bibblock">Tkil: Tangent kernel optimization for class balanced incremental learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 3529–3539, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
Zikai Zhang, Suman Rath, Jiaohao Xu, and Tingsong Xiao.

</span>
<span class="ltx_bibblock">Federated learning for smart grid: A survey on applications and potential vulnerabilities.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2409.10764</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
Jinglan Yang, Jianghuai Liu, Zheng Yao, and Chaoqun Ma.

</span>
<span class="ltx_bibblock">Measuring digitalization capabilities using machine learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Research in International Business and Finance</span>, 70:102380, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
Jinglan Yang, Chaoqun Ma, Shisong Hsiao, and Jianghuai Liu.

</span>
<span class="ltx_bibblock">Blockchain governance: a bibliometric study and content analysis.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Technology Analysis &amp; Strategic Management</span>, 0(0):1–15, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
Yunfan Zhao, Niclas Boehmer, Aparna Taneja, and Milind Tambe.

</span>
<span class="ltx_bibblock">Towards foundation-model-based multiagent system to accelerate ai for social impact.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.07880</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
Chen Chen, Chenyu Zhao, Hongyu Jin, Zhiping Jiang, Wei Wang, and Wen-Yang Li.

</span>
<span class="ltx_bibblock">Association of composite dietary antioxidant index with circadian syndrome: evidence from nhanes.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Frontiers in Nutrition</span>, 11:1501352, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
Chenyu You, Jinlin Xiang, Kun Su, Xiaoran Zhang, Siyuan Dong, John Onofrey, Lawrence Staib, and James S Duncan.

</span>
<span class="ltx_bibblock">Incremental learning meets transfer learning: Application to multi-site prostate mri segmentation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Workshop on Distributed, Collaborative, and Federated Learning</span>, pages 3–16. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
Zhihao Lin, Qi Zhang, Zhen Tian, Peizhuo Yu, Ziyang Ye, Hanyang Zhuang, and Jianglin Lan.

</span>
<span class="ltx_bibblock">Slam2: Simultaneous localization and multimode mapping for indoor dynamic environments.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Pattern Recognition</span>, 158:111054, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
Han Xu, Yuhong Shao, Kareem Benaissa, and Yutong Li.

</span>
<span class="ltx_bibblock">Sparsebf: Enhancing scalability and efficiency for sparsely filled privacy-preserving record linkage.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 33rd ACM International Conference on Information and Knowledge Management</span>, page 4143–4147, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
Han-Cheng Dan, Peng Yan, Jiawei Tan, Yinchao Zhou, and Bingjie Lu.

</span>
<span class="ltx_bibblock">Multiple distresses detection for asphalt pavement using improved you only look once algorithm based on convolutional neural network.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">International Journal of Pavement Engineering</span>, 25(1):2308169, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
Zhihao Lin, Qi Zhang, Zhen Tian, Peizhuo Yu, and Jianglin Lan.

</span>
<span class="ltx_bibblock">Dpl-slam: enhancing dynamic point-line slam through dense semantic methods.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE Sensors Journal</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
Chris Zhuang, Debadyuti Mukherjee, Tianfan Fu, and Ruqi Zhang.

</span>
<span class="ltx_bibblock">Gradient ga: Gradient genetic algorithm for drug molecular design.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.09860</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
Lincan Li, Jiaqi Li, Catherine Chen, Fred Gui, Hongjia Yang, Chenxiao Yu, Zhengguang Wang, Jianing Cai, Junlong Aaron Zhou, Bolin Shen, et al.

</span>
<span class="ltx_bibblock">Political-llm: Large language models in political science.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.06864</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
Jiachen Zhong and Yiting Wang.

</span>
<span class="ltx_bibblock">Enhancing thyroid disease prediction using machine learning: A comparative study of ensemble models and class balancing techniques.

</span>
<span class="ltx_bibblock">2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
An-Lan Wang, Bin Shan, Wei Shi, Kun-Yu Lin, Xiang Fei, Guozhi Tang, Lei Liao, Jingqun Tang, Can Huang, and Wei-Shi Zheng.

</span>
<span class="ltx_bibblock">Pargo: Bridging vision-language with partial and global views.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2408.12928</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
Menghao Huo, Kuan Lu, Yuxiao Li, and Qiang Zhu.

</span>
<span class="ltx_bibblock">Ct-patchtst: Channel-time patch time-series transformer for long-term renewable energy forecasting, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
Faris Jiwad, Owen Wolff, Omar Barabandi, Laith Najjab, and Xiaodong Qu.

</span>
<span class="ltx_bibblock">Flockjs: A browser-native game engine integrating webgpu and peer-to-peer networking for scalable multiplayer experiences.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
Zhen Zhu, Xiaobo Li, Jingsheng Zhai, and Haofeng Hu.

</span>
<span class="ltx_bibblock">Podb: A learning-based polarimetric object detection benchmark for road scenes in adverse weather conditions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Information Fusion</span>, 108:102385, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
Ziheng Chen, Fabrizio Silvestri, Gabriele Tolomei, Jia Wang, He Zhu, and Hongshik Ahn.

</span>
<span class="ltx_bibblock">Explain the explainer: Interpreting model-agnostic counterfactual explanations of a deep reinforcement learning agent.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE Transactions on Artificial Intelligence</span>, 5(4):1443–1457, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib168">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
Adam N Elmachtoub, Henry Lam, Haofeng Zhang, and Yunfan Zhao.

</span>
<span class="ltx_bibblock">Estimate-then-optimize versus integrated-estimation-optimization versus sample average approximation: a stochastic dominance perspective.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.06833</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib169">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
Han Xu, Xingyuan Wang, and Haipeng Chen.

</span>
<span class="ltx_bibblock">Towards real-time and personalized code generation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 33rd ACM International Conference on Information and Knowledge Management</span>, page 5568–5569, 2024.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Aug 16 07:33:46 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
