# Node Runner - MVP Design Document

## MVP Scope

This is an **MVP (Minimum Viable Product)** implementation focused on core functionality. Non-functional requirements such as performance optimization, privacy controls, security hardening, or production scaling are **explicitly out of scope** for this initial version.

## Conceptual Overview & Motivation

### The Full-Stack Testing & Development Challenge

When developing Node.js applications, especially web applications, developers face a fundamental visibility problem:

- **Backend logs** are scattered across stdout, stderr, console outputs, and application logs
- **Frontend logs** are trapped in browser developer tools, disconnected from backend context
- **Log correlation** between frontend actions and backend responses is manual and time-consuming
- **Historical analysis** requires piecing together logs from multiple sources
- **Testing visibility** across the full application stack is nearly impossible
- **Development workflow** lacks unified observability

### Traditional Approaches Fall Short

Current solutions handle only part of the equation:
- Backend logging tools miss frontend context
- Frontend monitoring misses server-side details  
- Full-stack solutions require complex setup and infrastructure
- Manual correlation between frontend and backend events is error-prone
- Process management tools don't integrate with logging systems

### The Node Runner Solution

The `@legion/node-runner` provides **unified full-stack process management and logging** for Node.js applications:

1. **Complete Process Lifecycle**: Start, monitor, and stop Node.js processes with comprehensive management
2. **Transparent Frontend Capture**: Automatically inject logging into web pages served by your application
3. **Unified Log Storage**: All logs (backend + frontend) in a searchable database with semantic capabilities
4. **Intelligent Search**: Semantic, keyword, and structured search across your entire application stack
5. **Session Management**: Clean separation between runs with historical preservation
6. **AI-Agent Friendly**: Designed for programmatic use with consistent APIs

### Key Innovation: Transparent Full-Stack Logging

The critical innovation is **transparent frontend log injection** combined with **comprehensive backend process management**:

**Backend Process Management:**
- Complete process lifecycle with monitoring
- Automatic stdout/stderr capture
- Port management and health checking
- Package manager detection and operations
- Graceful shutdown and resource cleanup

**Frontend Log Injection:**
- Automatically injects JavaScript logger into served web pages
- Captures console output, JavaScript errors, and network requests
- Sends everything back via WebSocket to centralized logging
- **No changes to your application code required**

### Use Cases

- **Development**: See complete application flow during development
- **Testing**: Capture full logs during automated or manual testing  
- **Debugging**: Trace issues across the full stack with timeline correlation
- **Performance Analysis**: Analyze both server and client-side performance
- **AI Agent Operations**: Programmatic process management with full observability

## Technical Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Node Runner Module                         â”‚
â”‚                         (Legion Backend)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                          MCP Tools Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ run_node     â”‚  â”‚ search_logs  â”‚  â”‚ manage_runs  â”‚          â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Core Management Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Process    â”‚  â”‚     Log      â”‚  â”‚   Session    â”‚          â”‚
â”‚  â”‚   Manager    â”‚  â”‚   Storage    â”‚  â”‚   Manager    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Server     â”‚  â”‚   Frontend   â”‚  â”‚    Search    â”‚          â”‚
â”‚  â”‚   Manager    â”‚  â”‚   Injector   â”‚  â”‚   Engine     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Storage & Search Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚    Legion    â”‚  â”‚   Legion     â”‚  â”‚   Package    â”‚          â”‚
â”‚  â”‚   Storage    â”‚  â”‚   Semantic   â”‚  â”‚   Manager    â”‚          â”‚
â”‚  â”‚   Provider   â”‚  â”‚   Search     â”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Architecture

```
Node.js Application                      Browser Pages
        â”‚                                       â”‚
        â”‚ stdout/stderr                         â”‚ console/errors/network
        â”‚                                       â”‚
        â–¼                                       â–¼
Process Monitor â—„â”€â”€â”€â”€ WebSocket Server â—„â”€â”€ Injected Logger
        â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
      Log Storage Manager
               â”‚
         â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
         â–¼     â–¼     â–¼
    Database Semantic Search
           Embeddings  Index
```

## Module Architecture

Standard Legion backend module with comprehensive process and logging management:

```javascript
export class NodeRunnerModule extends Module {
  constructor(dependencies) {
    super('node-runner', dependencies);
    
    this.processManager = dependencies.processManager;     // Process lifecycle
    this.serverManager = dependencies.serverManager;       // Web server management
    this.packageManager = dependencies.packageManager;     // NPM operations
    this.logStorage = dependencies.logStorage;             // Log storage
    this.logSearch = dependencies.logSearch;               // Search capabilities
    this.sessionManager = dependencies.sessionManager;     // Run sessions
    this.frontendInjector = dependencies.frontendInjector; // Frontend logging
  }
  
  static async create(resourceManager) {
    // Initialize Legion providers
    const storage = await StorageProvider.create(resourceManager);
    const search = await SemanticSearchProvider.create(resourceManager);
    
    // Create core managers
    const logStorage = new LogStorage(storage);
    const logSearch = new LogSearch(search);
    const sessionManager = new SessionManager(storage);
    
    // Create process management components
    const processManager = new ProcessManager(logStorage);
    const serverManager = new ServerManager(processManager, logStorage);
    const packageManager = new PackageManager(processManager);
    const frontendInjector = new FrontendLogInjector(logStorage);
    
    const dependencies = {
      processManager,
      serverManager,
      packageManager,
      logStorage,
      logSearch,
      sessionManager,
      frontendInjector
    };
    
    return new NodeRunnerModule(dependencies);
  }
  
  getTools() {
    return [
      new RunNodeTool(this),
      new StopNodeTool(this),
      new SearchLogsTool(this),
      new ListSessionsTool(this),
      new ManagePackagesTool(this),
      new ServerHealthTool(this)
    ];
  }
}
```

## Core Functionality

### 1. Process Management with Comprehensive Logging

```javascript
class ProcessManager extends EventEmitter {
  constructor(logStorage) {
    super();
    this.processes = new Map();
    this.logStorage = logStorage;
  }
  
  async startProcess(command, args, options = {}) {
    const processId = generateId();
    const sessionId = options.sessionId;
    
    // Clear previous logs if requested
    if (options.clearPrevious) {
      await this.logStorage.clearLogs();
    }
    
    // Spawn process with comprehensive monitoring
    const child = spawn(command, args, {
      env: { ...process.env, ...options.env },
      cwd: options.cwd,
      stdio: 'pipe'
    });
    
    // Track process metadata
    this.processes.set(processId, {
      id: processId,
      sessionId,
      child,
      command,
      args,
      startTime: new Date(),
      status: 'running'
    });
    
    // Capture backend logs with structured format
    child.stdout.on('data', (data) => {
      this.logStorage.storeLog({
        sessionId,
        source: 'backend',
        stream: 'stdout',
        level: 'info',
        content: data.toString(),
        timestamp: new Date(),
        processId,
        metadata: { pid: child.pid }
      });
    });
    
    child.stderr.on('data', (data) => {
      this.logStorage.storeLog({
        sessionId,
        source: 'backend',
        stream: 'stderr', 
        level: 'error',
        content: data.toString(),
        timestamp: new Date(),
        processId,
        metadata: { pid: child.pid }
      });
    });
    
    // Handle process lifecycle events
    child.on('exit', (code, signal) => {
      const processInfo = this.processes.get(processId);
      if (processInfo) {
        processInfo.status = code === 0 ? 'completed' : 'failed';
        processInfo.exitCode = code;
        processInfo.signal = signal;
        processInfo.endTime = new Date();
        
        this.emit('process-exit', { processId, code, signal });
      }
    });
    
    this.emit('process-start', { processId, pid: child.pid });
    return { processId, pid: child.pid };
  }
  
  async stopProcess(processId, options = {}) {
    const processInfo = this.processes.get(processId);
    if (!processInfo || processInfo.status !== 'running') {
      return { success: false, error: 'Process not found or not running' };
    }
    
    const { child } = processInfo;
    const timeout = options.timeout || 10000;
    const signal = options.signal || 'SIGTERM';
    
    // Graceful shutdown attempt
    child.kill(signal);
    
    // Force kill after timeout
    const forceKillTimer = setTimeout(() => {
      if (child.exitCode === null) {
        child.kill('SIGKILL');
      }
    }, timeout);
    
    // Wait for exit
    await new Promise(resolve => {
      child.on('exit', () => {
        clearTimeout(forceKillTimer);
        resolve();
      });
    });
    
    this.processes.delete(processId);
    return { success: true };
  }
}
```

### 2. Server Management with Health Monitoring

```javascript
class ServerManager {
  constructor(processManager, logStorage) {
    this.processManager = processManager;
    this.logStorage = logStorage;
    this.servers = new Map();
  }
  
  async startWebServer(command, options = {}) {
    const port = options.port || await this.findAvailablePort(3000);
    const sessionId = options.sessionId;
    
    // Start process
    const { processId } = await this.processManager.startProcess(command, options.args, {
      ...options,
      env: { ...options.env, PORT: port }
    });
    
    // Track server metadata
    this.servers.set(processId, {
      processId,
      sessionId,
      port,
      status: 'starting',
      healthEndpoint: options.healthEndpoint || `http://localhost:${port}`,
      startTime: new Date()
    });
    
    // Wait for server to be ready
    await this.waitForServerReady(port, options.timeout || 30000);
    
    // Perform health check
    const isHealthy = await this.checkServerHealth(processId);
    
    const serverInfo = this.servers.get(processId);
    serverInfo.status = isHealthy ? 'running' : 'unhealthy';
    
    return {
      success: true,
      processId,
      port,
      status: serverInfo.status
    };
  }
  
  async checkServerHealth(processId) {
    const serverInfo = this.servers.get(processId);
    if (!serverInfo) return false;
    
    try {
      const response = await fetch(serverInfo.healthEndpoint, {
        method: 'GET',
        timeout: 5000
      });
      
      return response.ok;
    } catch (error) {
      return false;
    }
  }
  
  async findAvailablePort(preferredPort) {
    let port = preferredPort;
    while (port < preferredPort + 100) {
      if (await this.isPortAvailable(port)) {
        return port;
      }
      port++;
    }
    throw new Error('No available ports found');
  }
}
```

### 3. Frontend Log Injection System

```javascript
class FrontendLogInjector {
  constructor(logStorage) {
    this.logStorage = logStorage;
    this.wsServers = new Map();
  }
  
  async setupInjection(processId, sessionId, serverPort) {
    // Start WebSocket server for frontend log capture
    const wsPort = await this.startWebSocketServer(processId, sessionId);
    
    // Set up HTTP response interception to inject logging script
    // MVP Note: This is the primary implementation challenge
    await this.setupHTTPInterception(serverPort, sessionId, wsPort);
    
    return wsPort;
  }
  
  async startWebSocketServer(processId, sessionId) {
    const WebSocketServer = require('ws').WebSocketServer;
    const wsPort = 9823 + Math.floor(Math.random() * 1000); // Avoid conflicts
    
    const wss = new WebSocketServer({ port: wsPort });
    this.wsServers.set(processId, wss);
    
    wss.on('connection', (ws) => {
      ws.on('message', async (data) => {
        try {
          const frontendLog = JSON.parse(data);
          
          // Store frontend log with structured format
          await this.logStorage.storeLog({
            sessionId: sessionId,
            source: 'frontend',
            stream: frontendLog.type,        // 'console' | 'error' | 'network'
            level: frontendLog.level || 'info',
            content: frontendLog.message || frontendLog.content,
            timestamp: new Date(frontendLog.timestamp),
            processId,
            metadata: {
              url: frontendLog.url,
              userAgent: frontendLog.userAgent,
              method: frontendLog.method,       // Network requests
              status: frontendLog.status,       // Response status
              duration: frontendLog.duration,   // Request timing
              stack: frontendLog.stack,         // Error stack traces
              filename: frontendLog.filename,   // Error location
              line: frontendLog.line            // Error line
            }
          });
        } catch (error) {
          console.warn('Failed to process frontend log:', error);
        }
      });
    });
    
    return wsPort;
  }
  
  generateInjectionScript(sessionId, wsPort) {
    return `
    <script>
    (function() {
      const ws = new WebSocket('ws://localhost:${wsPort}');
      const sessionId = '${sessionId}';
      
      // Wait for connection
      ws.addEventListener('open', function() {
        
        // Capture all console methods
        ['log', 'info', 'warn', 'error', 'debug'].forEach(method => {
          const original = console[method];
          console[method] = function(...args) {
            original.apply(console, args);
            
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(JSON.stringify({
                type: 'console',
                level: method,
                message: args.map(a => 
                  typeof a === 'object' ? JSON.stringify(a) : String(a)
                ).join(' '),
                sessionId: sessionId,
                timestamp: Date.now(),
                url: window.location.href,
                userAgent: navigator.userAgent
              }));
            }
          };
        });
        
        // Capture JavaScript errors
        window.addEventListener('error', function(event) {
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify({
              type: 'error',
              level: 'error',
              message: event.message,
              stack: event.error?.stack,
              filename: event.filename,
              line: event.lineno,
              column: event.colno,
              sessionId: sessionId,
              timestamp: Date.now(),
              url: window.location.href
            }));
          }
        });
        
        // Capture unhandled promise rejections
        window.addEventListener('unhandledrejection', function(event) {
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify({
              type: 'error',
              level: 'error',
              message: 'Unhandled Promise Rejection: ' + event.reason,
              stack: event.reason?.stack,
              sessionId: sessionId,
              timestamp: Date.now(),
              url: window.location.href
            }));
          }
        });
        
        // Capture network requests (fetch)
        const originalFetch = window.fetch;
        window.fetch = async function(...args) {
          const start = performance.now();
          const url = typeof args[0] === 'string' ? args[0] : args[0].url;
          const options = args[1] || {};
          const method = options.method || 'GET';
          
          try {
            const response = await originalFetch(...args);
            const duration = performance.now() - start;
            
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(JSON.stringify({
                type: 'network',
                level: response.ok ? 'info' : 'warn',
                message: \`\${method} \${url} -> \${response.status} (\${Math.round(duration)}ms)\`,
                method: method,
                status: response.status,
                duration: duration,
                sessionId: sessionId,
                timestamp: Date.now(),
                url: window.location.href
              }));
            }
            
            return response;
          } catch (error) {
            if (ws.readyState === WebSocket.OPEN) {
              ws.send(JSON.stringify({
                type: 'network',
                level: 'error',
                message: \`\${method} \${url} -> ERROR: \${error.message}\`,
                method: method,
                error: error.message,
                sessionId: sessionId,
                timestamp: Date.now(),
                url: window.location.href
              }));
            }
            throw error;
          }
        };
        
      });
    })();
    </script>`;
  }
  
  // MVP Implementation Approaches for HTTP Response Interception:
  // 1. Proxy Approach: HTTP proxy between browser and application (most robust)
  // 2. Middleware Detection: Auto-detect Express/Fastify and inject middleware
  // 3. Response Stream Interception: Intercept HTTP responses at process level
  async setupHTTPInterception(serverPort, sessionId, wsPort) {
    // Implementation details TBD - this is the main technical challenge
    // For MVP, could start with proxy approach or manual middleware injection
    console.log(`Setting up HTTP interception for port ${serverPort}`);
  }
}
```

### 4. Structured Log Storage

```javascript
class LogStorage {
  constructor(storageProvider) {
    this.storage = storageProvider;
    this.collection = 'node_runner_logs';
    this.runsCollection = 'node_runner_runs';
    this.embeddingsCollection = 'log_embeddings';
  }
  
  async storeLog(logEntry) {
    // Create comprehensive structured log record
    const logRecord = {
      id: generateId(),
      sessionId: logEntry.sessionId,
      processId: logEntry.processId,
      timestamp: logEntry.timestamp || new Date(),
      source: logEntry.source,           // 'backend' | 'frontend'
      stream: logEntry.stream,           // 'stdout' | 'stderr' | 'console' | 'network' | 'error'
      level: logEntry.level,             // 'info' | 'warn' | 'error' | 'debug'
      content: logEntry.content,
      metadata: {
        // Backend metadata
        pid: logEntry.metadata?.pid,
        
        // Frontend metadata
        url: logEntry.metadata?.url,
        userAgent: logEntry.metadata?.userAgent,
        
        // Network request metadata
        method: logEntry.metadata?.method,
        status: logEntry.metadata?.status,
        duration: logEntry.metadata?.duration,
        
        // Error metadata
        stack: logEntry.metadata?.stack,
        filename: logEntry.metadata?.filename,
        line: logEntry.metadata?.line,
        column: logEntry.metadata?.column,
        
        // Additional context
        ...logEntry.metadata
      }
    };
    
    // Store in database
    await this.storage.insert(this.collection, logRecord);
    
    // Generate semantic embeddings for search
    const embedding = await this.generateEmbedding(logRecord.content);
    await this.storage.insert(this.embeddingsCollection, {
      logId: logRecord.id,
      embedding: embedding,
      content: logRecord.content,
      sessionId: logRecord.sessionId
    });
    
    return logRecord.id;
  }
  
  async clearLogs() {
    await this.storage.deleteMany(this.collection, {});
    await this.storage.deleteMany(this.embeddingsCollection, {});
  }
}
```

### 5. Multi-Modal Search Engine

```javascript
class LogSearch {
  constructor(semanticSearch, storage) {
    this.semantic = semanticSearch;
    this.storage = storage;
  }
  
  async search(query, options = {}) {
    const results = [];
    
    // Semantic search using embeddings
    if (options.searchType === 'semantic' || options.searchType === 'hybrid') {
      const semanticResults = await this.semantic.search(
        'log_embeddings',
        query,
        { 
          limit: options.limit,
          filters: options.sessionId ? { sessionId: options.sessionId } : {}
        }
      );
      results.push(...semanticResults.map(r => ({ ...r, matchType: 'semantic' })));
    }
    
    // Keyword/text search
    if (options.searchType === 'keyword' || options.searchType === 'hybrid') {
      const filter = {
        $text: { $search: query }
      };
      if (options.sessionId) filter.sessionId = options.sessionId;
      
      const keywordResults = await this.storage.find('node_runner_logs', filter, {
        limit: options.limit
      });
      results.push(...keywordResults.map(r => ({ ...r, matchType: 'keyword' })));
    }
    
    // Structured database queries
    if (options.searchType === 'database' || options.filters) {
      const filter = { ...options.filters };
      if (options.sessionId) filter.sessionId = options.sessionId;
      
      const dbResults = await this.storage.find('node_runner_logs', filter, {
        limit: options.limit,
        sort: { timestamp: -1 }
      });
      results.push(...dbResults.map(r => ({ ...r, matchType: 'database' })));
    }
    
    // Deduplicate and sort by relevance/timestamp
    return this.deduplicateAndSort(results, options);
  }
  
  deduplicateAndSort(results, options) {
    // Remove duplicates based on log ID
    const seen = new Set();
    const unique = results.filter(result => {
      if (seen.has(result.id)) return false;
      seen.add(result.id);
      return true;
    });
    
    // Sort by timestamp (most recent first) or relevance
    return unique.sort((a, b) => {
      if (options.sortBy === 'relevance') {
        // Prioritize semantic matches, then keyword, then database
        const order = { semantic: 3, keyword: 2, database: 1 };
        return (order[b.matchType] || 0) - (order[a.matchType] || 0);
      }
      return new Date(b.timestamp) - new Date(a.timestamp);
    });
  }
}
```

## Legion Tools

### run_node Tool

```javascript
class RunNodeTool extends Tool {
  constructor(module) {
    super({
      name: 'run_node',
      description: 'Execute Node.js process with comprehensive logging',
      inputSchema: z.object({
        command: z.string().describe('Command to execute (e.g., "node server.js", "npm start")'),
        args: z.array(z.string()).optional().describe('Additional command line arguments'),
        env: z.record(z.string()).optional().describe('Environment variables'),
        cwd: z.string().optional().describe('Working directory'),
        port: z.number().optional().describe('Expected server port (for web servers)'),
        clearLogs: z.boolean().default(true).describe('Clear previous logs before starting'),
        injectFrontendLogger: z.boolean().default(true).describe('Inject frontend logging into served pages'),
        healthEndpoint: z.string().optional().describe('Health check endpoint for servers'),
        timeout: z.number().optional().describe('Startup timeout in milliseconds')
      })
    });
    this.module = module;
  }
  
  async execute(args) {
    this.emit('progress', { status: 'Creating new run session...' });
    
    // Create new session
    const session = await this.module.sessionManager.createSession({
      command: args.command,
      args: args.args,
      environment: args.env,
      cwd: args.cwd
    });
    
    this.emit('progress', { status: 'Starting Node.js process...', sessionId: session.id });
    
    // Determine if this is a server or regular process
    const isWebServer = args.port || args.healthEndpoint || args.injectFrontendLogger;
    
    let result;
    if (isWebServer) {
      // Use server manager for web servers
      result = await this.module.serverManager.startWebServer(args.command, {
        args: args.args,
        env: args.env,
        cwd: args.cwd,
        port: args.port,
        sessionId: session.id,
        healthEndpoint: args.healthEndpoint,
        timeout: args.timeout,
        clearPrevious: args.clearLogs
      });
      
      // Set up frontend logging if requested
      if (args.injectFrontendLogger && result.success) {
        await this.module.frontendInjector.setupInjection(
          result.processId,
          session.id,
          result.port
        );
      }
    } else {
      // Use process manager for regular processes
      result = await this.module.processManager.startProcess(args.command, args.args, {
        env: args.env,
        cwd: args.cwd,
        sessionId: session.id,
        clearPrevious: args.clearLogs
      });
    }
    
    if (result.success) {
      this.emit('progress', { 
        status: 'Process started successfully', 
        sessionId: session.id,
        processId: result.processId
      });
      
      return {
        success: true,
        sessionId: session.id,
        processId: result.processId,
        port: result.port,
        message: `Process started with session ${session.id}`
      };
    } else {
      return {
        success: false,
        error: result.error,
        sessionId: session.id
      };
    }
  }
}
```

### search_logs Tool

```javascript
class SearchLogsTool extends Tool {
  constructor(module) {
    super({
      name: 'search_logs',
      description: 'Search across all captured logs (backend and frontend)',
      inputSchema: z.object({
        query: z.string().describe('Search query'),
        searchType: z.enum(['semantic', 'keyword', 'database', 'hybrid']).default('hybrid'),
        sessionId: z.string().optional().describe('Filter by run session'),
        source: z.enum(['backend', 'frontend']).optional().describe('Filter by log source'),
        level: z.enum(['info', 'warn', 'error', 'debug']).optional().describe('Filter by log level'),
        stream: z.string().optional().describe('Filter by stream type'),
        timeRange: z.object({
          start: z.string().optional(),
          end: z.string().optional()
        }).optional().describe('Filter by time range'),
        limit: z.number().default(100).describe('Maximum number of results'),
        sortBy: z.enum(['timestamp', 'relevance']).default('timestamp')
      })
    });
    this.module = module;
  }
  
  async execute(args) {
    const filters = {};
    
    // Build filters
    if (args.sessionId) filters.sessionId = args.sessionId;
    if (args.source) filters.source = args.source;
    if (args.level) filters.level = args.level;
    if (args.stream) filters.stream = args.stream;
    
    // Time range filtering
    if (args.timeRange) {
      filters.timestamp = {};
      if (args.timeRange.start) filters.timestamp.$gte = new Date(args.timeRange.start);
      if (args.timeRange.end) filters.timestamp.$lte = new Date(args.timeRange.end);
    }
    
    const results = await this.module.logSearch.search(args.query, {
      searchType: args.searchType,
      filters: filters,
      limit: args.limit,
      sortBy: args.sortBy,
      sessionId: args.sessionId
    });
    
    return {
      success: true,
      count: results.length,
      searchType: args.searchType,
      logs: results.map(log => ({
        id: log.id,
        timestamp: log.timestamp,
        source: log.source,
        level: log.level,
        stream: log.stream,
        content: log.content,
        metadata: log.metadata,
        matchType: log.matchType
      }))
    };
  }
}
```

## Database Schema

### Runs Collection
```javascript
{
  id: String,                     // Unique run ID
  startTime: Date,
  endTime: Date,
  status: String,                 // 'running' | 'completed' | 'failed'
  command: String,                // Initial command
  args: Array,                    // Command arguments
  environment: Object,            // Environment variables
  cwd: String,                    // Working directory
  exitCode: Number,
  stats: {
    totalLogs: Number,
    backendLogs: Number,
    frontendLogs: Number,
    errorCount: Number,
    warningCount: Number
  }
}
```

### Logs Collection
```javascript
{
  id: String,                     // Unique log ID
  sessionId: String,              // Links to run session
  processId: String,              // Links to process
  timestamp: Date,
  source: String,                 // 'backend' | 'frontend'
  stream: String,                 // 'stdout' | 'stderr' | 'console' | 'network' | 'error'
  level: String,                  // 'info' | 'warn' | 'error' | 'debug'
  content: String,                // Log message content
  metadata: {
    // Backend-specific
    pid: Number,                  // Process ID
    
    // Frontend-specific  
    url: String,                  // Page URL
    userAgent: String,            // Browser info
    
    // Network-specific
    method: String,               // HTTP method
    status: Number,               // Response status
    duration: Number,             // Request duration (ms)
    
    // Error-specific
    stack: String,                // Error stack trace
    filename: String,             // Error file
    line: Number,                 // Error line
    column: Number                // Error column
  }
}
```

### Log Embeddings Collection
```javascript
{
  logId: String,                  // Links to log entry
  sessionId: String,              // For filtering
  embedding: Array,               // Vector embedding
  content: String                 // Original log content
}
```

## Configuration

Environment variables loaded via ResourceManager:

```bash
# Core Configuration
NODE_RUNNER_DB_COLLECTION=node_runner    # Database collection prefix
NODE_RUNNER_LOG_RETENTION=30             # Days to keep logs
NODE_RUNNER_WS_PORT_BASE=9823            # Base port for WebSocket servers

# Search Configuration
NODE_RUNNER_SEARCH_CACHE_TTL=3600        # Search cache TTL seconds

# Performance Configuration
NODE_RUNNER_BATCH_SIZE=50                # Log batch size
NODE_RUNNER_MAX_LOGS=100000              # Maximum stored logs
NODE_RUNNER_BUFFER_SIZE=1000             # Process output buffer size

# Server Configuration
NODE_RUNNER_HEALTH_TIMEOUT=30000         # Health check timeout
NODE_RUNNER_STARTUP_TIMEOUT=30000        # Server startup timeout
NODE_RUNNER_SHUTDOWN_TIMEOUT=10000       # Graceful shutdown timeout
```

## Usage Examples

### Full-Stack Web Application Testing

```javascript
// Start a web server with complete logging
const result = await moduleLoader.execute('node-runner', 'run_node', {
  command: 'npm start',
  port: 3000,
  clearLogs: true,
  injectFrontendLogger: true,
  healthEndpoint: 'http://localhost:3000/health'
});

// Search across all logs (backend + frontend)
const allLogs = await moduleLoader.execute('node-runner', 'search_logs', {
  query: 'user authentication',
  searchType: 'hybrid',
  sessionId: result.sessionId
});

// Find only frontend errors
const frontendErrors = await moduleLoader.execute('node-runner', 'search_logs', {
  query: '',
  searchType: 'database',
  sessionId: result.sessionId,
  source: 'frontend',
  level: 'error'
});

// Find backend API errors with network correlation
const apiErrors = await moduleLoader.execute('node-runner', 'search_logs', {
  query: 'API error 500',
  searchType: 'semantic',
  sessionId: result.sessionId
});
```

### Development Workflow

```javascript
// Start development server
const devServer = await moduleLoader.execute('node-runner', 'run_node', {
  command: 'npm run dev',
  env: { NODE_ENV: 'development' },
  injectFrontendLogger: true
});

// Monitor in real-time during development
setInterval(async () => {
  const recentLogs = await moduleLoader.execute('node-runner', 'search_logs', {
    query: '',
    searchType: 'database',
    sessionId: devServer.sessionId,
    timeRange: {
      start: new Date(Date.now() - 60000).toISOString() // Last minute
    },
    limit: 20
  });
  
  console.log('Recent activity:', recentLogs.logs);
}, 10000);
```

## Integration Points

1. **Legion StorageProvider**: All database operations for logs and sessions
2. **Legion SemanticSearchProvider**: Embedding generation and vector search
3. **Legion Module System**: Standard module pattern with comprehensive tools
4. **Legion ResourceManager**: Configuration and dependency injection

## Dependencies

- `cross-spawn`: Safe process spawning
- `ws`: WebSocket server for frontend log capture
- `detect-port`: Port availability detection
- `@legion/storage`: Database operations via Legion
- `@legion/semantic-search`: Semantic search capabilities
- `@legion/tools`: Legion module and tool base classes
- `zod`: Schema validation for tool inputs

## Implementation Assessment

This design is **highly implementable** by a competent senior developer. The architecture demonstrates:

### âœ… **Strong Design Qualities:**
- **Excellent Architecture**: Clean separation of concerns with well-defined components
- **Clear Implementation Roadmap**: Detailed code examples for all major components  
- **Standard Patterns**: Uses familiar Node.js patterns (EventEmitter, spawn, WebSockets)
- **Well-Defined Interfaces**: Clean APIs between components
- **Proper Legion Integration**: Follows established framework patterns

### ðŸ“‹ **Implementation Complexity Breakdown:**

**ðŸŸ¢ Straightforward Components (70% of work):**
- ProcessManager - Standard Node.js process spawning and lifecycle
- LogStorage - Database operations using existing StorageProvider
- LogSearch - Search implementation using existing SemanticSearchProvider  
- Session Management - CRUD operations with proper cleanup
- Legion Module wrapper - Standard Legion patterns

**ðŸŸ¡ Moderate Complexity (25% of work):**
- ServerManager with health checks - HTTP client work and port detection
- WebSocket server management - Proper lifecycle and cleanup
- Multi-modal search with deduplication - Some algorithmic complexity
- Frontend JavaScript injection script - Straightforward but needs testing

**ðŸ”´ Primary Challenge (5% of work):**
- **HTTP Response Interception** - The main technical challenge requiring creative solution

### ðŸŽ¯ **Why This Design Works:**
1. **Addresses Real Pain Points** - Clear motivation solving genuine developer problems
2. **Innovative Solution** - Transparent full-stack logging provides genuine value
3. **Production-Grade Architecture** - Handles resource cleanup, health checks, graceful shutdown
4. **Comprehensive Coverage** - Backend + frontend + search + session management
5. **AI-Agent Ready** - Consistent APIs perfect for programmatic use

## Summary

### MVP Features:
- **Complete Process Lifecycle**: Node.js process management with monitoring
- **Transparent Frontend Logging**: Automatic injection into served web pages
- **Unified Log Storage**: Single database for all application logs
- **Intelligent Search**: Semantic, keyword, and structured search capabilities
- **Session Management**: Clean test runs with historical data
- **Health Monitoring**: Basic server health checks and port management
- **AI-Agent Ready**: Consistent APIs designed for programmatic use

### Innovation:
The critical innovation is combining **robust process management** with **transparent full-stack logging**. You get complete visibility into both your Node.js application AND any web pages it serves - all without changing a single line of your application code.

Perfect for development, testing, debugging, and AI agent operations that need complete observability across the entire application stack.