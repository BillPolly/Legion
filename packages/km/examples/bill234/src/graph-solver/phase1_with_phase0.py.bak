#!/usr/bin/env python3
"""Phase 1: Value Planning - Value identification (pronouns resolved in Phase 0)"""
import sys
from pathlib import Path
import json
from jinja2 import Environment, FileSystemLoader

# Add parent directories to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))
from common.llm_client import call_llm
from phase0_pronoun_resolution import run_phase0_pronoun_resolution
from validators import validate_pronoun_resolution
from retry_framework import run_phase_with_retry


def parse_json_response(response):
    """Parse JSON response, handling markdown code fences"""
    # Strip markdown code fences if present
    response = response.strip()
    if response.startswith('```json'):
        response = response[7:]  # Remove ```json
    elif response.startswith('```'):
        response = response[3:]  # Remove ```
    if response.endswith('```'):
        response = response[:-3]  # Remove trailing ```
    response = response.strip()
    return json.loads(response)


def run_phase1(test_case, previous_results, calculation_rules, verbose=False):
    """
    Phase 1: Identify values, classify semantic types (pronouns resolved in Phase 0)

    Args:
        test_case: Dict with example_id, turn, question, gold_answer
        previous_results: Dict of {variable_name: {question, answer, scale}} from previous turns
        calculation_rules: Formatted string from ontology_loader
        verbose: Print debug info

    Returns:
        {
            'resolved_question': 'expanded question with no pronouns',
            'values': {
                'value_name': {
                    'description': '...',
                    'semantic_type': 'change_value',
                    'source': 'previous_result'  // uses variable name to lookup
                },
                'another_value_name': {
                    'description': '...',
                    'semantic_type': 'monetary_value',
                    'source': 'knowledge_graph'  // new value from KG
                }
            }
        }
    """
    # PHASE 0: Pronoun Resolution with validation + retry
    metadata = {
        'example_id': test_case['example_id'],
        'turn': test_case['turn']
    }

    def phase0_func(error_context=None):
        return run_phase0_pronoun_resolution(
            test_case['question'],
            previous_results,
            verbose=verbose,
            error_context=error_context,
            metadata=metadata
        )

    def phase0_validator(result):
        return validate_pronoun_resolution(result['resolved_question'], test_case['question'])

    if verbose:
        print(f"\n=== Running Phase 0: Pronoun Resolution ===")

    phase0_output = run_phase_with_retry(
        phase0_func,
        phase0_validator,
        max_retries=2,
        log_func=print if verbose else None,
        phase_name="Phase 0: Pronoun Resolution"
    )

    resolved_question = phase0_output['resolved_question']

    if verbose:
        print(f"âœ“ Phase 0 complete: {resolved_question}")

    # PHASE 1: Value Planning (using resolved question)
    # Load prompt template
    template_dir = Path(__file__).parent / 'prompts'
    env = Environment(loader=FileSystemLoader(str(template_dir)))
    template = env.get_template('value_planning.j2')

    # Render prompt with RESOLVED question
    prompt = template.render(
        question=resolved_question,  # Use resolved question from Phase 0
        previous_results=previous_results,
        calculation_rules=calculation_rules
    )

    # Call LLM with logging metadata
    metadata = {
        'example_id': test_case['example_id'],
        'turn': test_case['turn'],
        'question': test_case['question'],
        'phase': 'phase1_value_planning'
    }

    if verbose:
        print(f"\n--- PHASE 1: Value Planning ---")
        print(f"Prompt length: {len(prompt)} chars")

    response = call_llm(prompt, metadata)

    # Parse JSON response
    try:
        output = parse_json_response(response)
    except json.JSONDecodeError as e:
        if verbose:
            print(f"Error parsing Phase 1 response: {e}")
            print(f"Response: {response[:500]}")
        raise

    if verbose:
        print(f"Resolved question: {output['resolved_question']}")
        print(f"Values identified: {list(output['values'].keys())}")

    return output


if __name__ == "__main__":
    # Test on Example 2, Turn 4
    from ontology_loader import load_semantic_guidance

    calculation_rules = load_semantic_guidance()

    test_case = {
        'example_id': '2',
        'turn': 4,
        'question': 'and how much does this change represent in relation to that total in 2000, in percentage?',
        'gold_answer': -32
    }

    previous_results = {
        'net_sales_2001': {'question': 'what was the total of net sales in 2001?', 'answer': 5363},
        'net_sales_2000': {'question': 'and what was that in 2000?', 'answer': 7983},
        'change_in_net_sales': {'question': 'what was, then, the change in the total of net sales over the year?', 'answer': -2620}
    }

    output = run_phase1(test_case, previous_results, calculation_rules, verbose=True)
    print("\n" + "="*80)
    print("PHASE 1 OUTPUT:")
    print(json.dumps(output, indent=2))
